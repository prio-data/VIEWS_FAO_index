{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "\n",
    "#### Generate report style infographic --\n",
    "\n",
    "This notebook is intended to be a 'summary' report guide. It organizes the elements present in preceding notebooks and generates summary maps and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"The current Working Directory is:\", current_directory)\n",
    "\n",
    "# Get the path to the base directory (VIEWS_FAO_index)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(f'The base directory will be set to: {base_dir}')\n",
    "\n",
    "# Add the base directory to sys.path\n",
    "sys.path.insert(0, base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n"
     ]
    }
   ],
   "source": [
    "# delte this is temporary--\n",
    "from src.utils.functions_for_graphics.individual_graphics.map_helper.manipulate_tables_for_mapping import calculate_histogram_data\n",
    "\n",
    "\n",
    "from src.utils.universal_functions.setup.generate_base_file import give_primary_frame\n",
    "\n",
    "from src.utils.functions_for_return_periods.insurance_products_for_RP import insurance_files\n",
    "\n",
    "from src.utils.universal_functions.setup.build_directory import float_to_custom_string, ensure_directory_exists\n",
    "\n",
    "\n",
    "#Functions for graphics:\n",
    "from src.utils.functions_for_graphics.individual_graphics.map_helper.manipulate_tables_for_mapping import clean_info_dataframe, query_and_sort_annual_table, provide_values_at_input_return_periods, retrieve_geodataframe, define_year_to_map, query_geodataframe\n",
    "\n",
    "from src.utils.functions_for_graphics.individual_graphics.image_annual_returnperiod_table import image_save_returnperiodtable\n",
    "from src.utils.functions_for_graphics.individual_graphics.image_annual_returnperiod_lineplot import plot_histogram_with_lineplot_4\n",
    "from src.utils.functions_for_graphics.individual_graphics.image_annual_summary_table import plot_and_colorize_annual_table\n",
    "from src.utils.functions_for_graphics.individual_graphics.image_map_for_Ei import image_save_map_E_i\n",
    "\n",
    "#Mapping structure:\n",
    "from src.utils.functions_for_graphics.layout_formats.event_cat_rp import map_event_cat_rp\n",
    "from src.utils.functions_for_graphics.layout_formats.summary_of_top_years import map_top_years\n",
    "#from src.utils.functions_for_graphics.layout_formats.Layout_single_method_option1 import mapped_option1\n",
    "\n",
    "\n",
    "#functions for all methods\n",
    "from src.utils.universal_functions.FAO_table_formatting.generate_output_tables import generate_and_give_info_dataframe, append_return_periods_to_annual_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 2.44M/40.0M [00:56<14:35, 42.9kB/s] \n"
     ]
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(2442477 bytes read, 37513388 more expected)', IncompleteRead(2442477 bytes read, 37513388 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:737\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    740\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    741\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:883\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    874\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menforce_content_length\n\u001b[1;32m    875\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[39m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[39m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_bytes_read, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining)\n\u001b[1;32m    884\u001b[0m \u001b[39melif\u001b[39;00m read1 \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    885\u001b[0m     (amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[1;32m    886\u001b[0m ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39m# `http.client.HTTPResponse`, so we close it here.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[39m# See https://github.com/python/cpython/issues/113199\u001b[39;00m\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(2442477 bytes read, 37513388 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m   1045\u001b[0m     \u001b[39mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:963\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m<\u001b[39m amt \u001b[39mand\u001b[39;00m data:\n\u001b[1;32m    960\u001b[0m     \u001b[39m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    961\u001b[0m     \u001b[39m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    964\u001b[0m     decoded_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:861\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 861\u001b[0m \u001b[39mwith\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_error_catcher():\n\u001b[1;32m    862\u001b[0m     data \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt, read1\u001b[39m=\u001b[39;49mread1) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fp_closed \u001b[39melse\u001b[39;49;00m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    159\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    160\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/urllib3/response.py:761\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         arg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConnection broken: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 761\u001b[0m     \u001b[39mraise\u001b[39;00m ProtocolError(arg, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mexcept\u001b[39;00m (HTTPException, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(2442477 bytes read, 37513388 more expected)', IncompleteRead(2442477 bytes read, 37513388 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z1544sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m give_primary_frame(\u001b[39m'\u001b[39;49m\u001b[39mFatalities_fao_pgm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcm_properties\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m1988\u001b[39;49m, \u001b[39m2021\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/VIEWS_FAO_index/src/utils/universal_functions/setup/generate_base_file.py:47\u001b[0m, in \u001b[0;36mgive_primary_frame\u001b[0;34m(queryset_name, cm_queryset, start, end)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m#Here is the queryset used:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[39m# (Queryset('Fatalities_fao_pgm','priogrid_month')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m     \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     queryset_base_PG\u001b[39m=\u001b[39m (Queryset(queryset_name, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> 47\u001b[0m     df \u001b[39m=\u001b[39m queryset_base_PG\u001b[39m.\u001b[39;49mfetch()\n\u001b[1;32m     48\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     50\u001b[0m     queryset_cm\u001b[39m=\u001b[39m (Queryset(cm_queryset, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/viewser/commands/queryset/models/queryset.py:224\u001b[0m, in \u001b[0;36mQueryset.fetch\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39mfetch\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m=====\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mRequires a self.push first.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFetching queryset \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m dataset \u001b[39m=\u001b[39m queryset_operations\u001b[39m.\u001b[39;49mfetch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    225\u001b[0m \u001b[39mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/viewser/commands/queryset/operations.py:68\u001b[0m, in \u001b[0;36mQuerysetOperations.fetch\u001b[0;34m(self, queryset_name, start_date, end_date)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m start_date \u001b[39m>\u001b[39m end_date:\n\u001b[1;32m     66\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStart date \u001b[39m\u001b[39m{\u001b[39;00mstart_date\u001b[39m}\u001b[39;00m\u001b[39m bigger than end date \u001b[39m\u001b[39m{\u001b[39;00mend_date\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch(\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_retries,\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remote_url,\n\u001b[1;32m     71\u001b[0m     queryset_name,\n\u001b[1;32m     72\u001b[0m     start_date,\n\u001b[1;32m     73\u001b[0m     end_date\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/viewser/commands/queryset/operations.py:264\u001b[0m, in \u001b[0;36mQuerysetOperations._fetch\u001b[0;34m(self, max_retries, base_url, name, start_date, end_date)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m total_size \u001b[39m>\u001b[39m \u001b[39m1e6\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39mtotal_size, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m progress_bar:\n\u001b[0;32m--> 264\u001b[0m         \u001b[39mfor\u001b[39;49;00m segment \u001b[39min\u001b[39;49;00m response\u001b[39m.\u001b[39;49miter_content(block_size):\n\u001b[1;32m    265\u001b[0m             progress_bar\u001b[39m.\u001b[39;49mupdate(\u001b[39mlen\u001b[39;49m(segment))\n\u001b[1;32m    266\u001b[0m             data\u001b[39m.\u001b[39;49mwrite(segment)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/requests/models.py:818\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 818\u001b[0m     \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    819\u001b[0m \u001b[39mexcept\u001b[39;00m DecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(2442477 bytes read, 37513388 more expected)', IncompleteRead(2442477 bytes read, 37513388 more expected))"
     ]
    }
   ],
   "source": [
    "data = give_primary_frame('Fatalities_fao_pgm', 'cm_properties', 1988, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_working_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provides the primary dataframes defined by the FAO request for information\n",
    "\n",
    "#### Country Year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter (x):\n",
    "\n",
    "Make a selection on the attribute to be investigated. This is qualified to explore either raw fatalities ('fatalities_sum') OR per capita fatalities measured as a value of 100,000 ('percapita_100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_field = 'fatalities_sum' # or fatalities_sum or percapita_100k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from:\n",
    "\n",
    "#### 'standard' or 'aggregation' or 'smoothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'standard' # 'standard' or 'aggregation' or 'smoothing'\n",
    "\n",
    "#No need to change -- elements are dependant on the input above:\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if method == 'smoothing':\n",
    "    value_field = 'perca_Mean'\n",
    "\n",
    "print(value_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select from:\n",
    "\n",
    "#### 'Event year' or 'Country year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_period = 'Country year' # 'Event year' or 'Country year'\n",
    "\n",
    "#No need to change -- elements are dependant on the input above:\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if return_period == 'Event year':\n",
    "    insurance_attribute = 'return period' # This should eventually be changed and cleaned up\n",
    "if return_period == 'Country year':\n",
    "    insurance_attribute = 'Return Period' # This should eventually be changed and cleaned up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter (x):\n",
    "\n",
    "Make a country selection. In this research phase, only one selection can be input; You may not designate a list of countries. The spelling will need to exactly match the database of country names hosted in ViEWS attributes and the spelling convention requires the first letter to be capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Zimbabwe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter (x):\n",
    "\n",
    "\n",
    "##### Select from: integer value 2-10\n",
    "\n",
    "A value error will be raised to prompt a new input if the selection does match specifications required for the intended method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = '3'\n",
    "\n",
    "#No need to change -- elements are dependant on the input above:\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if method == 'aggregation' and int(aggregation) <= 1:\n",
    "    raise ValueError(\"Aggregation value must be greater than 1 for the 'aggregation' method.\")\n",
    "\n",
    "if method == 'standard' or method == 'smoothing':\n",
    "    aggregation = '1'\n",
    "print(aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter (x):\n",
    "\n",
    "Specify how the data should be sorted. Options include:\n",
    "1. 'weighted_sum_return_periods'\n",
    "2. 'first_value'\n",
    "3. 'average_value'\n",
    "4. 'top return period'\n",
    "\n",
    "Differntiating these options:\n",
    "\n",
    "#### Provide matrix communicating which sort attribute may appeal to unique graphic options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_annual_report_by = 'first_value' #first_value or 'average_value' or 'top return period' or 'weight_rp' or 'Total Payout'\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if method == 'smoothing':\n",
    "    sort_annual_report_by = 'first_value' # 'first_value' or 'average_value' /// or year but this is not built in yet\n",
    "\n",
    "if return_period == 'Event year' and sort_annual_report_by == 'sum_pop_payout_rate':\n",
    "        raise ValueError(\"No payout scheme has been defined for the big p (Event year). In order to develop a weighted_sum_return_periods field, payout percentages must be assigned.\")\n",
    "\n",
    "print(sort_annual_report_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter (x):\n",
    "\n",
    "Define the payout scheme\n",
    "\n",
    "big p \n",
    "\n",
    "little p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build core tables informed by preceding set of parameters\n",
    "\n",
    "The `insurance_files` function is informed by the notebooks outling unique specifications for each spatial/methodological unit parameter and return period statistics (little p or big p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conflict_profile, x, y, z = insurance_files(data_working_copy, country, method, return_period, aggregation_unit=aggregation, eval_field=value_field)\n",
    "\n",
    "print(x.head(10))\n",
    "print('y dataframe')\n",
    "print(y)\n",
    "print('z dataframe:')\n",
    "print(z)\n",
    "\n",
    "max_year = max(x['year'])\n",
    "min_year = min(x['year'])\n",
    "\n",
    "print(max_year)\n",
    "print(min_year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Expect issues when running the big p analysis. There will be an error (perhaps just incorrect values) sourced from \n",
    "\n",
    "update_preceding_row_if_not_in_return_period\n",
    "\n",
    "generate_and_give_info_dataframe\n",
    "\n",
    "The issue that is approached with the generate and give info dataframe will not exisit for the big p although other problems may exisit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def develop_info_dataframe(rp,threshold_value, colors, defined_labels):\n",
    "    data = {\n",
    "        'Return Period': [],\n",
    "        'Range': [],\n",
    "        'Color': [],\n",
    "        'Label': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(rp)):\n",
    "        lower_bound = threshold_value[i]\n",
    "        upper_bound = threshold_value[i + 1]\n",
    "        period = rp[i]\n",
    "        color = colors.get(period, '#FFFFFF')  # Default to white if not found\n",
    "        element_label = defined_labels[i]\n",
    "        \n",
    "        data['Return Period'].append(period)\n",
    "        data['Range'].append(f\"{lower_bound} - {upper_bound}\")\n",
    "        data['Color'].append(color)\n",
    "        data['Label'].append(element_label)\n",
    "    # Create DataFrame\n",
    "    info_df = pd.DataFrame(data)\n",
    "    \n",
    "    return(info_df)\n",
    "\n",
    "def update_preceding_row_if_not_in_return_period(df, periods_to_check, value_column, rp_col):\n",
    "    # Iterate through the DataFrame to check for values not in return_periods\n",
    "    for idx, row in df.iterrows():\n",
    "        percentile_value = row[rp_col]\n",
    "\n",
    "        # Skip the first row as it has no preceding row\n",
    "        if idx == 0:\n",
    "            continue\n",
    "\n",
    "        # Ignore rows where Percentile is 'max'\n",
    "        if percentile_value == '--':\n",
    "            continue\n",
    "        \n",
    "        # Skip if the percentile is in the list of return periods\n",
    "        if isinstance(percentile_value, (int, float)) and percentile_value in periods_to_check:\n",
    "            continue\n",
    "\n",
    "        # For the identified value, copy the percapita_100k and Occurrence values to the preceding row\n",
    "        if idx > 0:\n",
    "            df.at[idx - 1, value_column] = row[value_column]\n",
    "            df.at[idx - 1, 'Occurrence'] = row['Occurrence']\n",
    "            print(f\"Updated row {idx-1} with values from row {idx}: {row[value_column]}, {row['Occurrence']}\")\n",
    "\n",
    "        # Stop after updating the first row that matches the condition\n",
    "        break\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_and_give_info_dataframe(data, return_period, value_column, rp_column, cmap=None):\n",
    "\n",
    "    # We do not want to make changes to the original insurance table!\n",
    "    insurance_table_copy = data.copy()\n",
    "\n",
    "    if return_period == 'Country year':\n",
    "\n",
    "        default_color_map = {\n",
    "            0:  '#d5dbdb',   \n",
    "            10: '#377eb8',\n",
    "            20: '#e6ab02',\n",
    "            50: '#762a83',\n",
    "            100: '#b2182b'\n",
    "        }\n",
    "\n",
    "        if cmap is None:\n",
    "            color_map = default_color_map\n",
    "        else: \n",
    "            color_map = cmap\n",
    "\n",
    "        periods_to_check = [10.0, 20.0, 50.0, 100.0]\n",
    "        insurance_table_fixed_for_insurance_application = update_preceding_row_if_not_in_return_period(insurance_table_copy, periods_to_check, value_column, rp_column)\n",
    "\n",
    "        cleaned_thresholds = provide_values_at_input_return_periods(insurance_table_fixed_for_insurance_application, [10,20,50,100], value_column, rp_column) #(insurance_from_E_i, [5,10,20,30], 'percapita_100k', 'Intended Return Period')\n",
    "        # Define the thresholds and include 0 and 100000\n",
    "        thresholds = [0] + cleaned_thresholds + [100000]\n",
    "        return_periods = [0, 10, 20, 50, 100]\n",
    "\n",
    "        if len(thresholds) - 1 != len(return_periods):\n",
    "            raise ValueError(\"The number of thresholds should be one more than the number of return periods.\")\n",
    "        \n",
    "        labels = ['Below 1 in 10 year', '1 in 10 year',  '1 in 20 year',  '1 in 50 year', '1 in 100 year',]\n",
    "\n",
    "        info_df = develop_info_dataframe(return_periods, thresholds, color_map, labels)\n",
    "        return(info_df, color_map)\n",
    "\n",
    "\n",
    "    if return_period == 'Event year':\n",
    "\n",
    "        default_color_map = {\n",
    "                0:  '#d5dbdb',   \n",
    "                5: '#4daf4a',\n",
    "                10: '#377eb8',\n",
    "                20: '#e6ab02',\n",
    "                30: '#c51b7d',\n",
    "        }\n",
    "        if cmap is None:\n",
    "            color_map = default_color_map\n",
    "        else: \n",
    "            color_map = cmap\n",
    "\n",
    "        # For E-i---------------------------------------------------------------------------------------------------------------\n",
    "        cleaned_thresholds = provide_values_at_input_return_periods(insurance_table_copy, [5,10,20,30], value_column, rp_column)\n",
    "\n",
    "            #Now we make to make a reference dataframe regardless if there are duplicates:\n",
    "            # Define the return periods and their associated color map\n",
    "\n",
    "        print('This is a critical dataframe:')\n",
    "            #----- Define Map Pallete:-------------------------------------------------------------------------------------------\n",
    "\n",
    "            # Define the thresholds and include 0 and 100000\n",
    "        thresholds_to30 = [0] + cleaned_thresholds + [100000]\n",
    "        return_periods_to30 = [0, 5, 10, 20, 30]\n",
    "\n",
    "        if len(thresholds_to30) - 1 != len(return_periods_to30):\n",
    "                    raise ValueError(\"The number of thresholds should be one more than the number of return periods.\")\n",
    "                \n",
    "        labels_to30 = ['Below 1 in 5 year', '1 in 5 year', '1 in 10 year',  '1 in 20 year',  '1 in 30 year']\n",
    "\n",
    "        info_df_to30 = develop_info_dataframe(return_periods_to30, thresholds_to30, color_map, labels_to30)\n",
    "        return(info_df_to30, color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('z dataframe:')\n",
    "print(z)\n",
    "\n",
    "# z_copy = z\n",
    "info_df, color_scheme = generate_and_give_info_dataframe(z, return_period, value_field, insurance_attribute)\n",
    "\n",
    "#print(z)\n",
    "print(info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide examples of when to drop and when not to drop RP values:\n",
    "\n",
    "Do not drop when the maximum value of RP 0 is not zero:\n",
    "   Return Period          Range    Color               Label\n",
    "0              0        0 - 8.1  #d5dbdb  Below 1 in 10 year\n",
    "1             10     8.1 - 21.3  #377eb8        1 in 10 year\n",
    "2             20    21.3 - 41.5  #e6ab02        1 in 20 year\n",
    "3             50    41.5 - 54.4  #762a83        1 in 50 year\n",
    "4            100  54.4 - 100000  #b2182b       1 in 100 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the return period that should be dropped (if any) DEFUALT: 0\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#     This is what should be changed     \n",
    "#--------------------------------------------------------------------------------\n",
    "rp_to_drop=[0,10,20,50]\n",
    "#--------------------------------------------------------------------------------\n",
    "cleaned_labels, cleaned_thresholds, filtered_info = clean_info_dataframe(info_df,rp_to_drop)\n",
    "\n",
    "print('Reference the Info Dataframe:')\n",
    "print(filtered_info)\n",
    "print()\n",
    "print(f'Here are the labels to be referenced: {cleaned_labels}')\n",
    "print(f'Here are the corresponding thresholds to be referenced: {cleaned_thresholds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def append_return_periods_to_annual_table(x, y, z, filtered_info, value_field, population_field):\n",
    "    # Calculate the total population for percentage calculation\n",
    "\n",
    "\n",
    "    # Initialize the results dictionary for storing year, label, count, population sum, and percentage\n",
    "    results = {\n",
    "        'year': [], \n",
    "        'Label': [], \n",
    "        'count': [], \n",
    "        'pop sum': [], \n",
    "        'pop prop': []\n",
    "    }\n",
    "\n",
    "    # Loop over each unique year in the dataset 'x'\n",
    "    for year in x['year'].unique():\n",
    "        for _, row in filtered_info.iterrows():\n",
    "            range_start, range_end = map(float, row['Range'].split(' - '))\n",
    "            label = row['Label']\n",
    "\n",
    "            #subset by year and sum by population so pop sum is specific to that year\n",
    "            total_population = x[(x['year'] == year)][population_field].sum()\n",
    "\n",
    "            # Count occurrences within the range for the current year\n",
    "            count = x[(x['year'] == year) & \n",
    "                      (x[value_field] >= range_start) & \n",
    "                      (x[value_field] < range_end)].shape[0]\n",
    "\n",
    "            # Sum the population within the range for the current year\n",
    "            population_sum = x[(x['year'] == year) & \n",
    "                               (x[value_field] >= range_start) & \n",
    "                               (x[value_field] < range_end)][population_field].sum()\n",
    "\n",
    "            # Calculate the population percentage relative to the total population\n",
    "            pop_perc = population_sum / total_population\n",
    "\n",
    "            # Append the year, label, count, population sum, and percentage to the results dictionary\n",
    "            results['year'].append(year)\n",
    "            results['Label'].append(label)\n",
    "            results['count'].append(count)\n",
    "            results['pop sum'].append(population_sum)\n",
    "            results['pop prop'].append(pop_perc)\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Pivot the DataFrame to get counts and population sums for each 'Return Period'\n",
    "    pivoted_df = results_df.pivot_table(index='year', columns='Label', values=['count', 'pop sum', 'pop prop'], fill_value=0)\n",
    "\n",
    "    # Reset the index to make 'year' a column, and flatten the column MultiIndex\n",
    "    pivoted_df.columns = ['_'.join(col).strip() for col in pivoted_df.columns.values]\n",
    "    pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "    # Reformat the annual summary table to only contain the max event and average event\n",
    "    annual_summary_df = y.drop(columns=['second_value', 'third_value'])\n",
    "\n",
    "    # Merge the count of Return Period events with the annual summary table on the field 'year'\n",
    "    merged_annual_summary = pd.merge(annual_summary_df, pivoted_df, on='year')\n",
    "\n",
    "    # Check to make sure none of the columns refer to 'Below X Return Period'\n",
    "    columns_to_drop = merged_annual_summary.filter(like='Below', axis=1).columns\n",
    "\n",
    "    # Drop the identified columns\n",
    "    merged_annual_summary = merged_annual_summary.drop(columns=columns_to_drop)\n",
    "\n",
    "    fixed_order = ['year', 'first_value', 'average_value']\n",
    "    \n",
    "    #incorporating the population weigthed columns in order to define a total payout value----------------------------------------------------------\n",
    "    #-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "    #Right now there is no PAYOUT SCHEME defined for the big p return period so this calculation can only be developed for little p (Country year)\n",
    "    if return_period == 'Country year':\n",
    "        return_period_to_payout_rate = dict(zip(z['Return Period'], z['Payout Rate']))\n",
    "\n",
    "    if return_period == 'Event year':\n",
    "        return_period_to_payout_rate = dict.fromkeys(z['return period'], '100%')\n",
    "\n",
    "    filtered_dict = {\n",
    "            int(k) if k != '--' and '.' in str(k) and float(k).is_integer() else k: v.rstrip('%')\n",
    "            for k, v in return_period_to_payout_rate.items()\n",
    "            if 'undefined' not in str(k) and '--' not in str(k) and 'undefined' not in str(v) and '--' not in str(v)\n",
    "        }\n",
    "\n",
    "    transformed_dict = {\n",
    "            str(k): int(v) for k, v in filtered_dict.items()\n",
    "        }\n",
    "\n",
    "    for key, value in transformed_dict.items():\n",
    "            column_name = f'pop prop_1 in {key} year'\n",
    "            new_column_name = f'pay weight {key}'\n",
    "        \n",
    "            # Check if the column exists in the DataFrame\n",
    "            if column_name in merged_annual_summary.columns:\n",
    "                merged_annual_summary[new_column_name] = merged_annual_summary[column_name] * value\n",
    "\n",
    "    merged_annual_summary['payout rate (%)'] = merged_annual_summary.filter(like='pay weight').sum(axis=1)\n",
    "    merged_annual_summary['Total Payout'] = (merged_annual_summary['payout rate (%)'] * .01) * 1000000\n",
    "\n",
    "#Drop the '1 in <year> year' in field names:----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    merged_annual_summary.columns = merged_annual_summary.columns.str.replace(r'1 in (\\d+) year', r'\\1', regex=True)\n",
    "\n",
    "#Re organize the field structure:---------------------------------------------------------------------------------------------------------------------\n",
    "    columns = list(merged_annual_summary.columns)\n",
    "    # Extract columns that contain \"in \" followed by a number\n",
    "    numeric_columns = [col for col in columns if re.search(r'\\d+', col)]\n",
    "    print(numeric_columns)\n",
    "    # Sort the numeric columns by the number that comes after \"in \"\n",
    "    sorted_numeric_columns = sorted(numeric_columns, key=lambda x: int(re.search(r'\\d+', x).group(0)), reverse=True)\n",
    "    print(sorted_numeric_columns)\n",
    "\n",
    "    # Combine the fixed columns with the sorted numeric columns\n",
    "    new_column_order = fixed_order + sorted_numeric_columns\n",
    "\n",
    "    # Reorder the DataFrame columns based on the new order\n",
    "    merged_annual_summary = merged_annual_summary[new_column_order]\n",
    "\n",
    "    # Handle the case where there are multiple numeric columns for calculating weighted sums\n",
    "    # if len(sorted_numeric_columns) > 1:\n",
    "    #     sorted_numeric_columns_dropbottom = sorted_numeric_columns[:-1]\n",
    "\n",
    "        # Initialize a new column with zeros to accumulate the weighted sum\n",
    "    merged_annual_summary['weight_rp'] = 0\n",
    "\n",
    "#restrict columns to only the fields that are counting the number of occurrences for each conflict return period:\n",
    "    count_columns = [col for col in sorted_numeric_columns if 'count' in col]\n",
    "\n",
    "        # Loop through each column in sorted_numeric_columns_dropbottom\n",
    "    for col in count_columns:\n",
    "            # Extract the numerical part of the column name (assumes the pattern '1 in X year')\n",
    "            numeric_value = int(re.search(r'count_(\\d+)', col).group(1))\n",
    "            \n",
    "            # Multiply the entire column by the extracted numeric value and accumulate the result\n",
    "            merged_annual_summary['weight_rp'] += merged_annual_summary[col] * numeric_value\n",
    "\n",
    "    # else:\n",
    "    #     # If only one column, copy that column as the sum\n",
    "    #     merged_annual_summary['weight_rp'] = 0\n",
    "\n",
    "    #     for col in sorted_numeric_columns:\n",
    "    #         # Extract the numerical part of the column name (assumes the pattern '1 in X year')\n",
    "    #         numeric_value = int(re.search(r'count_(\\d+)', col).group(1))\n",
    "            \n",
    "    #         # Multiply the entire column by the extracted numeric value and accumulate the result\n",
    "    #         merged_annual_summary['weight_rp'] += merged_annual_summary[col] * numeric_value\n",
    "    merged_annual_summary['payout rate (%)'] = merged_annual_summary.filter(like='pay weight').sum(axis=1)\n",
    "    merged_annual_summary['Total Payout'] = (merged_annual_summary['payout rate (%)'] * .01) * 1000000\n",
    "\n",
    "    return merged_annual_summary, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the `Total Payout` sheet. Fields informing the final calculation are retained for transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rp, results_something = append_return_periods_to_annual_table(x, y, z, filtered_info, value_field, 'pop_gpw_sum')\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "y_rp_path = os.path.join(current_directory, 'files', 'reference_tables')\n",
    "ensure_directory_exists(y_rp_path)\n",
    "y_rp_filename = f'{country}_annual_report_{value_field}_{aggregation}x{aggregation}_{return_period}.csv'\n",
    "\n",
    "y_rp_path_filename = os.path.join(y_rp_path, y_rp_filename)\n",
    "\n",
    "y_rp = y_rp.round(4)\n",
    "\n",
    "y_rp.to_csv(y_rp_path_filename)\n",
    "print(f'file saved to: {y_rp_path_filename}')\n",
    "if sort_annual_report_by == 'top return period':\n",
    "    columns = list(y_rp.columns)\n",
    "\n",
    "    # Filter out non-numeric columns\n",
    "    # Filter out non-numeric columns and ensure 'count' is in the column name\n",
    "\n",
    "    numeric_columns = [col for col in columns if 'count' in col]\n",
    "    \n",
    "    print(numeric_columns)\n",
    "\n",
    "    # Extract the numeric part from each string and identify the highest one\n",
    "\n",
    "    # Extract numeric values from the column names and find the column with the highest value\n",
    "    def extract_numeric(col):\n",
    "        match = re.search(r'count_(\\d+)', col)\n",
    "        return int(match.group(1)) if match else -1\n",
    "\n",
    "    # Find the column with the highest numeric value\n",
    "    sort_annual_report_by = max(numeric_columns, key=extract_numeric)\n",
    "    max_value = extract_numeric(sort_annual_report_by)\n",
    "\n",
    "\n",
    "    print(f'The graphics and corresponding tables will sort by the return period: {sort_annual_report_by}')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(y_rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you want to filter this payout table to become more interpretable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#creates Filtered annual payout table:\n",
    "\n",
    "def filter_annual_payout_table___max_avg_count_payout(y_rp):\n",
    "\n",
    "    # List of columns to keep\n",
    "    keep = ['year', 'first_value', 'average_value', 'Total Payout']\n",
    "\n",
    "    # Filter out numeric columns containing 'count'\n",
    "    numeric_columns = [col for col in y_rp.columns if 'count' in col]\n",
    "\n",
    "    # Combine the keep list with numeric columns\n",
    "    filtered_columns = list(set(keep) | set(numeric_columns))\n",
    "\n",
    "    # Filter DataFrame to include only the relevant columns\n",
    "    filtered_df = y_rp[filtered_columns]\n",
    "\n",
    "    # Rename columns\n",
    "    filtered_df.rename(columns={\n",
    "        'first_value': 'max',\n",
    "        'average_value': 'avg'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Define the order: 'max', 'avg', numeric columns, 'Total Payout'\n",
    "    ordered_columns = ['year', 'max', 'avg'] + [col for col in numeric_columns if col in filtered_df.columns] + ['Total Payout']\n",
    "\n",
    "    # Ensure 'Total Payout' is last\n",
    "    filtered_df = filtered_df[ordered_columns]\n",
    "\n",
    "    filtered_df.rename(columns={\n",
    "        'count_100': '100',\n",
    "        'count_50': '50',\n",
    "        'count_20': '20',\n",
    "        'count_10': '10'\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(\"Filtered and Reordered DataFrame with Renamed Numeric Columns:\")\n",
    "\n",
    "    columns_to_round = ['avg', 'Total Payout']\n",
    "    filtered_df[columns_to_round] = filtered_df[columns_to_round].round(1)\n",
    "    return(filtered_df)\n",
    "\n",
    "def filter_annual_payout_table___count(y_rp):\n",
    "\n",
    "    # List of columns to keep\n",
    "    keep = ['year']\n",
    "\n",
    "    # Filter out numeric columns containing 'count'\n",
    "    numeric_columns = [col for col in y_rp.columns if 'count' in col]\n",
    "\n",
    "    # Combine the keep list with numeric columns\n",
    "    filtered_columns = list(set(keep) | set(numeric_columns))\n",
    "\n",
    "    # Filter DataFrame to include only the relevant columns\n",
    "    filtered_df = y_rp[filtered_columns]\n",
    "\n",
    "\n",
    "    # Define the order: 'max', 'avg', numeric columns, 'Total Payout'\n",
    "    ordered_columns = ['year'] + [col for col in numeric_columns if col in filtered_df.columns] \n",
    "\n",
    "    # Ensure 'Total Payout' is last\n",
    "    filtered_df = filtered_df[ordered_columns]\n",
    "\n",
    "    filtered_df.rename(columns={\n",
    "        'count_100': '100',\n",
    "        'count_50': '50',\n",
    "        'count_20': '20',\n",
    "        'count_10': '10'\n",
    "    }, inplace=True)\n",
    "\n",
    "    print(\"Filtered and Reordered DataFrame with Renamed Numeric Columns:\")\n",
    "\n",
    "    return(filtered_df)\n",
    "\n",
    "filtered_df =filter_annual_payout_table___count(y_rp)\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we generate just a basic plot for the derived interpretable payout table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create figure and axis\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# #columns_to_drop = ['max', 'avg']\n",
    "# #filtered_df = filtered_df.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# print(current_directory)\n",
    "# annual_count_path = os.path.join(current_directory, 'files', country, method, return_period, 'table_png')\n",
    "# ensure_directory_exists(y_rp_path)\n",
    "\n",
    "# annual_count_filename = f'{country}_annual_count_{value_field}_{aggregation}x{aggregation}_{return_period}.png'\n",
    "# annual_count_path_filename = os.path.join(annual_count_path, annual_count_filename)\n",
    "\n",
    "# fig_width = 3.25\n",
    "# fig_height = 5.0\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(fig_width, fig_height))  # Adjust size as needed\n",
    "\n",
    "# # Hide the axis\n",
    "# ax.xaxis.set_visible(False) \n",
    "# ax.yaxis.set_visible(False) \n",
    "# ax.set_frame_on(False)\n",
    "\n",
    "# # Create the table\n",
    "# table = ax.table(cellText=filtered_df.values, colLabels=filtered_df.columns, cellLoc='center', loc='center', colColours=['#f5f5f5'] * len(filtered_df.columns))\n",
    "# table.scale(1, 1)  # Scale the table to fit the figure exactly\n",
    "\n",
    "# # Adjust column and row sizes to match figure size\n",
    "# n_cols = len(filtered_df.columns)\n",
    "# n_rows = len(filtered_df)\n",
    "\n",
    "# # Get the width and height of each cell\n",
    "# cell_width = fig_width / n_cols\n",
    "# cell_height = fig_height / (n_rows + 1)  # +1 for header row\n",
    "\n",
    "# # Set column and row sizes\n",
    "# for (i, j), cell in table.get_celld().items():\n",
    "#     cell.set_width(cell_width)\n",
    "#     cell.set_height(cell_height)\n",
    "#     if i == 0:  # Header row\n",
    "#         cell.set_fontsize(15)\n",
    "#     else:\n",
    "#         cell.set_fontsize(14)  # Adjust font size for data cells if needed\n",
    "\n",
    "\n",
    "# plt.savefig(annual_count_path_filename, dpi=300, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here changes are being made locally to the function: lineplot_frominfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produces Graphics and saves to folder which can be referenced by next coding steps:\n",
    "\n",
    "## NOTE:\n",
    "y_rows --> is the number of rows in 'y'. this is a dataframe that contains 1 row for each year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to make a change so that \n",
    "\n",
    "indices = sorted_annual_table.index[sorted_annual_table['year'].isin(evaluate_specific_years)].tolist()\n",
    "\n",
    "is referencing the original index from the input specified years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preceding cells -- UP TO and INCLUDING the cell producing filtered_info, cleaned_labels, and cleaned_thresholds are universal:\n",
    "\n",
    "This means, regardless which graphic function is selected, the preceding steps are required!\n",
    "\n",
    "The formatting of notebook cells, departing from this alert message, follow a two cell structure. The first, is a collection of functions or processess\n",
    "that are applied to a combination of either the tables derived from `insurance_files` function or feature engineering completed by `generate_and_give_info_dataframe`\n",
    "or `clean_info_dataframe`. No other data will be sourced beyond this point. The investigative nature of this notebook and hosted functions is working exclusively\n",
    "with \"insurance files\".\n",
    "\n",
    "The second cell is a mapping function.\n",
    "\n",
    "Future development will construct the \"precondition cell\" to a function built into the desired mapping function. This present status features transparency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_event_cat_rp:\n",
    "\n",
    "#### Preconditions for setting up the mapping function `map_event_cat_rp`\n",
    "Gives Top 3 years and 3 select decadal years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces graphics, tables, and maps for the CELL TYPE RETURN PERIOD:\n",
    "y_rows = y_rp.shape[0]\n",
    "#make the insurance table columns lowercase to keep in line with JPR standards:\n",
    "z.columns = z.columns.str.lower()\n",
    "print(z)\n",
    "#-----This is setting up things to export a map---------------------------------------------------------------\n",
    "sorted_annual_table = query_and_sort_annual_table(y_rp, field_to_sort=sort_annual_report_by, number_of_rows=y_rows)\n",
    "sorted_annual_table.iloc[:, 1:] = sorted_annual_table.iloc[:, 1:].round(1)\n",
    "sorted_annual_table = sorted_annual_table.reset_index(drop=True)\n",
    "\n",
    "filtered_colors = filtered_info['Color'].tolist()\n",
    "lineplot_colors = filtered_colors[1:]\n",
    "image_save_returnperiodtable(z, color_scheme, insurance_attribute, country, method, return_period, value_field, aggregation=aggregation, figure_height=1.75, figure_width=2.5,) #input_table = Jerry_table\n",
    "    #image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info_upto30, country, 'Aggregation', 'Cell', year_to_eval, '3', figure_height=3.5, figure_width=3.5)\n",
    "display(sorted_annual_table)\n",
    "#plot_and_colorize_annual_table(sorted_annual_table, filtered_info, country, method, return_period, aggregation=aggregation, figure_height=5.5, figure_width=4.0)\n",
    "plot_histogram_with_lineplot_4(x, filtered_info, country, method, return_period, aggregation=aggregation, value_field=value_field, labels_to_omit='Below 1 in 5 year', figure_height=3.0, figure_width=6.0, histogram='on', horizontal_rp_expected= 'off')\n",
    "\n",
    "gdf = retrieve_geodataframe(aggregation)\n",
    "for annual_event in range(min(5, y_rows)):\n",
    "        print(f'map for: {annual_event}')\n",
    "        year_to_eval = define_year_to_map(sorted_annual_table, annual_event)\n",
    "        gdf_merged = query_geodataframe(gdf, x, year_to_eval, field=value_field)\n",
    "        image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info, country, method, return_period, year_to_eval, value_field, aggregation, field=value_field, country_label='no', figure_height=3.5, figure_width=3.5, year_id=annual_event)\n",
    "\n",
    "evaluate_specific_years = [2000, 2010, 2020]\n",
    "indices = sorted_annual_table.index[sorted_annual_table['year'].isin(evaluate_specific_years)].tolist()\n",
    "\n",
    "for specific_year in indices:\n",
    "        print(f'map for: {specific_year}')\n",
    "        year_to_eval = define_year_to_map(sorted_annual_table, specific_year)\n",
    "        gdf_merged = query_geodataframe(gdf, x, year_to_eval, field=value_field)\n",
    "        image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info, country, method, return_period, year_to_eval, value_field, aggregation, field=value_field, country_label='no', figure_height=3.5, figure_width=3.5, year_id=specific_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map_event_cat_rp:\n",
    "\n",
    "Gives Top 3 years and 3 select decadal years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_event_cat_rp(country, method, return_period, value_field, min_year, max_year, aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_top_years:\n",
    "\n",
    "#### Preconditions for setting up the mapping function `map_event_cat_rp`\n",
    "Gives Top 10 years of conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = 'summary text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your variables\n",
    "import pandas as pd\n",
    "country  # Example value, replace with actual country\n",
    "\n",
    "max_year = max(y['year'])\n",
    "min_year = min(y['year'])\n",
    "print(f'The max year in the dataframe (max_year): {max_year}')\n",
    "print(f'The min year in the dataframe (max_year): {min_year}')\n",
    "\n",
    "year_range = f\"{min_year}-{max_year}\"  # Example value, replace with actual year range\n",
    "#total_conflict = sum(subset_to_country['fatalities_sum'])  \n",
    "\n",
    "total_events = len(x)\n",
    "pg_events = len(pd.unique(x['pg_id']))\n",
    "total_years = len(pd.unique(x['year']))\n",
    "\n",
    "#method = \"Smoothing\"  # Example value, replace with actual method used\n",
    "#return_period_definition = \"Cell-year\"  # Example value, replace with actual definition\n",
    "\n",
    "year_of_greatest_conflict = sorted_annual_table['year'].iloc[0]\n",
    "\n",
    "row_with_50 = z.loc[z['Return Period'] == 50.0]\n",
    "row_with_100 = z.loc[z['Return Period'] == 100.0]\n",
    "row_with_max = z.loc[z['Return Period'] == 'Max']\n",
    "\n",
    "#greatest_conflict_range = \"2010-2020\"  # Example value, replace with actual range\n",
    "payout_rate_value50 = row_with_50[value_field].values[0]\n",
    "payout_rate_value100 = row_with_100[value_field].values[0]\n",
    "\n",
    "Occurrence_value50 = row_with_50['Occurrence'].values[0]\n",
    "Occurrence_value100 = row_with_100['Occurrence'].values[0]\n",
    "Occurrence_valueMax = row_with_max['Occurrence'].values[0]\n",
    "\n",
    "total_occurence_over100year = Occurrence_value100 + Occurrence_valueMax\n",
    "\n",
    "ged_sb_sum = conflict_profile['ged_sb']\n",
    "ged_ns_sum = conflict_profile['ged_ns']\n",
    "ged_os_sum = conflict_profile['ged_os']\n",
    "fatalities_sum = conflict_profile['fatalities_sum']\n",
    "\n",
    "summary_text = (\n",
    "    f\"During the observed period, a total of {total_events} PRIO-Grid years were analyzed in {country}, spanning from {year_range}. \"\n",
    "    f\"Throughout this time range, the conflict profile consists of {ged_os_sum} fatalities from one-sided events, {ged_sb_sum} state-based, and {ged_ns_sum} non-state, producing a total of {fatalities_sum} events.\"\n",
    "    f\"The analysis employed the {method} method for evaluation. \"\n",
    "    f\"The definition of return period applied is {return_period}. \"\n",
    "    f\"The year with the highest average conflict was {year_of_greatest_conflict}.\"\n",
    "    f\"The thresholds for 1 in 50 and 1 in 100 year events were {payout_rate_value50} and {payout_rate_value100}, respectively. \"\n",
    "    f\"Occurrences of 1 in 50 year events totaled {Occurrence_value50}, while there were {total_occurence_over100year} occurrences of 1 in 100 year events. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preconditions for setting up the mapping function `map_top_years`\n",
    "\n",
    "This cell generates and saves necessary graphics\n",
    "\n",
    "Gives Top 10 years of conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "filtered_y_rp___count=filter_annual_payout_table___count(y_rp)\n",
    "print(filtered_y_rp___count)\n",
    "plot_and_colorize_annual_table(filtered_y_rp___count, country, method, return_period, value_field, aggregation, '2020', 5.5, 4.0, annual_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces graphics, tables, and maps for the CELL TYPE RETURN PERIOD:\n",
    "y_rows = y_rp.shape[0]\n",
    "filtered_y_rp___count=filter_annual_payout_table___count(y_rp)\n",
    "\n",
    "#make the insurance table columns lowercase to keep in line with JPR standards:\n",
    "z.columns = z.columns.str.lower()\n",
    "print(z)\n",
    "#-----This is setting up things to export a map---------------------------------------------------------------\n",
    "sorted_annual_table = query_and_sort_annual_table(y_rp, field_to_sort='weight_rp', number_of_rows=y_rows)\n",
    "sorted_annual_table.iloc[:, 1:] = sorted_annual_table.iloc[:, 1:].round(1)\n",
    "sorted_annual_table = sorted_annual_table.reset_index(drop=True)\n",
    "\n",
    "filtered_colors = filtered_info['Color'].tolist()\n",
    "lineplot_colors = filtered_colors[1:]\n",
    "image_save_returnperiodtable(z, color_scheme, insurance_attribute, country, method, return_period, value_field, aggregation=aggregation, figure_height=1.75, figure_width=2.5,) #input_table = Jerry_table\n",
    "    #image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info_upto30, country, 'Aggregation', 'Cell', year_to_eval, '3', figure_height=3.5, figure_width=3.5)\n",
    "display(sorted_annual_table)\n",
    "plot_and_colorize_annual_table(filtered_y_rp___count, country, method, return_period, value_field, aggregation, '2020', 5.5, 4.0, annual_event)\n",
    "plot_histogram_with_lineplot_4(x, filtered_info, country, method, return_period, aggregation=aggregation, value_field=value_field, labels_to_omit='Below 1 in 10 year', figure_height=3.0, figure_width=6.0)\n",
    "\n",
    "\n",
    "gdf = retrieve_geodataframe(aggregation)\n",
    "for annual_event in range(min(10, y_rows)):\n",
    "        print(f'map for: {annual_event}')\n",
    "        year_to_eval = define_year_to_map(sorted_annual_table, annual_event)\n",
    "        gdf_merged = query_geodataframe(gdf, x, year_to_eval, field=value_field)\n",
    "        image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info, country, method, return_period, year_to_eval, value_field, aggregation, field=value_field, country_label='no', figure_height=3.5, figure_width=3.5, year_id=annual_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"The current Working Directory is:\", current_directory)\n",
    "\n",
    "# Get the path to the base directory (VIEWS_FAO_index)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(f'The base directory will be set to: {base_dir}')\n",
    "\n",
    "# Add the base directory to sys.path\n",
    "sys.path.insert(0, base_dir)\n",
    "\n",
    "from src.utils.universal_functions.setup.build_directory import ensure_directory_exists\n",
    "\n",
    "def find_file_with_string(folder_path, search_string):\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the search_string is in the filename\n",
    "        if search_string in filename:\n",
    "            return filename\n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This gives the formatting criteria for OPTION 2 Slides (1 & 2)\n",
    "\"\"\"\n",
    "\n",
    "def map_top_years(country, method, returnperiodmethod, summary_text, aggregation='0'): \n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "    font_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/OpenSans-VariableFont.ttf'\n",
    "    template_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/PRIO Layout A Sept2.png'\n",
    "    template_image = Image.open(template_path)\n",
    "\n",
    "    aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "    if aggregation == '1':\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + aggregation_string +  '/table_png/'\n",
    "        print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "        #---\n",
    "        output_path = base_directory + '/files/Layouts/' + country + '/' \n",
    "\n",
    "    else:\n",
    "        aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string   + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/table_png/'\n",
    "        print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "        #---\n",
    "        output_path = base_directory + '/files/Layouts/' + country + '/' \n",
    "\n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    #look for the graphic with the appropriate dimensions:\n",
    "    #Map 1\n",
    "    map_filename_0 = find_file_with_string(map_path, 'conflict year 0 ') # looking for a 3.5 x 3.5 map \n",
    "    print(map_filename_0)\n",
    "\n",
    "    year__0 = re.search(r\"\\b\\d{4}\\b\", map_filename_0)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__0:\n",
    "        year__0 = str(int(year__0.group()))\n",
    "        print(year__0)\n",
    "\n",
    "    #Map 2\n",
    "    map_filename_1 = find_file_with_string(map_path, 'conflict year 1 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_1)\n",
    "\n",
    "    year__1 = re.search(r\"\\b\\d{4}\\b\", map_filename_1)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__1:\n",
    "        year__1 = str(int(year__1.group()))\n",
    "        print(year__1)\n",
    "\n",
    "    #Map 3\n",
    "    map_filename_2 = find_file_with_string(map_path, 'conflict year 2 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2)\n",
    "\n",
    "    year__2 = re.search(r\"\\b\\d{4}\\b\", map_filename_2)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__2:\n",
    "        year__2 = str(int(year__2.group()))\n",
    "        print(year__2)\n",
    "\n",
    "    #Map 4\n",
    "    map_filename_3 = find_file_with_string(map_path, 'conflict year 3 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_3)\n",
    "\n",
    "    year__3 = re.search(r\"\\b\\d{4}\\b\", map_filename_3)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__3:\n",
    "        year__3 = str(int(year__3.group()))\n",
    "        print(year__3)\n",
    "\n",
    "    #Map 5\n",
    "    map_filename_4 = find_file_with_string(map_path, 'conflict year 4 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_4)\n",
    "\n",
    "    year__4 = re.search(r\"\\b\\d{4}\\b\", map_filename_4)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__4:\n",
    "        year__4 = str(int(year__4.group()))\n",
    "        print(year__4)\n",
    "\n",
    "    #Map 6\n",
    "    map_filename_5 = find_file_with_string(map_path, 'conflict year 5 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_5)\n",
    "\n",
    "    year__5 = re.search(r\"\\b\\d{4}\\b\", map_filename_5)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__5:\n",
    "        year__5 = str(int(year__5.group()))\n",
    "        print(year__5)\n",
    "\n",
    "    #Map 7\n",
    "    map_filename_6 = find_file_with_string(map_path, 'conflict year 6 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_6)\n",
    "\n",
    "    year__6 = re.search(r\"\\b\\d{4}\\b\", map_filename_6)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__6:\n",
    "        year__6 = str(int(year__6.group()))\n",
    "        print(year__6)\n",
    "\n",
    "    #Map 8\n",
    "    map_filename_7 = find_file_with_string(map_path, 'conflict year 7 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_7)\n",
    "\n",
    "    year__7 = re.search(r\"\\b\\d{4}\\b\", map_filename_7)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__7:\n",
    "        year__7 = str(int(year__7.group()))\n",
    "        print(year__7)\n",
    "\n",
    "    #Map 9\n",
    "    map_filename_8 = find_file_with_string(map_path, 'conflict year 8 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_8)\n",
    "\n",
    "    year__8 = re.search(r\"\\b\\d{4}\\b\", map_filename_8)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__8:\n",
    "        year__8 = str(int(year__8.group()))\n",
    "        print(year__8)\n",
    "\n",
    "    #Map 10\n",
    "    map_filename_9 = find_file_with_string(map_path, 'conflict year 9 ') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_9)\n",
    "\n",
    "    year__9 = re.search(r\"\\b\\d{4}\\b\", map_filename_9)\n",
    "        # Convert the match to an integer and print\n",
    "    if year__9:\n",
    "        year__9 = str(int(year__9.group()))\n",
    "        print(year__9)\n",
    "\n",
    "    annual_table_filename = find_file_with_string(annual_table_path, '4.0x5.5') #  looking for a 2.5 x 1.75 map 4_0x5_5\n",
    "    print(annual_table_filename)\n",
    "    return_period_table_fileneame = find_file_with_string(return_period_table_path, '2.5x1.8')\n",
    "    print(return_period_table_fileneame)\n",
    "    return_period_lineplot_fileneame = find_file_with_string(return_period_lineplot_path, '6.0x3.0')\n",
    "    print(return_period_lineplot_fileneame)\n",
    "\n",
    "\n",
    "\n",
    "    # Load the template image\n",
    "    #template_path = 'Slide 1 Option B Template.png'\n",
    "\n",
    "    template_image = template_image.resize((1620, 915), Image.Resampling.LANCZOS)\n",
    "    draw = ImageDraw.Draw(template_image)\n",
    "\n",
    "    #template_image = Image.open(template_path)\n",
    "    #draw = ImageDraw.Draw(template_image)\n",
    "\n",
    "    # # Define grid parameters\n",
    "    # grid_spacing = 50  # Adjust the spacing as needed\n",
    "    # grid_color = \"blue\"\n",
    "    # grid_width = 1\n",
    "\n",
    "    # # Define the font for the grid labels\n",
    "    # font = ImageFont.load_default()\n",
    "\n",
    "    # # Get the dimensions of the template image\n",
    "    # width, height = template_image.size\n",
    "\n",
    "    # # Draw the grid\n",
    "    # for x in range(0, width, grid_spacing):\n",
    "    #     draw.line([(x, 0), (x, height)], fill=grid_color, width=grid_width)\n",
    "    #     draw.text((x, 0), str(x), fill=grid_color, font=font)\n",
    "    # for y in range(0, height, grid_spacing):\n",
    "    #     draw.line([(0, y), (width, y)], fill=grid_color, width=grid_width)\n",
    "    #     draw.text((0, y), str(y), fill=grid_color, font=font)\n",
    "\n",
    "    # Define the positions and sizes for placeholders\n",
    "    positions = [\n",
    "#Main map\n",
    "        {'position': (425, 200), 'size': (400, 350), 'label': year__0,'filename': map_filename_0, 'folder': map_path, 'font_size':14},      # Main Map\n",
    "#map grid 3x3\n",
    "        {'position': (925, 175), 'size': (200, 200), 'label': year__1,'filename': map_filename_1, 'folder': map_path, 'font_size': 10},       # Year 1\n",
    "        {'position': (925, 400), 'size': (200, 200), 'label': year__4,'filename': map_filename_4, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (925, 625), 'size': (200, 200), 'label': year__7,'filename': map_filename_7, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1150, 175), 'size': (200, 200), 'label': year__2,'filename': map_filename_2, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1150, 400), 'size': (200, 200), 'label': year__5,'filename': map_filename_5, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1150, 625), 'size': (200, 200), 'label': year__8,'filename': map_filename_8, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1375, 175), 'size': (200, 200), 'label': year__3,'filename': map_filename_3, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1375, 400), 'size': (200, 200), 'label': year__6,'filename': map_filename_6, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "        {'position': (1375, 625), 'size': (200, 200), 'label': year__9,'filename': map_filename_9, 'folder': map_path, 'font_size':10},       # Year 1\n",
    "#annual report table\n",
    "        {'position': (50, 200), 'size': (300, 635), 'label': '','filename': annual_table_filename, 'folder': annual_table_path, 'font_size':9},       # Year 1\n",
    "#insurance table\n",
    "        {'position': (425, 625), 'size': (400, 200), 'label': '','filename': return_period_table_fileneame, 'folder': return_period_table_path,'font_size':1},     # Payout Legend \n",
    "       \n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "\n",
    "    ]\n",
    "\n",
    "        # Define the positions and sizes for text boxes\n",
    "    text_boxes = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        #{'position': (65, 215), 'size': (270, 325), 'label':  summary_text,'font_size': 15}\n",
    "    ]\n",
    "\n",
    "    title = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        {'position': (50, 25), 'size': (600, 125), 'label':  country, 'font_size': 92}\n",
    "    ]\n",
    "\n",
    "    title_boxes = [\n",
    "        {'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        {'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        #{'position': (50, 200), 'size': (300, 350), 'label': '','font_size': 32},     # empty text box\n",
    "\n",
    "        #{'position': (50, 175), 'size': (300, 500), 'label':  summary_text,'font_size': 14}\n",
    "    ]\n",
    "\n",
    "        # # Load and paste the images onto the template\n",
    "    for pos in positions:\n",
    "        if 'folder' in pos and 'filename' in pos:\n",
    "                img_path = os.path.join(pos['folder'], pos['filename'])\n",
    "                if os.path.exists(img_path):\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(pos['size'], Image.Resampling.LANCZOS)\n",
    "                    template_image.paste(img, pos['position'])\n",
    "                else:\n",
    "                    print(f\"Image {pos['filename']} not found in {pos['folder']}\")\n",
    "        else:\n",
    "                print(f\"Missing 'folder' or 'filename' in: {pos}\")\n",
    "\n",
    "# Add text boxes\n",
    "    # Add text boxes\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    for title_b in title_boxes:\n",
    "        x, y = title_b['position']\n",
    "        w, h = title_b['size']\n",
    "        label = title_b['label']\n",
    "        font_size = title_b['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "            # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    #     Draw a rectangle around the text box area with a dark grey background\n",
    "        draw.rectangle([x, y, x + w, y + h], fill=\"darkgrey\", outline=\"black\", width=2)\n",
    "\n",
    "    #     # Calculate the bounding box of the text\n",
    "        text_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "         # Calculate the position to center the text\n",
    "        text_x = x + (w - text_width) / 2\n",
    "        text_y = y + (h - text_height) / 3\n",
    "\n",
    "    #     # Draw the text centered in the box with white color\n",
    "        draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for t in title:\n",
    "        x, y = t['position']\n",
    "        w, h = t['size']\n",
    "        label = t['label']\n",
    "        font_size = t['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw a rectangle around the text box area with a dark grey background\n",
    "        #draw.rectangle([x, y, x + w, y + h], fill=\"grey\", outline=\"white\", width=2)\n",
    "        #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "        # Wrap the text to fit inside the box\n",
    "        wrapped_text = []\n",
    "        words = label.split()\n",
    "        line = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Add the word to the line and check if it fits\n",
    "            test_line = line + word + \" \"\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "            if test_width <= w:\n",
    "                line = test_line\n",
    "            else:\n",
    "                # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "                wrapped_text.append(line.strip())\n",
    "                line = word + \" \"\n",
    "\n",
    "        # Add the last line\n",
    "        wrapped_text.append(line.strip())\n",
    "\n",
    "        # Draw the text line by line, adjusting the position\n",
    "        current_y = y\n",
    "        for line in wrapped_text:\n",
    "            draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "            current_y += font_size  # Move to the next line\n",
    "\n",
    "        # Ensure that the text doesn't overflow the box height\n",
    "        if current_y > y + h:\n",
    "            print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    for box in text_boxes:\n",
    "        x, y = box['position']\n",
    "        w, h = box['size']\n",
    "        label = box['label']\n",
    "        font_size = box['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw a rectangle around the text box area with a dark grey background\n",
    "        #draw.rectangle([x, y, x + w, y + h], fill=\"white\", outline=\"white\", width=2)\n",
    "        #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "        # Wrap the text to fit inside the box\n",
    "        wrapped_text = []\n",
    "        words = label.split()\n",
    "        line = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Add the word to the line and check if it fits\n",
    "            test_line = line + word + \" \"\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "            if test_width <= w:\n",
    "                line = test_line\n",
    "            else:\n",
    "                # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "                wrapped_text.append(line.strip())\n",
    "                line = word + \" \"\n",
    "\n",
    "        # Add the last line\n",
    "        wrapped_text.append(line.strip())\n",
    "\n",
    "        # Draw the text line by line, adjusting the position\n",
    "        current_y = y\n",
    "        for line in wrapped_text:\n",
    "            draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "            current_y += font_size  # Move to the next line\n",
    "\n",
    "        # Ensure that the text doesn't overflow the box height\n",
    "        if current_y > y + h:\n",
    "            print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "\n",
    "    # Draw rectangles at specified positions\n",
    "    for pos in positions:\n",
    "        x, y = pos['position']\n",
    "        w, h = pos['size']\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"black\", width=3)\n",
    "        draw.text((x, y - 20), pos['label'], fill=\"black\")\n",
    "        font_size = pos['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Save and show the template with marked positions\n",
    "    #marked_template_path = '/Users/gbenz/Desktop/tmp.png'\n",
    "            \n",
    "        # Save the final image with a specified filename\n",
    "            \n",
    "\n",
    "    output_filename = os.path.join(output_path, f'{country}_{method}_{returnperiodmethod}_{aggregation}x{aggregation}.png')\n",
    "    print(f'file saved to: {output_filename}')\n",
    "    template_image.save(output_filename)\n",
    "    template_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_top_years(country, method, return_period, summary_text, aggregation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_event_cat_rp_with_an_summary_tables:\n",
    "\n",
    "#### Preconditions for setting up the mapping function `map_event_cat_rp_with_an_summary_tables`\n",
    "Gives Top 10 years of conflict\n",
    "\n",
    "\n",
    "Unlike preceding options, this function is still in development therefore still hosted locally in the notebook and not saved as .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from src.utils.universal_functions.setup.build_directory import float_to_custom_string, ensure_directory_exists\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_histogram_with_lineplot_4(df, info_dataframe, country, method, returnperiodmethod, aggregation, value_field='percapita_100k', labels_to_omit='Below 1 in 10 year', figure_height=3.0, figure_width=6.0, histogram='on', horizontal_rp_expected= 'on'):\n",
    "    figure_height_str = float_to_custom_string(figure_height)\n",
    "    figure_width_str = float_to_custom_string(figure_width)\n",
    "\n",
    "    aggregation_string = str(aggregation) + 'x' + str(aggregation)\n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "\n",
    "    if aggregation == '1':\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  +  '/plot_png'\n",
    "    else:\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/plot_png'\n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    output_file = os.path.join(output_path, f'{country} Annual Return Period LinePlot with dimensions {figure_width_str}x{figure_height_str}.png')\n",
    "\n",
    "    # Calculate histogram data\n",
    "    df_histogram = calculate_histogram_data(df)\n",
    "\n",
    "    if 'pg_id' in x.columns:\n",
    "    # Column exists, perform your action here\n",
    "        unique_pg_id_count = x['pg_id'].nunique()\n",
    "        print(unique_pg_id_count)\n",
    "\n",
    "        expected_100_rp = unique_pg_id_count * 0.01\n",
    "        print(expected_100_rp)\n",
    "\n",
    "        expected_50_rp = unique_pg_id_count * 0.02\n",
    "        print(expected_50_rp)\n",
    "\n",
    "    \n",
    "    elif 'priogrid_gid' in x.columns:\n",
    "    # Column exists, perform your action here\n",
    "        unique_pg_id_count = x['priogrid_gid'].nunique()\n",
    "        print(unique_pg_id_count)\n",
    "\n",
    "        expected_100_rp = unique_pg_id_count * 0.01\n",
    "        print(expected_100_rp)\n",
    "\n",
    "        expected_50_rp = unique_pg_id_count * 0.02\n",
    "        print(expected_50_rp)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        unique_pg_id_count = x['GIS__Index'].nunique()\n",
    "        print(unique_pg_id_count)\n",
    "\n",
    "        expected_100_rp = unique_pg_id_count * 0.01\n",
    "        print(expected_100_rp)\n",
    "\n",
    "        expected_50_rp = unique_pg_id_count * 0.02\n",
    "        print(expected_50_rp)\n",
    "    \n",
    "\n",
    "    # Initialize the list of labels to omit\n",
    "    list_of_labels_to_omit = []\n",
    "    for index, row in info_dataframe.iterrows():\n",
    "        if row['Range'].startswith('0.0'):\n",
    "            list_of_labels_to_omit.append(row['Label'])\n",
    "    list_of_labels_to_omit.append(labels_to_omit)\n",
    "\n",
    "    # Begin plotting\n",
    "    fig, ax1 = plt.subplots(figsize=(figure_width, figure_height))\n",
    "\n",
    "    # Plot the line plot (triggers) on the primary axis (ax1)\n",
    "    results = {'year': [], 'Label': [], 'count': []}\n",
    "    for year in df['year'].unique():\n",
    "        for _, row in info_dataframe.iterrows():\n",
    "            range_start, range_end = map(float, row['Range'].split(' - '))\n",
    "            label = row['Label']\n",
    "\n",
    "            count = df[(df['year'] == year) & \n",
    "                       (df[value_field] >= range_start) & \n",
    "                       (df[value_field] < range_end)].shape[0]\n",
    "\n",
    "            results['year'].append(year)\n",
    "            results['Label'].append(label)\n",
    "            results['count'].append(count)\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.merge(info_dataframe[['Label', 'Color']], on='Label', how='left')\n",
    "\n",
    "    # Filter out labels to omit\n",
    "    results_df = results_df[~results_df['Label'].isin(list_of_labels_to_omit)]\n",
    "\n",
    "    # Sort the DataFrame by year\n",
    "    results_df = results_df.sort_values(by='year')\n",
    "\n",
    "    # Plotting the line plot (for return period triggers) on the left axis (ax1)\n",
    "    line_width = 1.2\n",
    "    labels = results_df['Label'].unique()\n",
    "    \n",
    "    for label in labels:\n",
    "        subset = results_df[results_df['Label'] == label]\n",
    "        ax1.plot(subset['year'], subset['count'], label=label, color=subset['Color'].iloc[0], linewidth=line_width)\n",
    "\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Count of return period triggers', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "    # Set integer ticks on ax1\n",
    "    ax1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    if horizontal_rp_expected == 'on':\n",
    "        ax1.axhline(y=expected_100_rp, color='red', linestyle='--', linewidth=.5)\n",
    "        ax1.axhline(y=expected_50_rp, color='purple', linestyle='--', linewidth=.5)\n",
    "\n",
    "\n",
    "    if histogram == 'on':\n",
    "        # Create the second y-axis for the histogram (per capita fatalities) on the right\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        # Plot histogram\n",
    "        ax2.bar(df_histogram['year'], df_histogram['average_value'], color='gray', label='Per Capita Fatalities', alpha=0.25)\n",
    "        ax2.set_ylabel('Per capita fatalities (100k)', color='gray')\n",
    "        ax2.tick_params(axis='y', labelcolor='gray')\n",
    "\n",
    "        # Adjust the y-axis limits for ax1 and ax2\n",
    "        ax1_y_lim = ax1.get_ylim()\n",
    "        ax2_y_lim = ax2.get_ylim()\n",
    "\n",
    "        ax1.set_ylim(bottom=0, top=ax1_y_lim[1] * 1.05)\n",
    "        ax2.set_ylim(bottom=0, top=ax2_y_lim[1] * 1.05)\n",
    "\n",
    "    else:\n",
    "        # If histogram is off, adjust only the primary axis (ax1)\n",
    "        ax1_y_lim = ax1.get_ylim()\n",
    "        ax1.set_ylim(bottom=0, top=ax1_y_lim[1] * 1.05)\n",
    "\n",
    "    # Adjust the padding and margins to ensure alignment\n",
    "    fig.subplots_adjust(left=0.1, right=0.9, bottom=0.15, top=0.85)\n",
    "\n",
    "    # Add a legend\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "\n",
    "    # Set the title of the plot\n",
    "    plt.title(f'Return period thresholds over time')\n",
    "\n",
    "\n",
    "\n",
    "    # Add the horizontal line with a dotted style\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_save_ind_annual_rp_contextvalues\n",
    "\n",
    "from src.utils.universal_functions.setup.build_directory import float_to_custom_string, ensure_directory_exists\n",
    "\n",
    "#import: query_and_sort_annual_table from universal folder / FAO / generate output tables\n",
    "from src.utils.universal_functions.setup.build_directory import float_to_custom_string, ensure_directory_exists\n",
    "\n",
    "\n",
    "#from src.utils.functions_for_graphics.individual_graphics.map_helper.manipulate_tables_for_mapping import query_and_sort_annual_table, provide_values_at_input_return_periods, retrieve_geodataframe, define_year_to_map, query_geodataframe\n",
    "from src.utils.functions_for_graphics.layout_formats.rgb import rgb_to_hex\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "def image_save_ind_annual_rp_contextvalues(input_table, colors, column_to_apply_symbology, country, year, method, returnperiodmethod, aggregation='1', figure_height=5.0, figure_width=2.5): #input_table = Jerry_table\n",
    "\n",
    "    #Feedback on Sept 05 was to make column names lower case. The column_to_apply_symbology must now also be lowercase:\n",
    "    #column_to_apply_symbology = column_to_apply_symbology.lower()\n",
    "\n",
    "    if column_to_apply_symbology == 'Return Period':\n",
    "        column_to_apply_symbology = 'Return period'\n",
    "    \n",
    "    if column_to_apply_symbology == 'return period':\n",
    "        column_to_apply_symbology = 'Return period'\n",
    "\n",
    "    figure_height_str = float_to_custom_string(figure_height)\n",
    "    figure_width_str = float_to_custom_string(figure_width)\n",
    "\n",
    "    aggregation_string = str(aggregation) + 'x' + str(aggregation)\n",
    "\n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "    if aggregation == '1':\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'table_png/percentile and payout table/'\n",
    "    else:\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/percentile and payout table/'\n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    columns_to_remove = ['pg_id','year', 'Label']\n",
    "    columns_to_convert_int= ['Fatalities', 'Population', 'Return period']\n",
    "    columns_to_rename = {\n",
    "    'percapita_100k': 'Per capita',\n",
    "    'perca_Mean': 'Fatalities P.C',\n",
    "    'percentile': 'Percentile',\n",
    "    'return period': 'Return period',\n",
    "    'Return Period': 'Return period',\n",
    "    'payout rate': 'Payout rate',\n",
    "    'occurrence': 'Observations',\n",
    "    'observations': 'Observations',\n",
    "    'payout': 'Payout',\n",
    "    'closest r.p.': 'Closest R.P.',\n",
    "    'pop_gpw_sum': 'Population',\n",
    "    'fatalities_sum': 'Fatalities',\n",
    "\n",
    "    # Add more column mappings as needed\n",
    "    }\n",
    "\n",
    "    df = input_table.rename(columns={col: new_col for col, new_col in columns_to_rename.items() if col in input_table.columns})\n",
    "    #only interested in rows that correspond with a R.P\n",
    "    df = df.dropna(subset=columns_to_convert_int)\n",
    "    df[columns_to_convert_int] = df[columns_to_convert_int].apply(lambda x: x.astype(int))\n",
    "    df = df.drop(columns=df.columns.intersection(columns_to_remove))\n",
    "\n",
    "    light_grey = rgb_to_hex((211, 211, 211))  # Light grey color\n",
    "    dark_grey = rgb_to_hex((64, 64, 64))  # Dark grey color\n",
    "\n",
    "    # Plot the table\n",
    "    fig, ax = plt.subplots(figsize=(figure_width, figure_height))  # Size in inches (width, height)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Create the table\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "\n",
    "    # Adjust table properties\n",
    "    table.auto_set_font_size(False)  # Disable automatic font size\n",
    "    table.set_fontsize(8)  # Set font size\n",
    "\n",
    "    # Calculate cell widths and heights to fit the figure size exactly\n",
    "    n_rows, n_cols = df.shape\n",
    "    cell_width = figure_width / n_cols\n",
    "    cell_height = figure_height / (n_rows + 1)  # +1 for the header row\n",
    "\n",
    "    # Set the size of each cell\n",
    "    for i in range(n_rows + 1):\n",
    "        for j in range(n_cols):\n",
    "            table[(i, j)].set_width(cell_width)\n",
    "            table[(i, j)].set_height(cell_height)\n",
    "            table[(i, j)].set_fontsize(21)  # Set the font size for each cell\n",
    "\n",
    "\n",
    "    for j in range(n_cols):\n",
    "        table[(0, j)].set_facecolor(dark_grey)\n",
    "        table[(0, j)].set_text_props(color='white')\n",
    "\n",
    "    # Apply colors to the cells based on the 'percentile' column\n",
    "    percentile_col_idx = df.columns.get_loc(column_to_apply_symbology)\n",
    "    for i in range(1, n_rows + 1):  # Skip header row\n",
    "        percentile_value = df.iloc[i - 1, percentile_col_idx]\n",
    "        if percentile_value in colors:\n",
    "            color = colors[percentile_value]\n",
    "        else:\n",
    "            color = light_grey\n",
    "        for j in range(n_cols):\n",
    "            table[(i, j)].set_facecolor(color)\n",
    "            table[(i, j)].set_text_props(color='white' if color != light_grey else 'black')\n",
    "\n",
    "\n",
    "    output_file = output_path + 'individual_annual_context' + country +f'_{year}_' + 'with_dimensions_' + figure_width_str + 'x' + figure_height_str + '.png'\n",
    "    # Save the table as PNG with exact size and no white space\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "    # Show the table plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for mapping \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"The current Working Directory is:\", current_directory)\n",
    "\n",
    "# Get the path to the base directory (VIEWS_FAO_index)\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "print(f'The base directory will be set to: {base_dir}')\n",
    "\n",
    "# Add the base directory to sys.path\n",
    "sys.path.insert(0, base_dir)\n",
    "\n",
    "from src.utils.universal_functions.setup.build_directory import ensure_directory_exists\n",
    "\n",
    "def find_file_with_string(folder_path, search_string):\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the search_string is in the filename\n",
    "        if search_string in filename:\n",
    "            return filename\n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This gives the formatting criteria for OPTION 2 Slides (1 & 2)\n",
    "\"\"\"\n",
    "\n",
    "def map_event_cat_rp_with_an_summary_tables(country, method, returnperiodmethod, year_datastart, year_dataend, aggregation='0', gridlines='no'): \n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "    font_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/OpenSans-VariableFont.ttf'\n",
    "    template_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/event_cat_rd_template.png'\n",
    "    template_image = Image.open(template_path)\n",
    "\n",
    "\n",
    "    if aggregation == '1':\n",
    "        aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        \n",
    "        #annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod   + '/table_png/'\n",
    "        #print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/table_png/percentile and payout table/'\n",
    "        print('return period table path:')\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "\n",
    "        output_path = base_directory + '/files/Layouts/' + country + '/' \n",
    "\n",
    "    else:\n",
    "        aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string   + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        #annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/'\n",
    "        #print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "        #---\n",
    "\n",
    "    output_path = base_directory + '/files/Layouts/event_cat_rd/' \n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    #look for the graphic with the appropriate dimensions:\n",
    "    #Map 1\n",
    "    map_filename_0 = find_file_with_string(map_path, 'conflict year 0') # looking for a 3.5 x 3.5 map \n",
    "    print(f'located map rank1: {map_filename_0}')\n",
    "\n",
    "    year__0 = re.search(r\"\\b\\d{4}\\b\", map_filename_0)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__0:\n",
    "        year__0 = str(int(year__0.group()))\n",
    "        print(year__0)\n",
    "\n",
    "    #Map 2\n",
    "    map_filename_1 = find_file_with_string(map_path, 'conflict year 1 ') # looking for a 3.5 x 3.5 map\n",
    "    print(f'located map rank 2: {map_filename_1}')\n",
    "\n",
    "    year__1 = re.search(r\"\\b\\d{4}\\b\", map_filename_1)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__1:\n",
    "        year__1 = str(int(year__1.group()))\n",
    "        print(year__1)\n",
    "\n",
    "    map_filename_2 = find_file_with_string(map_path, 'conflict year 2 ') # looking for a 3.5 x 3.5 map\n",
    "    print(f'located map rank 3: {map_filename_2}')\n",
    "\n",
    "    year__2 = re.search(r\"\\b\\d{4}\\b\", map_filename_2)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__2:\n",
    "        year__2 = str(int(year__2.group()))\n",
    "        print(year__2)\n",
    "\n",
    "    \n",
    "\n",
    "    #Map 3\n",
    "    map_filename_2000 = find_file_with_string(return_period_table_path, year__0) # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2000)    \n",
    "    #Map 4\n",
    "    map_filename_2010 = find_file_with_string(return_period_table_path, year__1) # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2010)\n",
    "    #Map 5\n",
    "    map_filename_2020 = find_file_with_string(return_period_table_path, year__2) # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2020)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #annual_table_filename = find_file_with_string(annual_table_path, '4.0x5.5') #  looking for a 2.5 x 1.75 map 4_0x5_5\n",
    "    #print(f'located lineplot file in folder: {annual_table_filename}')\n",
    "\n",
    "    return_period_table_fileneame = find_file_with_string(return_period_table_path, '2.5x1.8')\n",
    "    print(f'located lineplot file in folder: {return_period_table_fileneame}')\n",
    "    \n",
    "    return_period_lineplot_fileneame = find_file_with_string(return_period_lineplot_path, '6.0x3.0')\n",
    "    print(f'located lineplot file in folder: {return_period_lineplot_fileneame}')\n",
    "\n",
    "\n",
    "\n",
    "    # Load the template image\n",
    "    #template_path = 'Slide 1 Option B Template.png'\n",
    "\n",
    "    template_image = template_image.resize((1620, 915), Image.Resampling.LANCZOS)\n",
    "    draw = ImageDraw.Draw(template_image)\n",
    "\n",
    "\n",
    "\n",
    "    # Define grid parameters\n",
    "    grid_spacing = 50  # Adjust the spacing as needed\n",
    "    grid_color = \"blue\"\n",
    "    grid_width = 1\n",
    "\n",
    "    # Define the font for the grid labels\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Get the dimensions of the template image\n",
    "    width, height = template_image.size\n",
    "\n",
    "    if gridlines == 'yes':\n",
    "    # Draw the grid\n",
    "        for x in range(0, width, grid_spacing):\n",
    "            draw.line([(x, 0), (x, height)], fill=grid_color, width=grid_width)\n",
    "            draw.text((x, 0), str(x), fill=grid_color, font=font)\n",
    "        for y in range(0, height, grid_spacing):\n",
    "            draw.line([(0, y), (width, y)], fill=grid_color, width=grid_width)\n",
    "            draw.text((0, y), str(y), fill=grid_color, font=font)\n",
    "\n",
    "    # Define the positions and sizes for placeholders\n",
    "    positions = [\n",
    "\n",
    "#These are the top 2 Conflict years\n",
    "        {'position': (745, 110), 'size': (265, 275), 'label': '','filename': map_filename_0, 'folder': map_path, 'font_size': 9, 'line_width': 3},       # Year 1\n",
    "        {'position': (1025, 110), 'size': (265, 275), 'label': '','filename': map_filename_1, 'folder': map_path, 'font_size':9,'line_width': 3},       # Year 1\n",
    "        {'position': (1305, 110), 'size': (275, 275), 'label': '','filename': map_filename_2, 'folder': map_path, 'font_size':9,'line_width': 3},       # Year 1\n",
    "\n",
    "#These are the selected conflict years\n",
    "        {'position': (745, 450), 'size': (265, 375), 'label': '','filename': map_filename_2000, 'folder': return_period_table_path, 'font_size':9, 'line_width': 3},       # Year 1\n",
    "        {'position': (1025, 450), 'size': (265, 375), 'label': '','filename': map_filename_2010, 'folder': return_period_table_path, 'font_size':9, 'line_width': 3},       # Year 1\n",
    "        {'position': (1305, 450), 'size': (265, 375), 'label': '','filename': map_filename_2020, 'folder': return_period_table_path, 'font_size':9, 'line_width': 3},       # Year 1\n",
    "\n",
    "\n",
    "        {'position': (50, 225), 'size': (550, 275), 'label': '','filename': return_period_table_fileneame, 'folder': return_period_table_path,'font_size':1, 'line_width': 3},     # Payout Legend \n",
    "       \n",
    "        #{'position': (375, 500), 'size': (250, 375), 'label': '','filename': annual_table_filename, 'folder': annual_table_path,'font_size':1},     # Payout Legend \n",
    "        {'position': (50, 550), 'size': (550, 300), 'label': '','filename': return_period_lineplot_fileneame, 'folder': return_period_lineplot_path,'font_size':1, 'line_width': 0},     # Payout Legend \n",
    "\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "\n",
    "    ]\n",
    "\n",
    "        # Define the positions and sizes for text boxes\n",
    "    text_boxes = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        #{'position': (65, 215), 'size': (270, 325), 'label':  summary_text,'font_size': 15}\n",
    "    ]\n",
    "\n",
    "    title = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        {'position': (50, 25), 'size': (600, 125), 'label':  country, 'font_size': 92}\n",
    "    ]\n",
    "\n",
    "    title_boxes = [\n",
    "        {'position': (50, 175), 'size': (550, 35), 'label': 'Return period labels and threshold values','font_size': 18, 'background_color': 'darkgrey', 'line_width': 2, 'text_color': 'white'},     # Payout Legend Title\n",
    "\n",
    "        {'position': (800, 385), 'size': (150, 35), 'label': year__0,'font_size': 24, 'background_color': None, 'line_width': 0, 'text_color': 'black'},     # Year Label for Top year\n",
    "        {'position': (1085, 385), 'size': (150, 35), 'label': year__1,'font_size': 24, 'background_color': None, 'line_width': 0, 'text_color': 'black'},     # Year Label for Top 2 year\n",
    "        {'position': (1355, 385), 'size': (150, 35), 'label': year__2,'font_size': 24, 'background_color': None, 'line_width': 0, 'text_color': 'black'},     # Year Label for Top 3 year\n",
    "    ]\n",
    "\n",
    "        # # Load and paste the images onto the template\n",
    "    for pos in positions:\n",
    "        if 'folder' in pos and 'filename' in pos:\n",
    "                img_path = os.path.join(pos['folder'], pos['filename'])\n",
    "                if os.path.exists(img_path):\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(pos['size'], Image.Resampling.LANCZOS)\n",
    "                    template_image.paste(img, pos['position'])\n",
    "                else:\n",
    "                    print(f\"Image {pos['filename']} not found in {pos['folder']}\")\n",
    "        else:\n",
    "                print(f\"Missing 'folder' or 'filename' in: {pos}\")\n",
    "\n",
    "# Add text boxes\n",
    "    # Add text boxes\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    for title_b in title_boxes:\n",
    "        x, y = title_b['position']\n",
    "        w, h = title_b['size']\n",
    "        label = title_b['label']\n",
    "        font_size = title_b['font_size']  # Get the font size from the dictionary\n",
    "        background_color = title_b['background_color']  # Get the font size from the dictionary\n",
    "        line_width = title_b['line_width']\n",
    "        text_color = title_b['text_color']\n",
    "            # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    #     Draw a rectangle around the text box area with a dark grey background\n",
    "        draw.rectangle([x, y, x + w, y + h], fill= background_color, outline=\"black\", width=line_width)\n",
    "\n",
    "    #     # Calculate the bounding box of the text\n",
    "        text_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "         # Calculate the position to center the text\n",
    "        text_x = x + (w - text_width) / 2\n",
    "        text_y = y + (h - text_height) / 3\n",
    "\n",
    "    #     # Draw the text centered in the box with white color\n",
    "        draw.text((text_x, text_y), label, fill=text_color, font=font)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for t in title:\n",
    "        x, y = t['position']\n",
    "        w, h = t['size']\n",
    "        label = t['label']\n",
    "        font_size = t['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw a rectangle around the text box area with a dark grey background\n",
    "        #draw.rectangle([x, y, x + w, y + h], fill=\"grey\", outline=\"white\", width=2)\n",
    "        #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "        # Wrap the text to fit inside the box\n",
    "        wrapped_text = []\n",
    "        words = label.split()\n",
    "        line = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Add the word to the line and check if it fits\n",
    "            test_line = line + word + \" \"\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "            if test_width <= w:\n",
    "                line = test_line\n",
    "            else:\n",
    "                # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "                wrapped_text.append(line.strip())\n",
    "                line = word + \" \"\n",
    "\n",
    "        # Add the last line\n",
    "        wrapped_text.append(line.strip())\n",
    "\n",
    "        # Draw the text line by line, adjusting the position\n",
    "        current_y = y\n",
    "        for line in wrapped_text:\n",
    "            draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "            current_y += font_size  # Move to the next line\n",
    "\n",
    "        # Ensure that the text doesn't overflow the box height\n",
    "        if current_y > y + h:\n",
    "            print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "\n",
    "    #Draw rectangles at specified positions\n",
    "    for pos in positions:\n",
    "        x, y = pos['position']\n",
    "        w, h = pos['size']\n",
    "        line_width = pos['line_width']  # Get the line width from the dictionary\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"black\", width=line_width)\n",
    "        draw.text((x, y - 20), pos['label'], fill=\"black\")\n",
    "        font_size = pos['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Save and show the template with marked positions\n",
    "    #marked_template_path = '/Users/gbenz/Desktop/tmp.png'\n",
    "            \n",
    "        # Save the final image with a specified filename\n",
    "    if returnperiodmethod == 'Event year':\n",
    "        return_period_definition = 'bigp'\n",
    "    else:\n",
    "        return_period_definition = 'littlep'\n",
    "\n",
    "\n",
    "    output_filename = os.path.join(output_path, f'event_cat_rp_{country}_{aggregation_string}_{return_period_definition}_{year_datastart}_{year_dataend}.png')\n",
    "    output_filename = output_filename.replace(' ', '_')\n",
    "\n",
    "    print()\n",
    "    print('file saved to:')\n",
    "    print(output_filename)\n",
    "    template_image.save(output_filename)\n",
    "    template_image.show()\n",
    "\n",
    "\n",
    "def map_event_cat_rp_2x2(country, method, returnperiodmethod, aggregation='0', gridlines='no'): \n",
    "\n",
    "    \"\"\" \n",
    "    This was built as a secondary option to map_event_cat_rp. If deployed, user should first consult the map_event_cat_rp code to keep references consistent.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "    font_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/OpenSans-VariableFont.ttf'\n",
    "    template_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/PRIO Layout Method 3_1.png'\n",
    "    template_image = Image.open(template_path)\n",
    "\n",
    "\n",
    "    if aggregation == '1':\n",
    "        aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + aggregation_string + '/table_png/'\n",
    "        print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/table_png/percentile and payout table/'\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "        #---\n",
    "        output_path = base_directory + '/files/Layouts/' + country + '/' \n",
    "\n",
    "    else:\n",
    "        aggregation_string = aggregation + 'x' + aggregation\n",
    "\n",
    "        map_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string   + '/' + 'map_png/'\n",
    "        print(map_path)\n",
    "        annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/'\n",
    "        print(annual_table_path)\n",
    "        return_period_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_path)\n",
    "        return_period_lineplot_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'plot_png/'\n",
    "        print(return_period_lineplot_path)\n",
    "        #---\n",
    "        output_path = base_directory + '/files/Layouts/' + country + '/' \n",
    "\n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    #look for the graphic with the appropriate dimensions:\n",
    "    #Map 1\n",
    "    map_filename_0 = find_file_with_string(map_path, 'conflict year 0') # looking for a 3.5 x 3.5 map \n",
    "    print(f'located map rank1: {map_filename_0}')\n",
    "    #Map 2\n",
    "    map_filename_1 = find_file_with_string(map_path, 'conflict year 1 ') # looking for a 3.5 x 3.5 map\n",
    "    print(f'located map rank 2: {map_filename_1}')\n",
    "    #Map 3\n",
    "    map_filename_2010 = find_file_with_string(map_path, '2010') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2010)\n",
    "    #Map 4\n",
    "    map_filename_2020 = find_file_with_string(map_path, '2020') # looking for a 3.5 x 3.5 map\n",
    "    print(map_filename_2020)\n",
    "    #Map 5\n",
    "    #Map 6\n",
    "\n",
    "\n",
    "    annual_table_filename = find_file_with_string(annual_table_path, '4.0x5.5') #  looking for a 2.5 x 1.75 map 4_0x5_5\n",
    "    print(f'located lineplot file in folder: {annual_table_filename}')\n",
    "\n",
    "    return_period_table_fileneame = find_file_with_string(return_period_table_path, '2.5x1.8')\n",
    "    print(f'located lineplot file in folder: {return_period_table_fileneame}')\n",
    "    \n",
    "    return_period_lineplot_fileneame = find_file_with_string(return_period_lineplot_path, '6.0x3.0')\n",
    "    print(f'located lineplot file in folder: {return_period_lineplot_fileneame}')\n",
    "\n",
    "\n",
    "\n",
    "    # Load the template image\n",
    "    #template_path = 'Slide 1 Option B Template.png'\n",
    "\n",
    "    template_image = template_image.resize((1620, 915), Image.Resampling.LANCZOS)\n",
    "    draw = ImageDraw.Draw(template_image)\n",
    "\n",
    "\n",
    "\n",
    "    # Define grid parameters\n",
    "    grid_spacing = 50  # Adjust the spacing as needed\n",
    "    grid_color = \"blue\"\n",
    "    grid_width = 1\n",
    "\n",
    "    # Define the font for the grid labels\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Get the dimensions of the template image\n",
    "    width, height = template_image.size\n",
    "\n",
    "    if gridlines == 'yes':\n",
    "    # Draw the grid\n",
    "        for x in range(0, width, grid_spacing):\n",
    "            draw.line([(x, 0), (x, height)], fill=grid_color, width=grid_width)\n",
    "            draw.text((x, 0), str(x), fill=grid_color, font=font)\n",
    "        for y in range(0, height, grid_spacing):\n",
    "            draw.line([(0, y), (width, y)], fill=grid_color, width=grid_width)\n",
    "            draw.text((0, y), str(y), fill=grid_color, font=font)\n",
    "\n",
    "    # Define the positions and sizes for placeholders\n",
    "    positions = [\n",
    "\n",
    "#These are the top 2 Conflict years\n",
    "        {'position': (765, 110), 'size': (325, 325), 'label': '','filename': map_filename_0, 'folder': map_path, 'font_size': 9, 'line_width': 3},       # Year 1\n",
    "        {'position': (1215, 110), 'size': (325, 325), 'label': '','filename': map_filename_1, 'folder': map_path, 'font_size':9,'line_width': 3},       # Year 1\n",
    "        \n",
    "#These are the selected conflict years\n",
    "        {'position': (765, 505), 'size': (325, 325), 'label': '','filename': map_filename_2010, 'folder': map_path, 'font_size':9, 'line_width': 3},       # Year 1\n",
    "        {'position': (1215, 505), 'size': (325, 325), 'label': '','filename': map_filename_2020, 'folder': map_path, 'font_size':9, 'line_width': 3},       # Year 1\n",
    "\n",
    "        {'position': (50, 225), 'size': (550, 275), 'label': '','filename': return_period_table_fileneame, 'folder': return_period_table_path,'font_size':1, 'line_width': 3},     # Payout Legend \n",
    "       \n",
    "        #{'position': (375, 500), 'size': (250, 375), 'label': '','filename': annual_table_filename, 'folder': annual_table_path,'font_size':1},     # Payout Legend \n",
    "        {'position': (50, 550), 'size': (550, 300), 'label': '','filename': return_period_lineplot_fileneame, 'folder': return_period_lineplot_path,'font_size':1, 'line_width': 0},     # Payout Legend \n",
    "\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "\n",
    "    ]\n",
    "\n",
    "        # Define the positions and sizes for text boxes\n",
    "    text_boxes = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        #{'position': (65, 215), 'size': (270, 325), 'label':  summary_text,'font_size': 15}\n",
    "    ]\n",
    "\n",
    "    title = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        {'position': (50, 25), 'size': (600, 125), 'label':  country, 'font_size': 92}\n",
    "    ]\n",
    "\n",
    "    title_boxes = [\n",
    "        {'position': (50, 175), 'size': (550, 35), 'label': 'Payout Legend','font_size': 18},     # Payout Legend Title\n",
    "        #{'position': (750, 25), 'size': (800, 35), 'label': 'Top Conflict Years','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (750, 450), 'size': (800, 35), 'label': 'Selected Conflict Years','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (50, 200), 'size': (300, 350), 'label': '','font_size': 32},     # empty text box\n",
    "\n",
    "        #{'position': (50, 175), 'size': (300, 500), 'label':  summary_text,'font_size': 14}\n",
    "    ]\n",
    "\n",
    "        # # Load and paste the images onto the template\n",
    "    for pos in positions:\n",
    "        if 'folder' in pos and 'filename' in pos:\n",
    "                img_path = os.path.join(pos['folder'], pos['filename'])\n",
    "                if os.path.exists(img_path):\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(pos['size'], Image.Resampling.LANCZOS)\n",
    "                    template_image.paste(img, pos['position'])\n",
    "                else:\n",
    "                    print(f\"Image {pos['filename']} not found in {pos['folder']}\")\n",
    "        else:\n",
    "                print(f\"Missing 'folder' or 'filename' in: {pos}\")\n",
    "\n",
    "# Add text boxes\n",
    "    # Add text boxes\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    for title_b in title_boxes:\n",
    "        x, y = title_b['position']\n",
    "        w, h = title_b['size']\n",
    "        label = title_b['label']\n",
    "        font_size = title_b['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "            # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    #     Draw a rectangle around the text box area with a dark grey background\n",
    "        draw.rectangle([x, y, x + w, y + h], fill=\"darkgrey\", outline=\"black\", width=2)\n",
    "\n",
    "    #     # Calculate the bounding box of the text\n",
    "        text_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "         # Calculate the position to center the text\n",
    "        text_x = x + (w - text_width) / 2\n",
    "        text_y = y + (h - text_height) / 3\n",
    "\n",
    "    #     # Draw the text centered in the box with white color\n",
    "        draw.text((text_x, text_y), label, fill=\"white\", font=font)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for t in title:\n",
    "        x, y = t['position']\n",
    "        w, h = t['size']\n",
    "        label = t['label']\n",
    "        font_size = t['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw a rectangle around the text box area with a dark grey background\n",
    "        #draw.rectangle([x, y, x + w, y + h], fill=\"grey\", outline=\"white\", width=2)\n",
    "        #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "        # Wrap the text to fit inside the box\n",
    "        wrapped_text = []\n",
    "        words = label.split()\n",
    "        line = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Add the word to the line and check if it fits\n",
    "            test_line = line + word + \" \"\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "            if test_width <= w:\n",
    "                line = test_line\n",
    "            else:\n",
    "                # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "                wrapped_text.append(line.strip())\n",
    "                line = word + \" \"\n",
    "\n",
    "        # Add the last line\n",
    "        wrapped_text.append(line.strip())\n",
    "\n",
    "        # Draw the text line by line, adjusting the position\n",
    "        current_y = y\n",
    "        for line in wrapped_text:\n",
    "            draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "            current_y += font_size  # Move to the next line\n",
    "\n",
    "        # Ensure that the text doesn't overflow the box height\n",
    "        if current_y > y + h:\n",
    "            print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    # for box in text_boxes:\n",
    "    #     x, y = box['position']\n",
    "    #     w, h = box['size']\n",
    "    #     label = box['label']\n",
    "    #     font_size = box['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "    #     # Create a font object with the specified size\n",
    "    #     try:\n",
    "    #         font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "    #     except IOError:\n",
    "    #         font = ImageFont.load_default()\n",
    "\n",
    "    #     # Draw a rectangle around the text box area with a dark grey background\n",
    "    #     #draw.rectangle([x, y, x + w, y + h], fill=\"white\", outline=\"white\", width=2)\n",
    "    #     #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "    #     # Wrap the text to fit inside the box\n",
    "    #     wrapped_text = []\n",
    "    #     words = label.split()\n",
    "    #     line = \"\"\n",
    "\n",
    "    #     for word in words:\n",
    "    #         # Add the word to the line and check if it fits\n",
    "    #         test_line = line + word + \" \"\n",
    "    #         text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "    #         test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "    #         if test_width <= w:\n",
    "    #             line = test_line\n",
    "    #         else:\n",
    "    #             # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "    #             wrapped_text.append(line.strip())\n",
    "    #             line = word + \" \"\n",
    "\n",
    "    #     # Add the last line\n",
    "    #     wrapped_text.append(line.strip())\n",
    "\n",
    "    #     # Draw the text line by line, adjusting the position\n",
    "    #     current_y = y\n",
    "    #     for line in wrapped_text:\n",
    "    #         draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "    #         current_y += font_size  # Move to the next line\n",
    "\n",
    "    #     # Ensure that the text doesn't overflow the box height\n",
    "    #     if current_y > y + h:\n",
    "    #         print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "\n",
    "    #Draw rectangles at specified positions\n",
    "    for pos in positions:\n",
    "        x, y = pos['position']\n",
    "        w, h = pos['size']\n",
    "        line_width = pos['line_width']  # Get the line width from the dictionary\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"black\", width=line_width)\n",
    "        draw.text((x, y - 20), pos['label'], fill=\"black\")\n",
    "        font_size = pos['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Save and show the template with marked positions\n",
    "    #marked_template_path = '/Users/gbenz/Desktop/tmp.png'\n",
    "            \n",
    "        # Save the final image with a specified filename\n",
    "            \n",
    "\n",
    "    output_filename = os.path.join(output_path, f'{country}_{method}_{returnperiodmethod}_{aggregation}x{aggregation}.png')\n",
    "    template_image.save(output_filename)\n",
    "    template_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#produces graphics, tables, and maps for the CELL TYPE RETURN PERIOD:\n",
    "y_rows = y_rp.shape[0]\n",
    "#make the insurance table columns lowercase to keep in line with JPR standards:\n",
    "z.columns = z.columns.str.lower()\n",
    "print(z)\n",
    "#-----This is setting up things to export a map---------------------------------------------------------------\n",
    "sorted_annual_table = query_and_sort_annual_table(y_rp, field_to_sort=sort_annual_report_by, number_of_rows=y_rows)\n",
    "sorted_annual_table.iloc[:, 1:] = sorted_annual_table.iloc[:, 1:].round(1)\n",
    "sorted_annual_table = sorted_annual_table.reset_index(drop=True)\n",
    "\n",
    "filtered_colors = filtered_info['Color'].tolist()\n",
    "lineplot_colors = filtered_colors[1:]\n",
    "image_save_returnperiodtable(z, color_scheme, insurance_attribute, country, method, return_period, value_field, aggregation=aggregation, figure_height=1.75, figure_width=2.5,) #input_table = Jerry_table\n",
    "    #image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info_upto30, country, 'Aggregation', 'Cell', year_to_eval, '3', figure_height=3.5, figure_width=3.5)\n",
    "display(sorted_annual_table)\n",
    "plot_histogram_with_lineplot_4(x, filtered_info, country, method, return_period, aggregation=aggregation, value_field=value_field, labels_to_omit='Below 1 in 10 year', figure_height=3.0, figure_width=6.0)\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "#Do this for the historic -- Or draw on already processed data\n",
    "gdf = retrieve_geodataframe(aggregation)\n",
    "for annual_event in range(min(5, y_rows)):\n",
    "        print(f'map for: {annual_event}')\n",
    "        year_to_eval = define_year_to_map(sorted_annual_table, annual_event)\n",
    "        gdf_merged = query_geodataframe(gdf, x, year_to_eval, field=value_field)\n",
    "        image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info, country, method, return_period, year_to_eval, aggregation, field=value_field, country_label='no', figure_height=3.5, figure_width=3.5, year_id=annual_event)\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "# Generate specific annual tables----------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Split the 'Range' column into two columns (min and max)\n",
    "filtered_info[['Range_min', 'Range_max']] = filtered_info['Range'].str.split(' - ', expand=True)\n",
    "filtered_info['Range_min'] = filtered_info['Range_min'].astype(float)\n",
    "filtered_info['Range_max'] = filtered_info['Range_max'].astype(float)\n",
    "\n",
    "# Step 2: Create a function to map per capita values to the appropriate 'Return Period' and 'Label'\n",
    "def map_return_period(per_capita_value):\n",
    "    for _, row in filtered_info.iterrows():\n",
    "        if row['Range_min'] <= per_capita_value < row['Range_max']:\n",
    "            return pd.Series([row['Return Period'], row['Label']])\n",
    "    return pd.Series([None, None])\n",
    "\n",
    "# Step 3: Apply the function to the per_capita_df and assign the new 'Return Period' and 'Label' columns\n",
    "x_with_rp = x\n",
    "x_with_rp[['Return Period', 'Label']] = x_with_rp[value_field].apply(map_return_period)\n",
    "\n",
    "year_list = sorted_annual_table['year'].head(3).tolist()\n",
    "for year in year_list:\n",
    "    sorted_df = x_with_rp.sort_values(by=['year', 'Return Period', value_field], ascending=[True, False, False])\n",
    "    subset_df = sorted_df[sorted_df['year'] == year].head(10)\n",
    "    print(list(subset_df))\n",
    "    image_save_ind_annual_rp_contextvalues(subset_df, color_scheme, 'Return Period', country, year, method, return_period, aggregation='1', figure_height=3.5, figure_width=3.5) #input_table = Jerry_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_event_cat_rp_with_an_summary_tables(country, method, return_period, min_year, max_year, aggregation, gridlines='no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the objective is to develop a mapping method that allows easy comparison between two elements; These may be comparing different countries or return period types of the same counry, or even the 'method' applied to develop the unit (per capita or raw fatalities) investigated.\n",
    "\n",
    "To complete this. There could be TWO set of parameters that need to be specified -- generated two unique sets of 'insurance tables' from which individual graphics can be generated. \n",
    "\n",
    "we should declare a new parameter 'collection size'. This can have a maximum value of two (for now). \n",
    "\n",
    "In fact, the basic process (running functions up to x_rp) should simply be run twice for whatever desired parameters seek to be compared and generate the intended (individual) graphics. The function to iterate throught these will be what requires the parameter for 2 elements -- making in a comparison infographic \n",
    "\n",
    "We DO want to set a parameter that requests 'how many years should this loop iterate through?' IF the E_i (that is big p) analysis is involved it hardly makes sense for this to be more than 3 (up to 5)\n",
    "\n",
    "\n",
    "1. needs to create a sepearte layout for each year\n",
    "2. The annual table (x_rp) should be sorted by YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map_prepare_time_enabled_summary:\n",
    "\n",
    "#### Preconditions for setting up the mapping function `map_event_cat_rp_with_an_summary_tables`\n",
    "Gives Top 10 years of conflict\n",
    "\n",
    "\n",
    "Unlike preceding options, this function is still in development therefore still hosted locally in the notebook and not saved as .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_prepare_time_enabled_summary(iteration_element, countryA, methodA, attributeA, returnperiodmethodA, countryB, methodB, attributeB,  returnperiodmethodB, year_datastart, year_dataend, aggregationA='0', aggregationB='0', gridlines='no'): \n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "    font_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/OpenSans-VariableFont.ttf'\n",
    "    template_path = base_dir + '/src/utils/functions_for_graphics/layout_formats/Slide 3 Template.png'\n",
    "    template_image = Image.open(template_path)\n",
    "\n",
    "\n",
    "    if aggregation == '1':\n",
    "        aggregation_stringA = aggregationA + 'x' + aggregationA\n",
    "        aggregation_stringB = aggregationB + 'x' + aggregationB\n",
    "\n",
    "        map_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA  + '/' + 'map_png/'\n",
    "        print(map_pathA)\n",
    "        map_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB  + '/' + 'map_png/'\n",
    "        print(map_pathB)\n",
    "\n",
    "        #annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod   + '/table_png/'\n",
    "        #print(annual_table_path)\n",
    "        return_period_table_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA  + '/table_png/percentile and payout table/'\n",
    "        print('return period table path A:')\n",
    "        return_period_table_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB  + '/table_png/percentile and payout table/'\n",
    "        print('return period table path B:')\n",
    "\n",
    "\n",
    "    #/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/\n",
    "\n",
    "    #Ethiopia/standard/Event year/1x1/table_png/Ethiopia Annual Summary Image year 4 in 2016 with dimensions 4.0x5.5.png\n",
    "\n",
    "        #print(return_period_table_path)\n",
    "        return_period_annual_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA  + '/' + aggregation_stringA + '/table_png/'\n",
    "        #print(return_period_lineplot_path)\n",
    "        return_period_annual_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB  + '/' + aggregation_stringB + '/table_png/'\n",
    "\n",
    "\n",
    "        output_path = base_directory + '/files/Layouts/' + countryA + '/' \n",
    "\n",
    "    else:\n",
    "        aggregation_stringA = aggregationA + 'x' + aggregationA\n",
    "        aggregation_stringB = aggregationB + 'x' + aggregationB\n",
    "\n",
    "        map_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA + '/' + aggregation_stringA   + '/' + 'map_png/'\n",
    "        print(map_pathA)\n",
    "        map_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB + '/' + aggregation_stringB   + '/' + 'map_png/'\n",
    "        print(map_pathB)\n",
    "\n",
    "        #annual_table_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string  + '/' + 'table_png/'\n",
    "        #print(annual_table_path)\n",
    "\n",
    "        return_period_table_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA + '/' + aggregation_stringA  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_pathA)\n",
    "\n",
    "        return_period_table_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB + '/' + aggregation_stringB  + '/' + 'table_png/percentile and payout table/'\n",
    "        print(return_period_table_pathB)\n",
    "\n",
    "        return_period_annual_pathA = base_directory + '/files/' + countryA + '/' + methodA + '/' + returnperiodmethodA  + '/' + aggregation_stringA + '/table_png/'\n",
    "        #print(return_period_lineplot_path)\n",
    "        return_period_annual_pathB = base_directory + '/files/' + countryB + '/' + methodB + '/' + returnperiodmethodB  + '/' + aggregation_stringB + '/table_png/'\n",
    "\n",
    "        #---\n",
    "\n",
    "    output_path = base_directory + f'/files/Layouts/map_prepare_time_enabled_summary/{countryA}' \n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "    #look for the graphic with the appropriate dimensions:\n",
    "    #Map 1\n",
    "\n",
    "\n",
    "    def find_file_with_string_year(path, iteration_element, attribute):\n",
    "        # Create the pattern to search for \"year <iteration_element>\" and the attribute\n",
    "        pattern = re.compile(rf\"\\byear {iteration_element}\\b\")\n",
    "        \n",
    "        # Search for files that contain both iteration_element AND attribute\n",
    "        files = [f for f in os.listdir(path) if pattern.search(f) and attribute in f]\n",
    "        \n",
    "        return files[0] if files else None\n",
    "\n",
    "    def find_file_with_string(path, iteration_element, attribute):\n",
    "        # Ensure iteration_element and attribute are strings\n",
    "        iteration_element = str(iteration_element)\n",
    "        attribute = str(attribute)\n",
    "        \n",
    "        # Search for files that contain both iteration_element AND attribute in their filenames\n",
    "        files = [f for f in os.listdir(path) if iteration_element in f and attribute in f]\n",
    "        \n",
    "        # Return the first matched file or None if no match is found\n",
    "        return files[0] if files else None\n",
    "\n",
    "    # Example usage\n",
    "    map_filename_0 = find_file_with_string_year(map_pathA, iteration_element, attributeA)\n",
    "    print(f'located map rank1: {map_filename_0}')\n",
    "\n",
    "    # map_filename_0 = find_file_with_string(map_pathA, f'conflict year {iteration_element}') # looking for a 3.5 x 3.5 map \n",
    "    # print(f'located map rank1: {map_filename_0}')\n",
    "\n",
    "    year__0 = re.search(r\"\\b\\d{4}\\b\", map_filename_0)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__0:\n",
    "        year__0 = str(int(year__0.group()))\n",
    "        print(year__0)\n",
    "\n",
    "    #Map 2\n",
    "    map_filename_1 = find_file_with_string_year(map_pathB, iteration_element, attributeB) # looking for a 3.5 x 3.5 map\n",
    "    print(f'located map rank 2: {map_filename_1}')\n",
    "\n",
    "    year__1 = re.search(r\"\\b\\d{4}\\b\", map_filename_1)\n",
    "\n",
    "    # Convert the match to an integer and print\n",
    "    if year__1:\n",
    "        year__1 = str(int(year__1.group()))\n",
    "        print(year__1)\n",
    "\n",
    "    #annual_table_filename = find_file_with_string(annual_table_path, '4.0x5.5') #  looking for a 2.5 x 1.75 map 4_0x5_5\n",
    "    #print(f'located lineplot file in folder: {annual_table_filename}')\n",
    "\n",
    "    return_period_table_fileneameA = find_file_with_string(return_period_table_pathA, '2.5x1.8', attributeA)\n",
    "    print(f'located lineplot file in folder: {return_period_table_fileneameA}')\n",
    "    \n",
    "    return_period_table_fileneameB = find_file_with_string(return_period_table_pathB, '2.5x1.8', attributeB)\n",
    "    print(f'located lineplot file in folder: {return_period_table_fileneameB}')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    annual_table_fileneameA = find_file_with_string_year(return_period_annual_pathA, iteration_element, attributeA)\n",
    "    print(f'located annual file in folder: {annual_table_fileneameA}')\n",
    "\n",
    "    annual_table_fileneameB = find_file_with_string_year(return_period_annual_pathB, iteration_element, attributeB)\n",
    "    print(f'located annual file in folder: {annual_table_fileneameB}')\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Load the template image\n",
    "    #template_path = 'Slide 1 Option B Template.png'\n",
    "\n",
    "    template_image = template_image.resize((1620, 915), Image.Resampling.LANCZOS)\n",
    "    draw = ImageDraw.Draw(template_image)\n",
    "\n",
    "\n",
    "\n",
    "    # Define grid parameters\n",
    "    grid_spacing = 50  # Adjust the spacing as needed\n",
    "    grid_color = \"blue\"\n",
    "    grid_width = 1\n",
    "\n",
    "    # Define the font for the grid labels\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    # Get the dimensions of the template image\n",
    "    width, height = template_image.size\n",
    "\n",
    "    if gridlines == 'yes':\n",
    "    # Draw the grid\n",
    "        for x in range(0, width, grid_spacing):\n",
    "            draw.line([(x, 0), (x, height)], fill=grid_color, width=grid_width)\n",
    "            draw.text((x, 0), str(x), fill=grid_color, font=font)\n",
    "        for y in range(0, height, grid_spacing):\n",
    "            draw.line([(0, y), (width, y)], fill=grid_color, width=grid_width)\n",
    "            draw.text((0, y), str(y), fill=grid_color, font=font)\n",
    "\n",
    "    # Define the positions and sizes for placeholders\n",
    "    positions = [\n",
    "\n",
    "#These are the top 2 Conflict years\n",
    "        {'position': (50, 175), 'size': (400, 400), 'label': '','filename': map_filename_0, 'folder': map_pathA, 'font_size': 9, 'line_width': 3},       # Year 1\n",
    "        {'position': (825, 175), 'size': (400, 400), 'label': '','filename': map_filename_1, 'folder': map_pathB, 'font_size':9,'line_width': 3},       # Year 1\n",
    "\n",
    "        #Insurance table for element #1\n",
    "        {'position': (50, 600), 'size': (400, 225), 'label': '','filename': return_period_table_fileneameA, 'folder': return_period_table_pathA,'font_size':1, 'line_width': 3},     # Payout Legend \n",
    "       \n",
    "        #Insurance table for element #2\n",
    "        {'position': (825, 600), 'size': (400, 225), 'label': '','filename': return_period_table_fileneameB, 'folder': return_period_table_pathB,'font_size':1, 'line_width': 3},     # Payout Legend \n",
    "        \n",
    "        #annual table\n",
    "        {'position': (475, 175), 'size': (325, 650), 'label': '', 'filename': annual_table_fileneameA, 'folder': return_period_annual_pathA,'font_size':1, 'line_width': 3},     # Payout Legend Title\n",
    "        {'position': (1250, 175), 'size': (325, 650), 'label': '', 'filename': annual_table_fileneameB, 'folder': return_period_annual_pathB,'font_size':1, 'line_width': 3},     # Payout Legend \n",
    "        \n",
    "        #Histogram\n",
    "        #{'position': (400, 50), 'size': (900, 125), 'label': '','filename': return_period_lineplot_fileneame, 'folder': return_period_lineplot_path,'font_size':1, 'line_width': 0},     # Payout Legend \n",
    "\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Legend'},     # Payout Legend Title\n",
    "\n",
    "    ]\n",
    "\n",
    "        # Define the positions and sizes for text boxes\n",
    "    text_boxes = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        #{'position': (65, 215), 'size': (270, 325), 'label':  summary_text,'font_size': 15}\n",
    "    ]\n",
    "\n",
    "    title = [\n",
    "        #{'position': (425, 575), 'size': (400, 50), 'label': 'Payout Legend','font_size': 24},     # Payout Legend Title\n",
    "        #{'position': (925, 100), 'size': (650, 50), 'label': 'Top Conflict Years','font_size': 32},     # Payout Legend Title\n",
    "        {'position': (50, 25), 'size': (600, 125), 'label':  country, 'font_size': 92}\n",
    "    ]\n",
    "\n",
    "    title_boxes = [\n",
    "        #these are placeholders until the actual graphics can be produced:\n",
    "        #{'position': (475, 175), 'size': (325, 650), 'label': 'Return period labels and threshold values','font_size': 18, 'background_color': 'darkgrey', 'line_width': 2, 'text_color': 'white'},     # Payout Legend Title\n",
    "        #{'position': (1250, 175), 'size': (325, 650), 'label': 'Return period labels and threshold values','font_size': 18, 'background_color': 'darkgrey', 'line_width': 2, 'text_color': 'white'},     # Payout Legend Title\n",
    "\n",
    "\n",
    "        #maybe keep these\n",
    "        #{'position': (50, 175), 'size': (550, 35), 'label': 'Return period labels and threshold values','font_size': 18, 'background_color': 'darkgrey', 'line_width': 2, 'text_color': 'white'},     # Payout Legend Title\n",
    "\n",
    "        #{'position': (800, 385), 'size': (150, 35), 'label': year__0,'font_size': 24, 'background_color': None, 'line_width': 0, 'text_color': 'black'},     # Year Label for Top year\n",
    "        #{'position': (1085, 385), 'size': (150, 35), 'label': year__1,'font_size': 24, 'background_color': None, 'line_width': 0, 'text_color': 'black'},     # Year Label for Top 2 year\n",
    "    ]\n",
    "\n",
    "        # # Load and paste the images onto the template\n",
    "    for pos in positions:\n",
    "        if 'folder' in pos and 'filename' in pos:\n",
    "                img_path = os.path.join(pos['folder'], pos['filename'])\n",
    "                if os.path.exists(img_path):\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize(pos['size'], Image.Resampling.LANCZOS)\n",
    "                    template_image.paste(img, pos['position'])\n",
    "                else:\n",
    "                    print(f\"Image {pos['filename']} not found in {pos['folder']}\")\n",
    "        else:\n",
    "                print(f\"Missing 'folder' or 'filename' in: {pos}\")\n",
    "\n",
    "# Add text boxes\n",
    "    # Add text boxes\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "    for title_b in title_boxes:\n",
    "        x, y = title_b['position']\n",
    "        w, h = title_b['size']\n",
    "        label = title_b['label']\n",
    "        font_size = title_b['font_size']  # Get the font size from the dictionary\n",
    "        background_color = title_b['background_color']  # Get the font size from the dictionary\n",
    "        line_width = title_b['line_width']\n",
    "        text_color = title_b['text_color']\n",
    "            # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    #     Draw a rectangle around the text box area with a dark grey background\n",
    "        draw.rectangle([x, y, x + w, y + h], fill= background_color, outline=\"black\", width=line_width)\n",
    "\n",
    "    #     # Calculate the bounding box of the text\n",
    "        text_bbox = draw.textbbox((0, 0), label, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "\n",
    "         # Calculate the position to center the text\n",
    "        text_x = x + (w - text_width) / 2\n",
    "        text_y = y + (h - text_height) / 3\n",
    "\n",
    "    #     # Draw the text centered in the box with white color\n",
    "        draw.text((text_x, text_y), label, fill=text_color, font=font)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    for t in title:\n",
    "        x, y = t['position']\n",
    "        w, h = t['size']\n",
    "        label = t['label']\n",
    "        font_size = t['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        # Create a font object with the specified size\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "        # Draw a rectangle around the text box area with a dark grey background\n",
    "        #draw.rectangle([x, y, x + w, y + h], fill=\"grey\", outline=\"white\", width=2)\n",
    "        #draw.rectangle([x, y, x + w, y + h])\n",
    "\n",
    "        # Wrap the text to fit inside the box\n",
    "        wrapped_text = []\n",
    "        words = label.split()\n",
    "        line = \"\"\n",
    "\n",
    "        for word in words:\n",
    "            # Add the word to the line and check if it fits\n",
    "            test_line = line + word + \" \"\n",
    "            text_bbox = draw.textbbox((0, 0), test_line, font=font)\n",
    "            test_width = text_bbox[2] - text_bbox[0]\n",
    "\n",
    "            if test_width <= w:\n",
    "                line = test_line\n",
    "            else:\n",
    "                # If the line is too long, add the current line to wrapped_text and start a new line\n",
    "                wrapped_text.append(line.strip())\n",
    "                line = word + \" \"\n",
    "\n",
    "        # Add the last line\n",
    "        wrapped_text.append(line.strip())\n",
    "\n",
    "        # Draw the text line by line, adjusting the position\n",
    "        current_y = y\n",
    "        for line in wrapped_text:\n",
    "            draw.text((x, current_y), line, fill=\"black\", font=font)\n",
    "            current_y += font_size  # Move to the next line\n",
    "\n",
    "        # Ensure that the text doesn't overflow the box height\n",
    "        if current_y > y + h:\n",
    "            print(\"Warning: Text overflow in the box. Consider reducing the font size or the amount of text.\")\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------         \n",
    "\n",
    "    #Draw rectangles at specified positions\n",
    "    for pos in positions:\n",
    "        x, y = pos['position']\n",
    "        w, h = pos['size']\n",
    "        line_width = pos['line_width']  # Get the line width from the dictionary\n",
    "        draw.rectangle([x, y, x + w, y + h], outline=\"black\", width=line_width)\n",
    "        draw.text((x, y - 20), pos['label'], fill=\"black\")\n",
    "        font_size = pos['font_size']  # Get the font size from the dictionary\n",
    "\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, font_size)  # Use a valid font on your system\n",
    "        except IOError:\n",
    "            font = ImageFont.load_default()\n",
    "\n",
    "    # Save and show the template with marked positions\n",
    "    #marked_template_path = '/Users/gbenz/Desktop/tmp.png'\n",
    "            \n",
    "        # Save the final image with a specified filename\n",
    "    if returnperiodmethodA == 'Event year':\n",
    "        return_period_definition = 'bigp'\n",
    "    else:\n",
    "        return_period_definition = 'littlep'\n",
    "\n",
    "\n",
    "    output_filename = os.path.join(output_path, f'single_{country}_iteration_{iteration_element}_{aggregation_stringA}_{return_period_definition}_{year_datastart}_{year_dataend}.png')\n",
    "    output_filename = output_filename.replace(' ', '_')\n",
    "\n",
    "    print()\n",
    "    print('file saved to:')\n",
    "    print(output_filename)\n",
    "    template_image.save(output_filename)\n",
    "    template_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_and_colorize_annual_table(annual_df, country, method, returnperiodmethod, eval_attribute, aggregation, year, figure_height=5.5, figure_width=4.0, year_id=None):\n",
    "    figure_height_str = float_to_custom_string(figure_height)\n",
    "    figure_width_str = float_to_custom_string(figure_width)\n",
    "\n",
    "    aggregation_string = str(aggregation) + 'x' + str(aggregation)\n",
    "\n",
    "    base_directory = os.getcwd()\n",
    "\n",
    "    if aggregation == 1:\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/table_png'\n",
    "    else:\n",
    "        output_path = base_directory + '/files/' + country + '/' + method + '/' + returnperiodmethod + '/' + aggregation_string + '/table_png'\n",
    "\n",
    "    ensure_directory_exists(output_path)\n",
    "\n",
    "\n",
    "    # Step 3: Format numeric values to one decimal place\n",
    "    def format_dataframe(df):\n",
    "        formatted_df = df.copy()\n",
    "        for column in df.columns[1:]:  # Skip the 'year' column\n",
    "            formatted_df[column] = formatted_df[column].apply(lambda x: f'{x:.1f}')\n",
    "        return formatted_df\n",
    "\n",
    "    formatted_annual_df = format_dataframe(annual_df)\n",
    "\n",
    "    if year_id != None:\n",
    "        output_file = os.path.join(output_path, f'{country} Annual Summary Image year {year_id} in {year} investigating {eval_attribute} with dimensions {figure_width_str}x{figure_height_str}.png')\n",
    "    else:\n",
    "        output_file = os.path.join(output_path, f'{country} Annual Summary Image in {year} investigating {eval_attribute} with dimensions {figure_width_str}x{figure_height_str}.png')\n",
    "\n",
    "    # Step 4: Plot and save the colored table\n",
    "    fig, ax = plt.subplots(figsize=(figure_width, figure_height))\n",
    "\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "\n",
    "    # Create a table from the formatted DataFrame\n",
    "    table = ax.table(cellText=formatted_annual_df.values, colLabels=formatted_annual_df.columns, cellLoc='center', loc='center')\n",
    "\n",
    "    # Define color and border properties\n",
    "    light_grey = '#D3D3D3'\n",
    "    dark_grey = rgb_to_hex((64, 64, 64))\n",
    "    medium_grey = '#A9A9A9'  # Color between light grey and dark grey\n",
    "    bold_black = {'linewidth': 4, 'color': 'black'}\n",
    "\n",
    "    # Highlight the specific row by 'year'\n",
    "    for key, cell in table.get_celld().items():\n",
    "        # First row (header)\n",
    "        if key[0] == 0:\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "            cell.set_facecolor(dark_grey)\n",
    "        # First column (year column)\n",
    "        if key[1] == 0:\n",
    "            cell.set_text_props(color='white')\n",
    "            cell.set_facecolor(dark_grey)\n",
    "        # Color all other cells light grey with white text\n",
    "        elif key[0] > 0:\n",
    "            row_year = formatted_annual_df.iloc[key[0]-1, 0]  # Get the year from the 'year' column\n",
    "            if str(row_year) == year:\n",
    "                cell.set_text_props(color='black')\n",
    "                cell.set_facecolor(medium_grey)\n",
    "                cell.set_edgecolor(bold_black['color'])\n",
    "                cell.set_linewidth(bold_black['linewidth'])\n",
    "            else:\n",
    "                cell.set_text_props(color='black')\n",
    "                cell.set_facecolor(light_grey)\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.5)\n",
    "\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_y_rp___count=filter_annual_payout_table___count(y_rp)\n",
    "\n",
    "sorted_annual_table = query_and_sort_annual_table(filtered_y_rp___count, field_to_sort='year', number_of_rows=y_rows)\n",
    "sorted_annual_table = sorted_annual_table.reset_index(drop=True)\n",
    "\n",
    "print(sorted_annual_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#produces graphics, tables, and maps for the CELL TYPE RETURN PERIOD:\n",
    "filtered_y_rp___count=filter_annual_payout_table___count(y_rp)\n",
    "\n",
    "y_rows = filtered_y_rp___count.shape[0]\n",
    "#make the insurance table columns lowercase to keep in line with JPR standards:\n",
    "z.columns = z.columns.str.lower()\n",
    "print(z)\n",
    "#-----This is setting up things to export a map---------------------------------------------------------------\n",
    "sorted_annual_table = query_and_sort_annual_table(filtered_y_rp___count, field_to_sort='year', number_of_rows=y_rows)\n",
    "sorted_annual_table = sorted_annual_table.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#filtered_colors = filtered_info['Color'].tolist()\n",
    "#lineplot_colors = filtered_colors[1:]\n",
    "\n",
    "image_save_returnperiodtable(z, color_scheme, insurance_attribute, country, method, return_period, value_field, aggregation=aggregation, figure_height=1.75, figure_width=2.5,) #input_table = Jerry_table\n",
    "    #image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info_upto30, country, 'Aggregation', 'Cell', year_to_eval, '3', figure_height=3.5, figure_width=3.5)\n",
    "display(sorted_annual_table)\n",
    "#plot_and_colorize_annual_table(sorted_annual_table, filtered_info, country, method, return_period, aggregation=aggregation, figure_height=5.5, figure_width=4.0)\n",
    "#plot_histogram_with_lineplot_4(x, filtered_info, country, method, return_period, aggregation=aggregation, value_field=value_field, labels_to_omit='Below 1 in 10 year', figure_height=3.0, figure_width=6.0)\n",
    "\n",
    "\n",
    "gdf = retrieve_geodataframe(aggregation)\n",
    "for annual_event in range(min(30, y_rows)):\n",
    "        print(f'map for: {annual_event}')\n",
    "        year_to_eval = define_year_to_map(sorted_annual_table, annual_event)\n",
    "        year_string = str(int(year_to_eval))\n",
    "        print(year_string)\n",
    "        plot_and_colorize_annual_table(sorted_annual_table, country, method, return_period, value_field, aggregation, year_string, 5.5, 4.0, annual_event)\n",
    "\n",
    "        gdf_merged = query_geodataframe(gdf, x, year_to_eval, field=value_field)\n",
    "        image_save_map_E_i(gdf_merged, cleaned_thresholds, cleaned_labels, filtered_info, country, method, return_period, year_to_eval, value_field, aggregation, field=value_field, country_label='no', figure_height=3.5, figure_width=3.5, year_id=annual_event)\n",
    "\n",
    "\n",
    "\n",
    "#create for loop that loops over BOTH the maps and annual table \n",
    "        #this must be done becuase a new annual table will be created for each year that HIGHLIGHTS the BORDER of the featured year!\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string_list = [str(i) for i in range(30)]\n",
    "del str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = [str(i) for i in range(30)]\n",
    "\n",
    "# Print out each function call before execution to inspect the inputs\n",
    "for string in string_list:\n",
    "    print(f\"Calling map_prepare_time_enabled_summary with: {string}\")\n",
    "    map_prepare_time_enabled_summary(string, country, 'standard', 'percapita_100k', 'Country year', country, \n",
    "                                     'standard', 'fatalities_sum', 'Country year', min_year, max_year, \n",
    "                                     aggregation, aggregation, gridlines='no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def create_video_from_images(image_folder, output_video_path, fps=30, display_time=0.75):\n",
    "    # Get the list of all PNG files in the directory, sorted by filename\n",
    "    # images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "    # images.sort()  # Make sure images are in the correct order\n",
    "\n",
    "\n",
    "        # List all images that end with \".png\"\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "\n",
    "    # Function to extract the number after 'iteration_'\n",
    "    def extract_iteration_number(filename):\n",
    "        match = re.search(r'iteration_(\\d+)', filename)\n",
    "        return int(match.group(1)) if match else float('inf')  # Return inf for filenames without 'iteration_'\n",
    "\n",
    "    # Sort images based on the extracted iteration number\n",
    "    images.sort(key=extract_iteration_number)\n",
    "    \n",
    "    # Calculate the number of frames each image should be displayed for\n",
    "    frames_per_image = int(fps * display_time)\n",
    "    \n",
    "    # Read the first image to get the frame size\n",
    "    first_image = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = first_image.shape\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for .mp4\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # Loop through images and write them to the video\n",
    "    for image in images:\n",
    "        img_path = os.path.join(image_folder, image)\n",
    "        frame = cv2.imread(img_path)\n",
    "        \n",
    "        # Write the same frame multiple times to achieve the desired display time\n",
    "        for _ in range(frames_per_image):\n",
    "            video.write(frame)\n",
    "\n",
    "    # Release the video writer object\n",
    "    video.release()\n",
    "\n",
    "# Example usage:\n",
    "image_folder = '/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/Layouts/map_prepare_time_enabled_summary/Somalia/'\n",
    "output_video_path = '/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/Layouts/map_prepare_time_enabled_summary/Somalia/output_video.mp4'\n",
    "create_video_from_images(image_folder, output_video_path, fps=30, display_time=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_download = pd.read_pickle('/Users/gbenz/Downloads/df_yearly_country_return_periods.pkl')\n",
    "\n",
    "pkl_download\n",
    "\n",
    "pkl_ethiopia__kgi = pkl_download[\n",
    "    (pkl_download['c_id'] == 57) & \n",
    "    (pkl_download['year_id'] > 1992) & \n",
    "    (pkl_download['year_id'] < 2021) \n",
    "]\n",
    "\n",
    "# display(pkl_download.head(3))\n",
    "display(pkl_ethiopia__kgi.head(3))\n",
    "\n",
    "sum_kgi = {col: pkl_ethiopia__kgi[col].sum() for col in ['sb_best', 'ns_best', 'os_best']}\n",
    "print(sum_kgi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopia_download = pd.read_csv('/Users/gbenz/Downloads/gedevents-2024-09-23.csv')\n",
    "#display(ethiopia_download.head(3))\n",
    "\n",
    "ged = pd.read_csv('/Users/gbenz/Downloads/GEDEvent_v24_1.csv')\n",
    "#sb = pd.read_csv('/Users/gbenz/Downloads/BattleDeaths_v24_1.csv')\n",
    "#os = pd.read_csv('/Users/gbenz/Downloads/ucdp-onesided-241-csv/OneSided_v24_1.csv')\n",
    "#ns = pd.read_csv('/Users/gbenz/Downloads/Nonstate_v24_1.csv')\n",
    "\n",
    "#display(sb.head(3))\n",
    "\n",
    "#display(os.head(3))\n",
    "\n",
    "#display(ns.head(3))\n",
    "\n",
    "ged['country_id'] = pd.to_numeric(ged['country_id'], errors='coerce')\n",
    "\n",
    "ged_ethiopia__kgi = ged[\n",
    "    (ged['country'] == 'Ethiopia') & \n",
    "    (ged['year'] > 1992) & \n",
    "    (ged['year'] < 2021) & \n",
    "    (ged['where_prec'].isin([1, 2]))\n",
    "]\n",
    "#print(ged['country_id'].unique())\n",
    "\n",
    "ged_ethiopia__all = ged[(ged['country'] == 'Ethiopia') &\n",
    "                        (ged['year'] > 1992) & \n",
    "                        (ged['year'] < 2021)\n",
    "                        ]\n",
    "\n",
    "display(ged_ethiopia__kgi.head(3))\n",
    "#ethiopia_ged\n",
    "\n",
    "sum_all = {col: ged_ethiopia__all[col].sum() for col in ['best']}\n",
    "sum_kgi = {col: ged_ethiopia__kgi[col].sum() for col in ['best']}\n",
    "\n",
    "print(sum_kgi)\n",
    "print(sum_all)\n",
    "\n",
    "unique_countries = pd.unique(ged_ethiopia__all['country_id'])\n",
    "print(unique_countries)\n",
    "\n",
    "#print(unique_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malawi\n",
    "\n",
    "no per capita fatalities appear because there are only 2 maybe 3 event which puts any occurence above the 99.9% threshold. because the insurance table rounds o the .1 deceimal -- no fatalities are reports anywhere in the country because there are so few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/Zimbabwe_annual_report_percapita_100k_3x3_Country year.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data_1x1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/\u001b[39m\u001b[39m{\u001b[39;00mcountry\u001b[39m}\u001b[39;00m\u001b[39m_annual_report_\u001b[39m\u001b[39m{\u001b[39;00mattribute\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00maggregation_1x1\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mreturn_period_type\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m data_3x3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/\u001b[39;49m\u001b[39m{\u001b[39;49;00mcountry\u001b[39m}\u001b[39;49;00m\u001b[39m_annual_report_\u001b[39;49m\u001b[39m{\u001b[39;49;00mattribute\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00maggregation_3x3\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mreturn_period_type\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Create the plot\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/summary_graphics.ipynb#Z2012sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/Zimbabwe_annual_report_percapita_100k_3x3_Country year.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "country = 'Zimbabwe'\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "attribute= 'percapita_100k'\n",
    "aggregation_1x1 = '1x1'\n",
    "aggregation_3x3 = '3x3'\n",
    "return_period_type = 'Country year'\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "data_1x1 = pd.read_csv(f'/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/{country}_annual_report_{attribute}_{aggregation_1x1}_{return_period_type}.csv')\n",
    "data_3x3 = pd.read_csv(f'/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/{country}_annual_report_{attribute}_{aggregation_3x3}_{return_period_type}.csv')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot df1 with a thick black line\n",
    "plt.plot(data_1x1['year'], data_1x1['payout rate (%)'], color='black', linewidth=2.5, label='1x1')\n",
    "\n",
    "# Plot df2 with a dark grey dotted line\n",
    "plt.plot(data_3x3['year'], data_3x3['payout rate (%)'], color='darkgrey', linestyle='--', linewidth=2.5, label='3x3')\n",
    "\n",
    "# Set x-ticks to be multiples of 5, ensuring 2020 is included\n",
    "min_year = min(data_1x1['year'].min(), data_3x3['year'].min())  # Get the earliest year from both datasets\n",
    "max_year = 2020  # Ensure 2020 is the last tick\n",
    "\n",
    "# Create ticks for every year and labels only for multiples of 5\n",
    "all_years = np.arange(min_year, max_year + 1)  # Tick at every year\n",
    "label_years = np.arange(min_year, max_year + 1, 5)  # Labels only at multiples of 5\n",
    "\n",
    "if 2020 not in label_years:  # Ensure 2020 is included\n",
    "    years = np.append(label_years, 2020)\n",
    "\n",
    "plt.xticks(all_years)  # Set ticks for every year\n",
    "plt.gca().set_xticklabels([str(year) if year in label_years else '' for year in all_years])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Payout Rate (%)')\n",
    "plt.title('Payout Rate Comparison')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "plt.savefig(f'/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/files/reference_tables/payout_line_graph/Payout_table_{country}_{attribute}_comparing_{aggregation_1x1}_and_{aggregation_3x3}.png')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
