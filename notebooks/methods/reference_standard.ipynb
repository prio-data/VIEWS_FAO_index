{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Method Notebook\n",
    "\n",
    "### Overview: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary functions\n",
    "\n",
    "These functions are stored in src/utils and contain intuitive folders hosting functions. The working directory should be set to the VIEWS_FAO_INDEX folder to enable access to retrieve these .py files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# # Get the current working directory\n",
    "# current_directory = os.getcwd()\n",
    "\n",
    "# # Print the current working directory\n",
    "# print(\"The current Working Directory is:\", current_directory)\n",
    "\n",
    "# # Get the path to the base directory (VIEWS_FAO_index)\n",
    "# base_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "# print(f'The base directory will be set to: {base_dir}')\n",
    "\n",
    "# # Add the base directory to sys.path\n",
    "# sys.path.insert(0, base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook solution  --------------------------------------------------------------------------------------------\n",
    "notebook_dir = os.getcwd() # notebook specific\n",
    "notebook_name = \"reference_standard.ipynb\" # notebook specific name\n",
    "\n",
    "PATH = Path(notebook_dir) / Path(notebook_name) # notebook specific\n",
    "\n",
    "# alt script version -----------------------------------------------------------------------------------------------------\n",
    "# PATH = Path(__file__)\n",
    "\n",
    "# Common for notebooks and scripts alike\n",
    "sys.path.insert(0, str(Path(*[i for i in PATH.parts[:PATH.parts.index(\"VIEWS_FAO_index\")+1]]) / \"src/utils\"))   \n",
    "\n",
    "from set_paths import setup_project_paths, get_logo_path, get_data_paths, setup_root_paths, get_plot_path\n",
    "setup_project_paths(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gbenz/Documents/VIEWS_FAO_index/data/raw_viewser\n",
      "/Users/gbenz/Documents/VIEWS_FAO_index/data/raw_external\n",
      "/Users/gbenz/Documents/VIEWS_FAO_index/data/processed\n",
      "/Users/gbenz/Documents/VIEWS_FAO_index/data/generated\n"
     ]
    }
   ],
   "source": [
    "PATH_RAW_VIEWSER, PATH_RAW_EXTERNAL, PATH_PROCESSED, PATH_GENERATED = get_data_paths(PATH)\n",
    "\n",
    "# lest print the paths\n",
    "print(PATH_RAW_VIEWSER)\n",
    "print(PATH_RAW_EXTERNAL)\n",
    "print(PATH_PROCESSED)\n",
    "print(PATH_GENERATED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n",
      "The current Working Directory is: /Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods\n",
      "The base directory will be set to: /Users/gbenz/Documents/VIEWS_FAO_index\n"
     ]
    }
   ],
   "source": [
    "#Functions necessary for all methods:\n",
    "from src.utils.universal_functions.setup.generate_base_file import give_primary_frame\n",
    "from src.utils.universal_functions.setup.associate_country_id import associate_country_years, pull_from_c_y_dictionary\n",
    "from src.utils.universal_functions.setup.build_directory import ensure_directory_exists\n",
    "\n",
    "#Functions to generate the insurance table requested by FAO partners:\n",
    "from src.utils.universal_functions.FAO_table_formatting.calculate_percentiles import format_stats, clean_percentile_table\n",
    "from src.utils.universal_functions.FAO_table_formatting.generate_output_tables import insurance_table, annual_summary_table\n",
    "\n",
    "#Functions bespoke to standard method:\n",
    "from src.utils.functions_for_method_standard.standard_per_capita_fatalities import native_per_capita_fatalities\n",
    "\n",
    "#function to calculate Ei & big P return period\n",
    "from src.utils.functions_for_single_cell_return_period.cell_return_period import calculate_cumulative_distribution, calculate_probabilities, calculate_expected_time_periods, calculate_expected_voxels, compare_empirical_vs_expected\n",
    "from src.utils.functions_for_single_cell_return_period.Ei_insurance_table_setup import insurance_table_for_E_i\n",
    "\n",
    "#summary function that is templated by preceding code:\n",
    "from src.utils.functions_for_return_periods.insurance_products_for_RP import standard_Country_Year_files, standard_Event_Year_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we define our primary dataframe. \n",
    "\n",
    "The variable 'data' is developed from two querysets 1. Fatalities_fao_pgm and 2. cm_properties which are required in order to capture fatality attributes and unique country identifiers, including start and end years for boundary changes.\n",
    "\n",
    "Year parameters can be adapted to incorporate future annual releases of Uppsala Conflict Data Program (UCDP) Geospatial Events Database (GED) data or constrain the temporal window for unique applications. The recommendation is to capture data from the full extent, which at the time of this release is 1989 - 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gbenz/Documents/VIEWS_FAO_index/data/generated/df_monthly_country_return_periods.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/reference_standard.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/reference_standard.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_monthly \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(PATH_GENERATED \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdf_monthly_country_return_periods.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gbenz/Documents/VIEWS_FAO_index/notebooks/methods/reference_standard.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_yearly \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(PATH_GENERATED \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdf_yearly_country_return_periods.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/viewser/lib/python3.11/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/gbenz/Documents/VIEWS_FAO_index/data/generated/df_monthly_country_return_periods.pkl'"
     ]
    }
   ],
   "source": [
    "df_monthly = pd.read_pickle(PATH_GENERATED / \"df_monthly_country_return_periods.pkl\")\n",
    "df_yearly = pd.read_pickle(PATH_GENERATED / \"df_yearly_country_return_periods.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = give_primary_frame('Fatalities_fao_pgm', 'cm_properties', 1988, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a copy of the variable data to keep a clean version accesible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_working_copy = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifiy countries to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Burkina Faso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process for Country Year Return Period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    print('working on: '+ country)\n",
    "\n",
    "#   First:\n",
    "#   1. Aggregate the standard PRIO-Grid scale to a courser resolution\n",
    "    country_and_year_dictionary = associate_country_years(data_working_copy, country)\n",
    "    print('printing he country and year dictionary:')\n",
    "    print(country_and_year_dictionary)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#   Second:\n",
    "#       1. Subset designated country in list. This requires examining country_id information and corresponding start and end years. \n",
    "#   Some countries contain more than one country_id. The functions employed in this section identify the most recent country range and \n",
    "#   subset the neccesary temporal ranges.\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    cid_int = pull_from_c_y_dictionary(country_and_year_dictionary)\n",
    "    subset_to_country = data_working_copy[data_working_copy['country_id'] == cid_int]\n",
    "    conflict_profile = {col: subset_to_country[col].sum() for col in ['ged_sb', 'ged_ns', 'ged_os', 'fatalities_sum']}\n",
    "\n",
    "    df_annual = native_per_capita_fatalities(subset_to_country)\n",
    "    df_annual['percapita_100k'] = df_annual['percapita_100k'].round(1)\n",
    "\n",
    "    percentile_df = format_stats(df_annual, field_to_describe='fatalities_sum') #or 'percapita_100k'\n",
    "    filtered_x = clean_percentile_table(percentile_df)\n",
    "    insurance_table_df = insurance_table(filtered_x, df_annual, ['90','95','98','99','100'], attribute_to_explore= 'fatalities_sum') #uses the default attribute = percapita_100k and appened_1_value = yes\n",
    "    annual_summary = annual_summary_table(df_annual, 'standard', fat_or_pcf='fatalities_sum') #or 'percapita_100k'\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- SET DIRECTORIES \n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- THIS SETS A DIRECTORY THAT IS UNIQUE UNIQUE STANDARD METHOD ----\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- <<< working just with the 'Cell Year' Return Period Process >>>-\n",
    "    output_path = base_dir + '/notebooks/methods/Country_Results/' + country + '/Standard/Country Year/FAO tables/'\n",
    "    ensure_directory_exists(output_path)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    annual_summary_file_path = output_path + country + ' annual summary.csv'\n",
    "    print(f'saving annual_summary table to: {annual_summary_file_path}')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    insurance_table_file_path = output_path + country + ' insurance table.csv'\n",
    "    print(f'saving insurance table to: {insurance_table_file_path}')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    main_dataframe_file_path = output_path + country + ' main dataframe.csv'\n",
    "    print(f'saving main dataframe table to: {main_dataframe_file_path}')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- NOW WE WRITE TO THE FOLDERS. -----------------------------------\n",
    "    annual_summary.to_csv(annual_summary_file_path)\n",
    "    insurance_table_df.to_csv(insurance_table_file_path)\n",
    "    df_annual.to_csv(main_dataframe_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_profile, df_annual, annual_summary, insurance_table_df = standard_Country_Year_files(data_working_copy, 'Ethiopia', 'fatalities_sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process for Event Year Return Period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "\n",
    "    conflict_profile, df_annual, annual_summary, insurance_table_df = standard_Country_Year_files(data, country, 'fatalities_sum') #or 'percapita_100k'\n",
    "\n",
    "    df_annual = df_annual.rename(columns={'GIS__Index': 'priogrid_gid'})\n",
    "    cumulative_distribution = calculate_cumulative_distribution(df_annual, 'fatalities_sum') #or 'percapita_100k'\n",
    "\n",
    "    #calculate_probabilities(cumulative_distribution, data, id_column='percapita_100k'):\n",
    "    probabilities = calculate_probabilities(cumulative_distribution, df_annual, 'pg_id')\n",
    "    #print(probabilities)\n",
    "    probabilities['E_i'] = calculate_expected_time_periods(probabilities['P_i'])\n",
    "    # Calculate E_i^voxels\n",
    "    probabilities['E_i_voxels'] = calculate_expected_voxels(probabilities['p_i'])\n",
    "    probabilities_renamed = probabilities.rename(columns={'value': 'fatalities_sum'}) #or 'percapita_100k'\n",
    "    print(probabilities_renamed.head(100))\n",
    "\n",
    "    probabilities_with_empirical = compare_empirical_vs_expected(df_annual, probabilities_renamed, time_column='year', value_column='fatalities_sum') #or 'percapita_100k'\n",
    "    probabilities_with_empirical_sorted = probabilities_with_empirical.sort_values(by='E_i_value')\n",
    "    subset_E_i = probabilities_with_empirical_sorted[probabilities_with_empirical_sorted['E_i_value'] >= 4.0]\n",
    "    insurance_from_E_i = insurance_table_for_E_i([5,10,20,30], subset_E_i, df_annual, value_field='fatalities_sum') #or 'percapita_100k'\n",
    "    insurance_from_E_i = insurance_from_E_i.round({\n",
    "        'closest r.p.': 1,\n",
    "        'fatalities_sum': 1, #or 'percapita_100k'\n",
    "    })\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- SET DIRECTORIES \n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- THIS SETS A DIRECTORY THAT IS UNIQUE FOR AGGREGATION METHOD ----\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- <<< working just with the 'Cell Year' Return Period Process >>>-\n",
    "    output_path = base_dir + '/notebooks/methods/Country_Results/' + country + '/Standard/Event year/FAO tables/'\n",
    "    ensure_directory_exists(output_path)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    E_i_insurance_table_file_path = output_path + country + 'Event year insurance table.csv'\n",
    "    print(f'saving insurance table to: {E_i_insurance_table_file_path}')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "    event_year_probabilities_file_path = output_path + ' Event year probabilities.csv'\n",
    "    print(f'saving main dataframe table to: {event_year_probabilities_file_path}')\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#----- NOW WE WRITE TO THE FOLDERS. -----------------------------------\n",
    "    insurance_from_E_i.to_csv(E_i_insurance_table_file_path)\n",
    "    probabilities_with_empirical_sorted.to_csv(event_year_probabilities_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_profile, df_annual, annual_summary, insurance_from_E_i = standard_Event_Year_files(data_working_copy, 'Ethiopia', 'Standard', 'Event year', 'fatalities_sum')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
