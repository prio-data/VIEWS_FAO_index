{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import json\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "# set path to the utils\n",
    "notebook_dir = os.getcwd()\n",
    "notebook_name = \"correct_return_periods.ipynb\"\n",
    "\n",
    "PATH = Path(notebook_dir) / Path(notebook_name) \n",
    "\n",
    "sys.path.insert(0, str(Path(*[i for i in PATH.parts[:PATH.parts.index(\"VIEWS_FAO_index\")+1]]) / \"src/utils\"))   \n",
    "\n",
    "from set_paths import setup_project_paths, get_logo_path, get_data_paths, setup_root_paths\n",
    "setup_project_paths(PATH)\n",
    "\n",
    "\n",
    "#from utils_plotting import plot_time_series, plot_random_monthly_and_yearly_data, plot_feature_histograms, plot_contry_period_map\n",
    "from utils_annual_aggregation import aggregate_monthly_to_yearly\n",
    "from utils_feature_eng_per_100k import feature_eng_fat_per_100k\n",
    "from utils_p_i import calculate_p_i\n",
    "from utils_P_i import calculate_P_i\n",
    "\n",
    "#from utils_likelihoods import calculate_likelihood_of_at_least_one_event\n",
    "\n",
    "from utils_return_periods import calculate_return_periods\n",
    "\n",
    "#from utils_global_probabilities import calculate_global_probabilities\n",
    "#from utils_country_probabilities import calculate_all_country_probabilities\n",
    "#from utils_check_expected_features import check_expected_features    \n",
    "#from utils_date_index import calculate_date_from_index \n",
    "#from utils_country_id_csv_to_json import country_id_csv_to_json\n",
    "\n",
    "from utils_get_country_names_by_ids import get_country_names_by_ids\n",
    "from utils_get_country_id_by_name import get_country_id_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "2.2.1\n",
      "3.8.4\n",
      "0.13.2\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__) # 1.26.4 used\n",
    "print(pd.__version__) # 2.2.1 used\n",
    "print(matplotlib.__version__) # 3.8.4 used\n",
    "print(sns.__version__) # 0.13.2 used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_RAW_VIEWSER, PATH_RAW_EXTERNAL, PATH_PROCESSED, PATH_GENERATED = get_data_paths(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the data from pkl\n",
    "# df_monthly = pd.read_pickle(PATH_RAW_VIEWSER / \"simon_full_base_01_viewser_df.pkl\")\n",
    "# \n",
    "# df_yearly = aggregate_monthly_to_yearly(df_monthly)\n",
    "# \n",
    "# # Feature engineering\n",
    "# df_monthly = feature_eng_fat_per_100k(df_monthly)\n",
    "# df_yearly = feature_eng_fat_per_100k(df_yearly)\n",
    "# \n",
    "# # save the data\n",
    "# df_monthly.to_pickle(PATH_PROCESSED / \"df_monthly_new.pkl\")  \n",
    "# df_yearly.to_pickle(PATH_PROCESSED / \"df_yearly_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_monthly = pd.read_pickle(PATH_PROCESSED / \"df_monthly_new.pkl\")\n",
    "df_yearly = pd.read_pickle(PATH_PROCESSED / \"df_yearly_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 'Mali'), (120, 'Somalia'), (161, 'Malawi')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_id_by_name(\"Mali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_with_probabilities_and_return_periods_pretest(df, feature):\n",
    "\n",
    "    # check that it is a pandas dataframe\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError('df is not a pandas dataframe')\n",
    "\n",
    "    # check the df is not empty\n",
    "    if df.empty:\n",
    "        raise ValueError('DataFrame is empty')\n",
    "\n",
    "    # checkt that the time period is present\n",
    "    time_period_column = ['month_id', 'year_id']\n",
    "    if time_period_column[0] not in df.columns or time_period_column[1] not in df.columns:\n",
    "        raise ValueError('Time period not found')\n",
    "\n",
    "    # check that the other relevant columns are present\n",
    "    relevant_columns = ['pg_id', 'c_id', 'row', 'col', feature]\n",
    "    for column in relevant_columns:\n",
    "        if column not in df.columns:\n",
    "            raise ValueError(f'{column} not found in df')\n",
    "\n",
    "    # check that the feature is not empty\n",
    "    if df[feature].isnull().all():\n",
    "        raise ValueError(f'{feature} is empty')\n",
    "\n",
    "    # check that the feature is not negative\n",
    "    if (df[feature] < 0).any():\n",
    "        raise ValueError(f'{feature} contains negative values')\n",
    "\n",
    "    # check for null, inf and nan\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError('DataFrame contains NaN values')\n",
    "\n",
    "    if np.isinf(df.values).any():\n",
    "        raise ValueError('DataFrame contains infinite values')\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_time_period(df):\n",
    "    if 'month_id' in df.columns:\n",
    "        return 'month_id'\n",
    "    \n",
    "    elif 'year_id' in df.columns:\n",
    "        return 'year_id'\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Time period not found')\n",
    "    \n",
    "\n",
    "def check_region_id(region_id_type, region_id, df):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if region_id_type == 'pg_ids':\n",
    "        # chekc that the region_id is present in the df pg_ids\n",
    "        if region_id not in df['pg_id'].unique():\n",
    "            raise ValueError(f'{region_id} not found in pg_id column')\n",
    "        \n",
    "    elif region_id_type == 'c_ids':\n",
    "        # chekc that the region_id is present in the df c_ids\n",
    "        if region_id not in df['c_id'].unique():\n",
    "            raise ValueError(f'{region_id} not found in c_id column')\n",
    "        \n",
    "    elif region_id_type == 'global':\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'{region_id_type} not recognized')\n",
    "\n",
    "    return True\n",
    "\n",
    "def subset_regional_df(df, region_id_type, region_id):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if region_id_type == 'pg_ids':\n",
    "        sub_df = df[df['pg_id'] == region_id].copy()\n",
    "        \n",
    "    elif region_id_type == 'c_ids':\n",
    "        sub_df = df[df['c_id'] == region_id].copy()\n",
    "        \n",
    "    elif region_id_type == 'global':\n",
    "        sub_df = df.copy()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'{region_id_type} not recognized')\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "def update_df_with_probabilities_and_return_periods(df, feature, region_id_type, region_id):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    update_df_with_probabilities_and_return_periods_pretest(df, feature)\n",
    "    check_region_id(region_id_type, region_id, df)\n",
    "    time_period = get_time_period(df)\n",
    "\n",
    "    # sub set the df according to the region_id_type and region_id - if global, then the whole df is used but we still do this for consistency\n",
    "    sub_df = subset_regional_df(df, region_id_type, region_id)\n",
    "\n",
    "\n",
    "    feature_series = sub_df[feature]\n",
    "    n_cells = sub_df['pg_id'].unique().shape[0] # THIS WOULD ONLT CHANGE IF WE AGGREGATE THE PRIO GRID CELLS\n",
    "\n",
    "    # calculate the probabilities and return periods\n",
    "    df_probabilities = calculate_p_i(feature_series)\n",
    "    df_probabilities = calculate_P_i(df_probabilities, n_cells)\n",
    "    df_probabilities = calculate_return_periods(df_probabilities)\n",
    "\n",
    "    # rename the calculated columns to match the original df feature\n",
    "    df_probabilities.rename(columns={'value': feature, 'value_count' : f'{feature}_value_count', 'p_i' : f\"{feature}_p_i\", 'P_i' : f\"{feature}_P_i\", 'e_i' : f\"{feature}_e_i\", 'E_i' : f\"{feature}_E_i\"}, inplace=True)\n",
    "\n",
    "    # Merge\n",
    "    merged_df = pd.merge(df, df_probabilities, on=[feature], how='left')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_monthly\n",
    "contry_id = 50\n",
    "feature = 'fatalities_per_100k'\n",
    "region_id_type = 'c_ids' # pg_ids, c_ids, or global\n",
    "region_id = contry_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_id</th>\n",
       "      <th>pg_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year_id</th>\n",
       "      <th>c_id</th>\n",
       "      <th>col</th>\n",
       "      <th>row</th>\n",
       "      <th>sb_best</th>\n",
       "      <th>ns_best</th>\n",
       "      <th>os_best</th>\n",
       "      <th>...</th>\n",
       "      <th>total_best</th>\n",
       "      <th>fatalities_per_100k</th>\n",
       "      <th>sb_per_100k</th>\n",
       "      <th>ns_per_100k</th>\n",
       "      <th>os_per_100k</th>\n",
       "      <th>fatalities_per_100k_value_count</th>\n",
       "      <th>fatalities_per_100k_p_i</th>\n",
       "      <th>fatalities_per_100k_P_i</th>\n",
       "      <th>fatalities_per_100k_e_i</th>\n",
       "      <th>fatalities_per_100k_E_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>62356</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>192</td>\n",
       "      <td>436</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>79599</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>192</td>\n",
       "      <td>399</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>79600</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>192</td>\n",
       "      <td>400</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>79601</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>192</td>\n",
       "      <td>401</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>80317</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>192</td>\n",
       "      <td>397</td>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_id  pg_id  month  year_id  c_id  col  row  sb_best  ns_best  os_best  \\\n",
       "0       109  62356      1     1989   192  436   87      0.0      0.0      0.0   \n",
       "1       109  79599      1     1989   192  399  111      0.0      0.0      0.0   \n",
       "2       109  79600      1     1989   192  400  111      0.0      0.0      0.0   \n",
       "3       109  79601      1     1989   192  401  111      0.0      0.0      0.0   \n",
       "4       109  80317      1     1989   192  397  112      0.0      0.0      0.0   \n",
       "\n",
       "   ...  total_best  fatalities_per_100k  sb_per_100k  ns_per_100k  \\\n",
       "0  ...         0.0                  0.0          0.0          0.0   \n",
       "1  ...         0.0                  0.0          0.0          0.0   \n",
       "2  ...         0.0                  0.0          0.0          0.0   \n",
       "3  ...         0.0                  0.0          0.0          0.0   \n",
       "4  ...         0.0                  0.0          0.0          0.0   \n",
       "\n",
       "   os_per_100k  fatalities_per_100k_value_count  fatalities_per_100k_p_i  \\\n",
       "0          0.0                         177459.0                      1.0   \n",
       "1          0.0                         177459.0                      1.0   \n",
       "2          0.0                         177459.0                      1.0   \n",
       "3          0.0                         177459.0                      1.0   \n",
       "4          0.0                         177459.0                      1.0   \n",
       "\n",
       "   fatalities_per_100k_P_i  fatalities_per_100k_e_i  fatalities_per_100k_E_i  \n",
       "0                      1.0                      1.0                      1.0  \n",
       "1                      1.0                      1.0                      1.0  \n",
       "2                      1.0                      1.0                      1.0  \n",
       "3                      1.0                      1.0                      1.0  \n",
       "4                      1.0                      1.0                      1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = update_df_with_probabilities_and_return_periods(df, feature, region_id_type, region_id)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETTER NAMING BEFORE ANYTHING ELSE!!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'liklihood' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m return_periods \u001b[38;5;241m=\u001b[39m calculate_return_periods(\u001b[43mliklihood\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcdf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlikelihood\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'liklihood' is not defined"
     ]
    }
   ],
   "source": [
    "return_periods = calculate_return_periods(liklihood, 'cdf', 'likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liklihood['cdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(liklihood, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_periods = calculate_return_periods(cdf, liklihood, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
