{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import glob\n",
    "\n",
    "#some extra functions for some of the later demonstration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "#Define QuerySet\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_base_PG = (Queryset(\"Benz_PG_CF\", \"priogrid_month\")\n",
    "\n",
    "    .with_column(Column(\"country_name\", from_table = \"country\", from_column = \"name\")\n",
    "        .transform.missing.replace_na()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"year_id\", from_table = \"country_year\", from_column = \"year_id\")\n",
    "        )\n",
    "\n",
    "    # target variable\n",
    "    .with_column(Column(\"ged_sb\", from_table = \"ged2_pgm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"ged_ns\", from_table = \"ged2_pgm\", from_column = \"ged_ns_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ged_os\", from_table = \"ged2_pgm\", from_column = \"ged_os_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"sb_count\", from_table = \"ged2_pgm\", from_column = \"ged_sb_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ns_count\", from_table = \"ged2_pgm\", from_column = \"ged_ns_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"os_count\", from_table = \"ged2_pgm\", from_column = \"ged_os_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "    .with_column(Column(\"pop_gpw_sum\", from_table=\"priogrid_year\", from_column=\"pop_gpw_sum\")\n",
    "        \n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_base_CM = (Queryset(\"Benz_PG_CF\", \"country_month\")\n",
    "\n",
    "    .with_column(Column(\"country_name\", from_table = \"country\", from_column = \"name\")\n",
    "        .transform.missing.replace_na()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"year_id\", from_table = \"country_year\", from_column = \"year_id\")\n",
    "        )\n",
    "\n",
    "    # target variable\n",
    "    .with_column(Column(\"ged_sb\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"ged_ns\", from_table = \"ged2_cm\", from_column = \"ged_ns_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ged_os\", from_table = \"ged2_cm\", from_column = \"ged_os_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"sb_count\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ns_count\", from_table = \"ged2_cm\", from_column = \"ged_ns_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"os_count\", from_table = \"ged2_cm\", from_column = \"ged_os_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "    .with_column(Column(\"pop_gpw_sum\", from_table=\"wdi_cy\", from_column=\"wdi_sp_pop_totl\")\n",
    "        \n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories to set:\n",
    "\n",
    "Change_to_your_local_drive = '/Users/gbenz/Documents/Food Security and Conflict/GIT'\n",
    "Established_GIT_DIR = '/VIEWS_FAO_index/notebooks/Benz_experiments/Aggregation_Key_Tables/'\n",
    "\n",
    "aggregation_tables_dir = Change_to_your_local_drive + Established_GIT_DIR\n",
    "#base_path = f'/Users/gbenz/Documents/Food Security and Conflict/'\n",
    "#source_PG_dir = '/Users/gbenz/Documents/Common Data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This toolbox considers 3 primary paramters\n",
    "\n",
    "**Parameter 1:** Is this analysis employing PGM or CM data?<br><br>\n",
    "**Parameter 2:** What level of SPACE aggregation is the user interested in?<br>\n",
    "*Options include -- Original PrioGRid aggregation 1x1 or courser aggregations 2x2, 3x3, 4x4, 5x5, 6x6, 8x8, 9x9, and 10x10*<br><br>\n",
    "**Parameter 3:** What level of TIME aggregation is the user interested in?<br><br>\n",
    "*Options include -- Original PrioGRid monthly resolution and annual*<br>\n",
    "Note that within this time parameter, the range of available data is fixed between 1989-2022.<br><br>\n",
    "**Parameter 4:** Define the processing extent to apply space and time factors<br><br>\n",
    "**Parameter 5:** Establish what statistics to generate for the Unit of Analysis and designated Area of Responsibility'<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGM_preprocess(table):\n",
    "\n",
    "    #replace NA Population values with 0\n",
    "    table['pop_gpw_sum'] = table['pop_gpw_sum'].replace({np.nan:0})\n",
    "\n",
    "    table['Fatalities_Sum'] = table['ged_sb'] + table['ged_ns'] + table['ged_os']\n",
    "    table['PerCapitaFatalities'] = table['Fatalities_Sum'] / table['pop_gpw_sum']\n",
    "    table['PerCapitaFatalities'] = table['PerCapitaFatalities'].replace({np.nan:0})\n",
    "\n",
    "    table = table.drop(['ged_sb','ged_ns','ged_os','sb_count','ns_count','os_count'], axis = 1)\n",
    "\n",
    "    return(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_infinity_values(base_table,CM__or__PG, resolution=0):\n",
    "\n",
    "    if resolution == 0:\n",
    "        res = '_'\n",
    "    else:\n",
    "        res = resolution\n",
    "\n",
    "    CM__or__PGstr = CM__or__PG+'_'\n",
    "\n",
    "    base_table['PerCapitaFatalities'] = base_table['PerCapitaFatalities'].replace([np.inf, -np.inf], np.nan)\n",
    "    Anamoly = base_table[base_table['PerCapitaFatalities'].isna()]\n",
    "    Anamoly.to_csv(f'/Users/gbenz/Documents/Food Security and Conflict/{CM__or__PGstr}{res}Fatality_NoPop.csv')\n",
    "    base_table['PerCapitaFatalities'] = base_table['PerCapitaFatalities'].replace({np.nan:0})\n",
    "\n",
    "    return(base_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRIO_Aggregation(table,time,CMorPG,scale=0,country=0):\n",
    "    \n",
    "    import glob\n",
    "\n",
    "    CM_or_PG = CMorPG\n",
    "    c = np.isinf(table['PerCapitaFatalities']).values.sum() \n",
    "\n",
    "    if c > 0:    \n",
    "        table=report_infinity_values(table,CM_or_PG)\n",
    "\n",
    "    if time == 'monthly':\n",
    "        time_attribute = 'month_id'\n",
    "    elif time == 'annual':\n",
    "        time_attribute = 'year_id'\n",
    "\n",
    "    if scale == '1x1':\n",
    "        table = table.rename(columns={'priogrid_gid':'Scale_ID'})\n",
    "        table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "        table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "        if country == 0:\n",
    "            return(table)\n",
    "        else:\n",
    "            selected_country=table[table['Included_Countries'].isin([country])]\n",
    "            return(selected_country)\n",
    "        \n",
    "    elif scale == 0:\n",
    "        table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "        table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "        return(table) \n",
    "    #--------------------------------------------------\n",
    "    else:\n",
    "        source_PG_aggregation_dir = '/Users/gbenz/Documents/Common Data/PG Aggregation/'\n",
    "        allFiles = glob.glob(source_PG_aggregation_dir + \"/*.csv\")\n",
    "\n",
    "        for filename in allFiles:\n",
    "                if scale in filename:\n",
    "                    print(filename)\n",
    "                    break\n",
    "        Aggregation_file = filename\n",
    "\n",
    "        single_res = int(scale.split('x')[0])\n",
    "\n",
    "        Expected = single_res ** 2\n",
    "\n",
    "        pg_AG = pd.read_csv(Aggregation_file)\n",
    "\n",
    "        pg_AG['gid'] = pg_AG['gid'].astype(str)\n",
    "        pg_AG['Id'] = pg_AG['Id'].astype(str)\n",
    "\n",
    "        pg_AG['Scale_ID'] = pg_AG.groupby(['Id'])['gid'].transform(lambda x : '_'.join(x))\n",
    "\n",
    "        pg_AG['gid'] = pg_AG['gid'].astype('int64')\n",
    "        pg_AG['Id'] = pg_AG['Id'].astype('int64')\n",
    "    #A method to get rows that communicate 1. Each indivdiual geospatial abstract id and corresponding PRIOgrid ID \n",
    "        pg_AG__FOR_VALIDATE = pg_AG.groupby(['Id','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "        pg_AG__FOR_VALIDATE = pg_AG__FOR_VALIDATE.sort_values(by='Scale_ID')\n",
    "\n",
    "        pg__AG = pg_AG.groupby('Scale_ID')['gid'].apply(list)\n",
    "        pg__AG__dic = pg__AG.to_dict()\n",
    "\n",
    "        table['Scale_ID'] = table.priogrid_gid.map({item: k for k, v in pg__AG__dic.items() for item in v})\n",
    "        df_2022 = table.sort_values(by=['Scale_ID','priogrid_gid'], ascending=[False,True])\n",
    "\n",
    "    #changes here --\n",
    "        withcountry = df_2022.groupby(['Scale_ID','country_name']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "        withcountry['Country_present'] = withcountry.groupby(['Scale_ID'])['country_name'].transform(lambda x : '___'.join(x))\n",
    "        withcountry = withcountry.drop(['country_name'], axis=1).drop_duplicates()\n",
    "        withcountry__dic = dict(zip(withcountry.Scale_ID, withcountry.Country_present))\n",
    "    #---------\n",
    "        check = df_2022.groupby(['priogrid_gid','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "        check = check.sort_values(by='Scale_ID')\n",
    "\n",
    "        check_PGID = check.groupby(['Scale_ID']).size().to_frame().reset_index()\n",
    "        check_PGID = check_PGID.rename(columns = {0:'Size'})\n",
    "        check_PGID = check_PGID.sort_values(by='Size')\n",
    "        less_than_expected = check_PGID[check_PGID['Size'] < Expected]\n",
    "        print(less_than_expected)\n",
    "        less_than_expected.to_csv('/Users/gbenz/Documents/Common Data/inf_FPC.csv')\n",
    "\n",
    "        df_2022_grouped = df_2022.groupby([time_attribute,'Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "\n",
    "        if country == 0:\n",
    "            return(df_2022_grouped)\n",
    "        else:\n",
    "            df_2022_grouped['Countries_In_AG_Unit']= df_2022_grouped['Scale_ID'].map(withcountry__dic)\n",
    "            df_2022_grouped['Included_Countries'] = df_2022_grouped['Countries_In_AG_Unit'].str.split('___')\n",
    "            selected_country = df_2022_grouped.loc[df_2022_grouped['Included_Countries'].explode().eq(country).loc[lambda x: x].index]\n",
    "            selected_country = selected_country.drop('Included_Countries', axis=1)\n",
    "            return(selected_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_length(data, PG_or_CM, scale, time, resolution):\n",
    "\n",
    "    if scale == 'Individual':\n",
    "        s = 'This individual'\n",
    "    elif scale == 'Global':\n",
    "        s = ' The global'\n",
    "\n",
    "    if resolution == 0:\n",
    "        res = ''\n",
    "    else:\n",
    "        res = 'and ' + resolution + ' resolution'\n",
    "\n",
    "    if time == 'monthly':\n",
    "        t = 'month_id'\n",
    "    elif time == 'annual':\n",
    "        t = 'year_id'\n",
    "\n",
    "    events_df_2022 = len(data)\n",
    "    PG_totalcells = len(pd.unique(data['Scale_ID']))\n",
    "    PG_totalmonths = len(pd.unique(data[t])) \n",
    "    return(f'{s} {PG_or_CM} level {res} contains {events_df_2022} events.\\nThis is calculated from {PG_totalcells} * {PG_totalmonths}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array(arange(70, 100.1, 0.1))\n",
    "divisor = 100\n",
    "p_div = p/divisor\n",
    "l = p_div.tolist()\n",
    "l_3dec = [ round(elem, 3) for elem in l ]\n",
    "\n",
    "#percentile = [.5,.7,.8,.81,.82,.83,.84,.85,.86,.87,.88,.89,.9,.95,.98,.99,.991,.992,.993,.994,.995,.996,.997,.998,.999,1]\n",
    "print(l_3dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Format_summary_stats(PG_or_CM, table_to_describe,field_to_describe,zero__or__non_zero):\n",
    "    \n",
    "    p = np.array(arange(40, 100.1, 0.1))\n",
    "    divisor = 100\n",
    "    p_div = p/divisor\n",
    "    l = p_div.tolist()\n",
    "    l_3dec = [round(elem, 3) for elem in l ]\n",
    "\n",
    "    if field_to_describe == 'Fatalities_Sum':\n",
    "        SummaryField = 'Fatalities'\n",
    "\n",
    "    elif field_to_describe == 'PerCapitaFatalities':\n",
    "        SummaryField = 'Fatalities Per Capita'\n",
    "\n",
    "    if zero__or__non_zero == 'zero' and PG_or_CM == 'PG':\n",
    "        #percentile = [.5,.7,.8,.85,.9,.95,.98,.99,.991,.992,.993,.994,.995,.996,.997,.998,.999,1]\n",
    "        data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=l_3dec)})\n",
    "\n",
    "    elif zero__or__non_zero == 'zero' and PG_or_CM == 'CM':\n",
    "        #percentile = [.5,.7,.8,.81,.82,.83,.84,.85,.86,.87,.88,.89,.9,.95,.98,.99,.991,.992,.993,.994,.995,.996,.997,.998,.999,1]\n",
    "        data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=l_3dec)})\n",
    "\n",
    "    elif zero__or__non_zero == 'non-zero':\n",
    "        attribute_nozero=table_to_describe[table_to_describe[field_to_describe]!= 0]\n",
    "        length_of_attribute_nozero = len(attribute_nozero)\n",
    "        percentile = [0,.25,.5,.75,.8,.85,.9,.95,.99,.995,1]\n",
    "        data = pd.DataFrame({SummaryField: attribute_nozero[field_to_describe].describe(percentiles=percentile)})\n",
    "\n",
    "    #data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=percentile)})\n",
    "    data = data.reset_index()\n",
    "    data = data.rename(columns={'index':'Percentile'})\n",
    "    data = data.iloc[4:][:-1]\n",
    "    data['Percentile'] = data['Percentile'].str[:-1]\n",
    "\n",
    "    if field_to_describe == 'Fatalities_Sum' and zero__or__non_zero == 'non-zero':\n",
    "        data['Fatalities'] = (data['Fatalities']).astype(int)\n",
    "        #attribute_nozero=table_to_describe[table_to_describe['Fatalities_Sum']!= 0]\n",
    "        return(attribute_nozero, data, length_of_attribute_nozero)\n",
    "\n",
    "    elif field_to_describe == 'Fatalities_Sum' and zero__or__non_zero == 'zero':\n",
    "        data['Fatalities'] = (data['Fatalities']).astype(int)\n",
    "        return(data)\n",
    "\n",
    "    elif field_to_describe == 'PerCapitaFatalities' and zero__or__non_zero == 'non-zero':\n",
    "        #attribute_nozero=table_to_describe[table_to_describe['PerCapitaFatalities']!= 0]\n",
    "        return(attribute_nozero, data, length_of_attribute_nozero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_zero_percentiles(insert_percentile):\n",
    "    float_percentile_at_1 = float(insert_percentile)\n",
    "    if float_percentile_at_1 >= 99.5:\n",
    "        sub_perc = [99.7, 99.8, 99.9, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 99.5 and float_percentile_at_1 >= 99:\n",
    "        sub_perc = [99.5, 99.7, 99.9, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 99 and float_percentile_at_1 >= 98:\n",
    "        sub_perc = [99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 98 and float_percentile_at_1 >= 95:\n",
    "        sub_perc = [99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 95 and float_percentile_at_1 >= 90:\n",
    "        sub_perc = [95, 99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 90 and float_percentile_at_1 >= 85:\n",
    "        sub_perc = [90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 85 and float_percentile_at_1 >= 80:\n",
    "        sub_perc = [85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 80 and float_percentile_at_1 >= 70:\n",
    "        sub_perc = [80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "    \n",
    "    elif float_percentile_at_1 < 70 and float_percentile_at_1 >= 50:\n",
    "        sub_perc = [70, 80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "    \n",
    "    elif float_percentile_at_1 <50:\n",
    "        sub_perc = [50, 75, 80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_definition_df(definition_dataframe,original_dataframe,zero__or__nonzero,single_cell_analysis,PG__or__CM='PG',single_cell_analysis_percentiles=[99,95]):\n",
    "\n",
    "    check_list = list(definition_dataframe)\n",
    "\n",
    "    if 'Fatalities' in check_list:\n",
    "        #attribute_nozero=original_dataframe[original_dataframe['Fatalities_Sum']!= 0]\n",
    "        #return(Fatalities_nozero)\n",
    "\n",
    "        if zero__or__nonzero == 'zero':\n",
    "            percentile_at_1 = list(definition_dataframe.loc[definition_dataframe['Fatalities'] == 1, 'Percentile'])[0]\n",
    "            sub_perc=represent_zero_percentiles(percentile_at_1)\n",
    "\n",
    "            search_P = list(map(str, sub_perc))\n",
    "            print(search_P)\n",
    "            definition_dataframe['Percentile'] = definition_dataframe['Percentile'].astype('string')\n",
    "            from_sub_perc = definition_dataframe[definition_dataframe['Percentile'].isin(search_P)]\n",
    "            #sub_perc = ['84','90','95','99','99.5','100']\n",
    "            #definition_dataframe['Percentile'] = definition_dataframe['Percentile'].astype('string')\n",
    "            #from_sub_perc = definition_dataframe[definition_dataframe['Percentile'].isin(sub_perc)]\n",
    "            #from_sub_perc = definition_dataframe[definition_dataframe['Percentile'] in sub_perc]\n",
    "            #match_p = definition_dataframe.loc[definition_dataframe['Percentile'] == i]\n",
    "            def_values = from_sub_perc['Fatalities'].unique()\n",
    "            print(def_values)\n",
    "        else:\n",
    "            def_values = definition_dataframe['Fatalities'].unique()\n",
    "        id_fatality = []\n",
    "        id_triggers = []\n",
    "        id_p = []\n",
    "            \n",
    "    if 'Fatalities Per Capita' in check_list:\n",
    "        def_values = definition_dataframe['Fatalities Per Capita'].unique()\n",
    "        id_percapita = []\n",
    "        id_triggers = []\n",
    "        id_p = []\n",
    "\n",
    "    collected = pd.DataFrame()\n",
    "\n",
    "    if single_cell_analysis == 'Yes':\n",
    "        def_values = single_cell_analysis_percentiles\n",
    "\n",
    "    for i in def_values:\n",
    "                            if 'Fatalities' in check_list and i == 0.0:\n",
    "                                #if i == 0.0:\n",
    "                                continue\n",
    "                            elif 'Fatalities' in check_list and i != 0.0:\n",
    "                                match_p = definition_dataframe.loc[definition_dataframe['Fatalities'] == i]\n",
    "                                perc = match_p.at[match_p.index[0], 'Percentile']\n",
    "                                limit = original_dataframe.loc[original_dataframe['Fatalities_Sum'] >= i]\n",
    "                                triggers = len(limit.index)\n",
    "                                fatality = i\n",
    "\n",
    "                                id_p.append(perc)\n",
    "                                id_fatality.append(fatality)\n",
    "                                id_triggers.append(triggers)\n",
    "\n",
    "                                Out_Percentile = pd.DataFrame(list(zip(id_p, id_fatality, id_triggers)),\n",
    "                                    columns=['Percentile','Fatalities','Occurance'])\n",
    "                                \n",
    "                            if 'Fatalities Per Capita' in check_list:\n",
    "                                match_p = definition_dataframe.loc[definition_dataframe['Fatalities Per Capita'] == i]\n",
    "                                perc = match_p.at[match_p.index[0], 'Percentile']\n",
    "                                limit = original_dataframe.loc[original_dataframe['PerCapitaFatalities'] >= i]\n",
    "                                triggers = len(limit.index)\n",
    "                                capita = i                        \n",
    "\n",
    "                                id_p.append(perc)\n",
    "                                id_percapita.append(capita)\n",
    "                                id_triggers.append(triggers)\n",
    "\n",
    "                                Out_Percentile = pd.DataFrame(list(zip(id_p, id_percapita, id_triggers)),\n",
    "                                    columns=['Percentile','Fatalities Per Capita','Occurance'])\n",
    "                            \n",
    "    if zero__or__nonzero == 'zero' or single_cell_analysis == 'Yes':\n",
    "           \n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        return(collected)\n",
    "    \n",
    "    elif zero__or__nonzero == 'non-zero'and 'Fatalities Per Capita' in check_list:\n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        collected['Fatalities Per Capita'] = collected['Fatalities Per Capita']*10000\n",
    "        collected['Fatalities Per Capita'] = collected['Fatalities Per Capita'].round(1)\n",
    "        collected = collected.rename(columns={'Fatalities Per Capita':'Per Capita'})\n",
    "        Transpose_desc=collected.transpose()\n",
    "        new_header = Transpose_desc.iloc[0] #grab the first row for the header\n",
    "        Transpose_desc_less = Transpose_desc[1:] #take the data less the header row\n",
    "        Transpose_desc_less.columns = new_header\n",
    "        Transpose_desc_less = Transpose_desc_less.reset_index()\n",
    "        Transpose_desc_less = Transpose_desc_less.rename(columns={'index':'Percentile'})\n",
    "\n",
    "        return(Transpose_desc_less)\n",
    "\n",
    "    elif zero__or__nonzero == 'non-zero' and 'Fatalities' in check_list:\n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        Transpose_desc=collected.transpose()\n",
    "        new_header = Transpose_desc.iloc[0] #grab the first row for the header\n",
    "        Transpose_desc_less = Transpose_desc[1:] #take the data less the header row\n",
    "        Transpose_desc_less.columns = new_header\n",
    "        Transpose_desc_less = Transpose_desc_less.reset_index()\n",
    "        Transpose_desc_less = Transpose_desc_less.rename(columns={'index':'Percentile'})\n",
    "\n",
    "        return(Transpose_desc_less)\n",
    "\n",
    "    #elif zero__or__nonzero != 'zero' or zero__or__nonzero != 'non-zero':\n",
    "        #print('This parameter was incorrectly named. Select from zero or non-zero') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_for_graphs(description,original_df,a,b,c,):\n",
    "\n",
    "    a=str(a)\n",
    "    b=str(b)\n",
    "    c=str(c)\n",
    "\n",
    "    desc_attribute = description.at[0, 'Percentile']\n",
    "    if desc_attribute == 'Fatalities':\n",
    "        attribute = 'Fatalities_Sum'\n",
    "    elif desc_attribute == 'Fatalities Per Capita':\n",
    "        attribute = 'PerCapitaFatalities'\n",
    "\n",
    "    f_fpc=original_df[attribute]\n",
    "    #fpc=df_109_516___Fatalities['PerCapitaFatalities']\n",
    "\n",
    "    #print('trying to now select 85th percentile value')\n",
    "    Select_a_Percentile = description.at[0,a]\n",
    "    Select_b_Percentile = description.at[0,b]\n",
    "    Select_c_Percentile = description.at[0,c]\n",
    "\n",
    "#print(Select_95_Percentile)\n",
    "\n",
    "#print()\n",
    "    Fatalities_a = f_fpc[f_fpc <= Select_a_Percentile]\n",
    "    Fatalities_a_b = f_fpc[(f_fpc > Select_a_Percentile) & (f_fpc <= Select_b_Percentile)]\n",
    "    Fatalities_b_c = f_fpc[(f_fpc > Select_b_Percentile) & (f_fpc <= Select_c_Percentile)]\n",
    "    Fatalities_c = f_fpc[(f_fpc > Select_c_Percentile)]\n",
    "\n",
    "    Fatalities_a = np.sort(Fatalities_a)\n",
    "    cdf_a = 1.0 * np.arange(len(Fatalities_a)) / float(len(Fatalities_a) - 1)\n",
    "    Fatalities_a_b = np.sort(Fatalities_a_b)\n",
    "    cdf_a_b = 1.0 * np.arange(len(Fatalities_a_b)) / float(len(Fatalities_a_b) - 1)\n",
    "    Fatalities_b_c = np.sort(Fatalities_b_c)\n",
    "    cdf_b_c = 1.0 * np.arange(len(Fatalities_b_c)) / float(len(Fatalities_b_c) - 1)\n",
    "    Fatalities_c = np.sort(Fatalities_c)\n",
    "    cdf_c = 1.0 * np.arange(len(Fatalities_c)) / float(len(Fatalities_c) - 1)\n",
    "    return((Fatalities_a,cdf_a), (Fatalities_a_b,cdf_a_b), (Fatalities_b_c,cdf_b_c), (Fatalities_c,cdf_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ax4_params(resolution):\n",
    "\n",
    "    if resolution == '2x2':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 50\n",
    "        ax4_set_xticks = (0,10,20,30,40,50)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "\n",
    "    elif resolution == '3x3':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 60\n",
    "        ax4_set_xticks = (0,15,30,45,60)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "\n",
    "    elif resolution == '4x4':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 75\n",
    "        ax4_set_xticks = (0,15,30,45,60,75)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "    \n",
    "def ax6_params(resolution):\n",
    "\n",
    "    if resolution == '2x2':\n",
    "        ax6_set_xticks = [50,75,100,125,155]\n",
    "        ax6_set_xticks_labels = ['0',' ','100','','155']\n",
    "        ax6_set_yticks = [0,50,100,150,200]\n",
    "        ax6_set_yticks_labels = ['0',' ','100','','200']\n",
    "        return(ax6_set_xticks, ax6_set_xticks_labels, ax6_set_yticks, ax6_set_yticks_labels)\n",
    "\n",
    "    elif resolution == '3x3':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 60\n",
    "        ax4_set_xticks = (0,15,30,45,60)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "\n",
    "    elif resolution == '4x4':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 75\n",
    "        ax4_set_xticks = (0,15,30,45,60,75)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "    \n",
    "def ax8_params(resolution):\n",
    "\n",
    "    if resolution == '2x2':\n",
    "\n",
    "        ax8_set_xticks = (150,250,500,750,1050)\n",
    "        ax8_set_xticks_labels = ['150',' ','500','750','1050']\n",
    "        ax8_set_yticks = [0,25,50,75,100]\n",
    "        ax8_set_yticks_labels = ['0',' ','50','','100']\n",
    "        return(ax8_set_xticks, ax8_set_xticks_labels, ax8_set_yticks, ax8_set_yticks_labels)\n",
    "\n",
    "    elif resolution == '3x3':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 60\n",
    "        ax4_set_xticks = (0,15,30,45,60)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "\n",
    "    elif resolution == '4x4':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 75\n",
    "        ax4_set_xticks = (0,15,30,45,60,75)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "    \n",
    "def ax10_params(resolution):\n",
    "\n",
    "    if resolution == '2x2':\n",
    "        ax10_set_xticks = (1050,25000,50000,100000,200000)\n",
    "        ax10_set_xticks_labels = ['1050',' ','50000','100000','200000']\n",
    "        ax10_set_yticks = [0,5,10]\n",
    "        ax10_set_yticks_labels = ['0','5','10']\n",
    "        ylim = 10\n",
    "        return(ax10_set_xticks, ax10_set_xticks_labels, ax10_set_yticks, ax10_set_yticks_labels, ylim)\n",
    "\n",
    "    elif resolution == '3x3':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 60\n",
    "        ax4_set_xticks = (0,15,30,45,60)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)\n",
    "\n",
    "    elif resolution == '4x4':\n",
    "        ax4_set_ylim_max = 2000\n",
    "        ax4_set_xlim_max = 75\n",
    "        ax4_set_xticks = (0,15,30,45,60,75)\n",
    "        return(ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_axes(ax, text, fontsize=18):\n",
    "        ax.text(0.5, 0.5, text, transform=ax.transAxes,\n",
    "                ha=\"center\", va=\"center\", fontsize=fontsize, color=\"darkgrey\")\n",
    "\n",
    "    #def statsheet(zerotable, nonzerotable_Fatality, nonzerotable_fpc, hist1, cdf1, hist2, cdf2, hist3, cdf3, hist4, cdf4, timeseries):    \n",
    "def statsheet(zerotable, nonzerotable_Fatality, nonzerotable_fpc, hist1, cdf1, hist2, cdf2, hist3, cdf3, hist4, cdf4, timeline, resolution=0):    \n",
    "\n",
    "    #nonzerotable_fpc['Fatalities Per Capita'] = nonzerotable_fpc['Fatalities Per Capita']*10000\n",
    "    #nonzerotable_fpc['Fatalities Per Capita'] = nonzerotable_fpc['Fatalities Per Capita'].round(1)\n",
    "\n",
    "    #if resolution != 0:\n",
    "    res = resolution\n",
    "\n",
    "    #For timeline--------------------------v\n",
    "    timeline_month_fatalitytotal = timeline.groupby([\"month_id\"]).Fatalities_Sum.sum().reset_index().reset_index()\n",
    "\n",
    "    timeline_month_fatalities20000 = timeline_month_fatalitytotal.loc[timeline_month_fatalitytotal['Fatalities_Sum']>20000]\n",
    "\n",
    "    index_to_color = timeline_month_fatalities20000['index']\n",
    "    #--------------------------------------^\n",
    "\n",
    "    units_of_analysis = '13000'\n",
    "    percent_zero_fromtable = '99.3%'\n",
    "    percent_nonzero_fromtable ='.6%'\n",
    "    total_nonzero_fromtable = '1300'\n",
    "    inf_total = '7'\n",
    "    MissingData1 ='Y# occurances of 2 or less# fatalities and Y# occurances of 3-5 fatalities.'\n",
    "    MissingData2 = 'Y# counts of fatalities between n and n'\n",
    "    MissingData3 = 'XXXXXXX# fatalities were recorded between XX and XX of XXXX, XXXXXX in XX-XX, XXXXXXXX# in XX-XX, and XXXXX# in XX-XX'\n",
    "    inputtext = 'In this text I want to summarize:\\nalso, the per capita row reflects 1/10,000 individuals 1. The definition of event in this iteration 2.The total number of Events.\\n Including how many months and the month ranges. Describe the graphs \\n why do the total fatalities not match the total PCF (becuse 7 events in area with no population\\n This is the last line that you have room for!'\n",
    "    inputtext = f'Defining an event, summarizing fatalities, as a 1x1 standard PRIO Grid across a monthly temporal resolution produced {units_of_analysis} units of analysis. Summary tables\\n discriminate between events reflecting zero and non-zero fatality results. At the employed unit scale, zero fatalities account for {percent_zero_fromtable} of all events. The remaining\\n tables and graphics are constituent to that remaining {percent_nonzero_fromtable} ({total_nonzero_fromtable}) fatalities. Non-zero results from the Per Capita table reflect a unique total from the reported fatalities,\\n {inf_total} events contained fatalities in units with no expected population values. Several graphics host data that is not completely visualized with extreme values exceeding\\n the Y-axis; These locations are indicated by a prominent red bar. The following relationships uncover the obscured information. 1st-85th Percentile: There were\\n {MissingData1} ; 99.5-100th Percentile: {MissingData2}'\n",
    "    \n",
    "    fig = plt.figure(figsize=(11, 8.5), constrained_layout = True)\n",
    "    spec = fig.add_gridspec(7, 4)\n",
    "\n",
    "#Zero table\n",
    "    ax0 = fig.add_subplot(spec[0:3, :-3])\n",
    "    annotate_axes(ax0, 'ax0')\n",
    "    table_ax0 = ax0.table(cellText=zerotable.values,\n",
    "                    colLabels=zerotable.columns,\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    #table_ax0.auto_set_font_size(True)\n",
    "    table_ax0.set_fontsize(8)\n",
    "    ax0.axis('off')\n",
    "    table_ax0.scale(1, 1.65)\n",
    "\n",
    "# Summary Text\n",
    "    ax1 = fig.add_subplot(spec[0, -3:])\n",
    "    #annotate_axes(ax1, 'ax1')\n",
    "    ax1.text(0, 0.5,inputtext, fontsize=6, va='top',wrap='True',\n",
    "                      bbox=dict(facecolor='none', edgecolor='black', boxstyle='round,pad=1'))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('Global 1x1, monthly Stat Sheet')\n",
    "\n",
    "    #ax1.margins(x=-.25)\n",
    "    #text_ax1.scale(-.25, 1)\n",
    "\n",
    "#plt.text(5, 5, input_text, fontsize=10, style='oblique', ha='center', va='top', wrap=True, rotation=-30)\n",
    "\n",
    "#Non-Zero Fatalities\n",
    "    ax2 = fig.add_subplot(spec[1, -3:])\n",
    "    #annotate_axes(ax1, 'ax1')\n",
    "    table_ax2 = ax2.table(cellText=nonzerotable_fpc.values,\n",
    "                    colLabels=nonzerotable_fpc.columns,\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    table_ax2.auto_set_font_size(False)\n",
    "    table_ax2.set_fontsize(6)\n",
    "    ax2.axis('off')\n",
    "    table_ax2.scale(1.0, 1.85)\n",
    "\n",
    "#Non-Zero Fatalities\n",
    "    ax3 = fig.add_subplot(spec[2, -3:])\n",
    "\n",
    "    cellcolours_array = [['#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9','#fef0d9', '#fdcc8a', '#fdcc8a', '#fc8d59', '#fc8d59', '#e34a33',],\n",
    "                        ['#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fdcc8a', '#fdcc8a', '#fc8d59', '#fc8d59', '#e34a33']]\n",
    "\n",
    "    table_ax3 = ax3.table(cellText=nonzerotable_Fatality.values,\n",
    "                    colLabels=nonzerotable_Fatality.columns,\n",
    "                    cellColours=cellcolours_array,\n",
    "                    loc='top',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    table_ax3.auto_set_font_size(False)\n",
    "    table_ax3.set_fontsize(6)\n",
    "    ax3.axis('off')\n",
    "    table_ax3.scale(1, 1.85)\n",
    "\n",
    "    ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks = ax4_params(res)\n",
    "\n",
    "    #Histogram 1-85\n",
    "    ax4 = fig.add_subplot(spec[3, 0])\n",
    "    annotate_axes(ax4, 'ax4')\n",
    "    N, bins, patches_ax4 = ax4.hist(hist1, bins=100, color='black')\n",
    "    ax4.set_title(\"1-85th Percentile\")\n",
    "    for i in range(0,10):\n",
    "        patches_ax4[i].set_facecolor('red')\n",
    "    #ax4.set_xlabel(\"Fatalities\")\n",
    "    ax4.set_ylabel(\"Count of Fatalities\")\n",
    "    ax4.set_ylim(0, ax4_set_ylim_max)\n",
    "    ax4.set_xlim(0, ax4_set_xlim_max)\n",
    "    ax4.set_xticks(ax4_set_xticks)\n",
    "    #ax4.set_yticks((0,500,1000,1500,2000))\n",
    "    ax4.set_yticks(ticks=[0,500,1000,1500,2000],labels=['0',' ','1000','','2000'])\n",
    "\n",
    "    for label in ax4.xaxis.get_ticklabels()[::2]:\n",
    "        label.set_visible(False)\n",
    "    ax4.tick_params(axis='x', labelcolor='white', labelsize=.1)\n",
    "    ax4.set_facecolor('#fef0d9')\n",
    "\n",
    "    #CDF 1-85\n",
    "    ax5 = fig.add_subplot(spec[4, 0])\n",
    "    annotate_axes(ax5, 'ax5')\n",
    "    ax5.plot(hist1, cdf1, color='black')\n",
    "    ax5.set_xlabel(\"Fatalities\")\n",
    "    ax5.set_ylabel(\"Probability\")\n",
    "    ax5.set_title(\"CDF (1-85)\")\n",
    "    ax5.sharex(ax4)\n",
    "    ax5.set_xticks(ax4_set_xticks)\n",
    "    #ax5.set_yticks((0,50,100,200,225))\n",
    "\n",
    "    for label in ax5.xaxis.get_ticklabels()[::2]:\n",
    "        label.set_visible(False)\n",
    "    ax5.xaxis.label.set_color('black')\n",
    "    ax5.set_facecolor('#fef0d9')\n",
    "    \n",
    "    ax6_set_xticks, ax6_set_xticks_labels, ax6_set_yticks, ax6_set_yticks_labels = ax6_params(res)\n",
    "\n",
    "    #Histogram 85-95\n",
    "    ax6 = fig.add_subplot(spec[3, 1])\n",
    "    annotate_axes(ax6, 'ax6')\n",
    "    ax6.hist(hist2, bins=100, color='black')\n",
    "    ax6.set_title(\"85-95th Percentile\")\n",
    "    ax6.tick_params(axis='x', labelcolor='white')\n",
    "    ax6.set_xticks(ticks=ax6_set_xticks, labels=ax6_set_xticks_labels)\n",
    "    #for label in ax6.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax6.set_yticks(ticks=ax6_set_yticks,labels=ax6_set_yticks_labels)\n",
    "    ax6.set_facecolor('#fdcc8a')\n",
    "\n",
    "    #Histogram 85-95\n",
    "    ax7 = fig.add_subplot(spec[4, 1])\n",
    "    annotate_axes(ax7, 'ax7')\n",
    "    ax7.plot(hist2, cdf2, color='black')\n",
    "    ax7.set_title(\"CDF (85-95)\")\n",
    "    ax7.sharex(ax6)\n",
    "    #for label in ax7.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax7.set_facecolor('#fdcc8a')\n",
    "\n",
    "    ax8_set_xticks, ax8_set_xticks_labels, ax8_set_yticks, ax8_set_yticks_labels = ax8_params(res)\n",
    "\n",
    "    #Histogram 95-99.5\n",
    "    ax8 = fig.add_subplot(spec[3, 2])\n",
    "    annotate_axes(ax8, 'ax8')\n",
    "    ax8.hist(hist3, bins=100, color='black')\n",
    "    ax8.set_title(\"95-99.5 Percentile\")\n",
    "    ax8.tick_params(axis='x', labelcolor='white')\n",
    "    ax8.set_xticks(ticks=ax8_set_xticks, labels=ax8_set_xticks_labels)\n",
    "    #for label in ax8.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax8.set_yticks(ticks=ax8_set_yticks,labels=ax8_set_yticks_labels)\n",
    "    ax8.set_facecolor('#fc8d59')\n",
    "\n",
    "    #CDF 95-99.5\n",
    "    ax9 = fig.add_subplot(spec[4, 2])\n",
    "    annotate_axes(ax9, 'ax9')\n",
    "    ax9.plot(hist3, cdf3, color = 'black')\n",
    "    ax9.set_title(\"CDF (95-99.5)\")\n",
    "    ax9.sharex(ax8)\n",
    "    #ax9.set_xticks((125,200,300,400,500,600,700,800),)\n",
    "    #for label in ax9.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax9.set_facecolor('#fc8d59')\n",
    "\n",
    "    ax10_set_xticks, ax10_set_xticks_labels, ax10_set_yticks, ax10_set_yticks_labels, ylim = ax10_params(res)\n",
    "\n",
    "    #Histogram 99.5-100\n",
    "    ax10 = fig.add_subplot(spec[3, 3])\n",
    "    annotate_axes(ax10, 'ax10')\n",
    "    N, bins, patches_ax10=ax10.hist(hist4, bins=100, color='black')\n",
    "    ax10.set_title(\"99.5-100th Percentile\")\n",
    "    ax10.tick_params(axis='x', labelcolor='white')\n",
    "    ax10.set_ylim(0, ylim)\n",
    "    ax10.set_xticks(ticks=ax10_set_xticks, labels=ax10_set_xticks_labels)\n",
    "    ax10.set_yticks(ticks=ax10_set_yticks,labels=ax10_set_yticks_labels)\n",
    "    #for i in range(0,2):\n",
    "    #    patches_ax10[i].set_edgecolor('white')\n",
    "    #    patches_ax10[i].set_facecolor('red')\n",
    "\n",
    "    #for label in ax10.xaxis.get_ticklabels()[::1]:\n",
    "    #    label.set_visible(False)\n",
    "    ax10.set_facecolor('#e34a33')\n",
    "\n",
    "    #CDF 99.5-100\n",
    "    ax11 = fig.add_subplot(spec[4, 3])\n",
    "    annotate_axes(ax11, 'ax11')\n",
    "    ax11.plot(hist4, cdf4, color = 'black')\n",
    "    ax11.set_title(\"CDF (99.5-100)\")\n",
    "    ax11.sharex(ax10)\n",
    "    #ax11.set_xticks((10000,50000,100000,150000))\n",
    "    #for label in ax11.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax11.tick_params(axis='x', labelsize=7)\n",
    "\n",
    "    ax11.set_facecolor('#e34a33')\n",
    "\n",
    "\n",
    "    ax12 = fig.add_subplot(spec[5:, :])\n",
    "    annotate_axes(ax12, 'ax12')\n",
    "    bars=ax12.bar(timeline_month_fatalitytotal['month_id'],timeline_month_fatalitytotal['Fatalities_Sum'],align='center', color = 'darkgrey') # A bar chart\n",
    "    ax12.set_xlabel('Month')\n",
    "    ax12.set_ylabel('Total Fatalities')\n",
    "    ax12.set_ylim(0, 18500)\n",
    "    for col in index_to_color:\n",
    "        # That's it!\n",
    "        bars[col].set_color('white')\n",
    "    \n",
    "    #ax7 = fig.add_subplot(spec[4, 1])\n",
    "    #ax.get_yaxis().set_label_coords(-0.1,0.5)\n",
    "\n",
    "    fig.align_ylabels()\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    return(plt.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Graph_it_all (PG_or_CM, monthly_or_annual, resolution=0, country=0):\n",
    "\n",
    "    pg__or__cm = PG_or_CM\n",
    "    res = resolution\n",
    "    cntry = country\n",
    "    \n",
    "    if PG_or_CM == 'PG':\n",
    "        df_pg = queryset_base_PG.publish().fetch()\n",
    "    #Reset index in order to access 'month_id' and 'priogrid_gid' columns\n",
    "        df_pg = df_pg.reset_index()\n",
    "        df_109_516 = df_pg.loc[(df_pg['month_id']>=109) & (df_pg['month_id']<= 516)]\n",
    "\n",
    "    else:\n",
    "        df_cm = queryset_base_CM.publish().fetch()\n",
    "        df_cm = df_cm.reset_index()\n",
    "        df_109_516 = df_cm.loc[(df_cm['month_id']>=109) & (df_cm['month_id']<= 516)]\n",
    "\n",
    "    df__PP=PGM_preprocess(df_109_516)\n",
    "    df_ag=PRIO_Aggregation(df__PP, monthly_or_annual,pg__or__cm, resolution, cntry)\n",
    "\n",
    "    printed_introduction = report_length(df_ag, PG_or_CM,'Global', monthly_or_annual,resolution)\n",
    "    print(printed_introduction)\n",
    "\n",
    "    format_fatalities_zero=Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','zero')\n",
    "    print(format_fatalities_zero.dtypes)\n",
    "    \n",
    "    described_fatalities_zero = correct_definition_df(format_fatalities_zero,df_ag,'zero','No',pg__or__cm)\n",
    "\n",
    "    fatalities_nonzero, described_fatalities_nonzero,len_fat = Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','non-zero')\n",
    "    Fatalities_nonzero_cordef = correct_definition_df(described_fatalities_nonzero, fatalities_nonzero,'non-zero','No')\n",
    "    print(len_fat)\n",
    "    \n",
    "    pcf_nonzero, described_pcf_nonzero, len_fpc = Format_summary_stats(PG_or_CM,df_ag,'PerCapitaFatalities','non-zero')\n",
    "    pcf_nonzero_cordef = correct_definition_df(described_pcf_nonzero, pcf_nonzero,'non-zero','No')\n",
    "    print(len_fpc)\n",
    "    a, b, c, d=params_for_graphs(Fatalities_nonzero_cordef,fatalities_nonzero,85,95,99.5)\n",
    "\n",
    "    print('type of A:')\n",
    "    a_dic = a[0]\n",
    "    a_cdf = a[1]\n",
    "    b_dic = b[0]\n",
    "    b_cdf = b[1]\n",
    "    c_dic = c[0]\n",
    "    c_cdf = c[1]\n",
    "    d_dic = d[0]\n",
    "    d_cdf = d[1]\n",
    "\n",
    "    x = statsheet(described_fatalities_zero, Fatalities_nonzero_cordef, pcf_nonzero_cordef, a_dic, a_cdf, b_dic, b_cdf, c_dic, c_cdf, d_dic, d_cdf, fatalities_nonzero, res)    \n",
    "    return(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = Graph_it_all('PG', 'monthly', '2x2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
