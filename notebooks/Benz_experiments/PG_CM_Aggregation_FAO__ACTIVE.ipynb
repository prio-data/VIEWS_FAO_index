{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import glob\n",
    "\n",
    "#some extra functions for some of the later demonstration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "#Define QuerySet\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup to let someone else drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_country = (Queryset(\"mihais_countries\", \"country_year\")\n",
    ".with_column(Column(\"country_id\", from_table=\"country\", from_column='id'))\n",
    ".with_column(Column(\"country_name\", from_table=\"country\", from_column='name'))\n",
    ".with_column(Column(\"gwcode\", from_table=\"country\", from_column='gwcode'))\n",
    ".with_column(Column(\"C_start_year\", from_table=\"country\", from_column='gwsyear'))\n",
    ".with_column(Column(\"C_end_year\", from_table=\"country\", from_column='gweyear'))\n",
    ".with_column(Column(\"geom_wkt\", from_table=\"country\", from_column='geom_wkt'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_c = queryset_country.publish().fetch()\n",
    "queryset_c.head(2)\n",
    "Ethi = queryset_c.loc[(queryset_c['country_name']=='Ethiopia')]\n",
    "#print(Ethi)\n",
    "Ethi = Ethi.rename(columns={'country_id':'C_id'})\n",
    "country_and_year = Ethi.groupby(['C_id', 'country_name', 'C_start_year', 'C_end_year']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "cids = list(unique(country_and_year['C_id']))\n",
    "print(cids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Ethi)\n",
    "Ethi = queryset_c.loc[(queryset_c['country_name']=='Ethiopia')]\n",
    "\n",
    "Ethi = Ethi.rename(columns={'country_id':'C_id'})\n",
    "country_and_year = Ethi.groupby(['C_id', 'country_name', 'C_start_year', 'C_end_year']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "cids = list(unique(country_and_year['C_id']))\n",
    "print(country_and_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_base_PG = (Queryset(\"Benz_PG_CF\", \"priogrid_month\")\n",
    "\n",
    "    .with_column(Column(\"country_name\", from_table = \"country\", from_column = \"name\")\n",
    "        .transform.missing.replace_na()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"country_id\", from_table=\"country\", from_column='id'))\n",
    "\n",
    "    #column with wkt to review \n",
    "    .with_column(Column(\"C_start_year\", from_table=\"country\", from_column='gwsyear'))\n",
    "    \n",
    "    .with_column(Column(\"C_end_year\", from_table=\"country\", from_column='gweyear'))\n",
    "        \n",
    "    .with_column(Column(\"year_id\", from_table = \"country_year\", from_column = \"year_id\")\n",
    "        )\n",
    "\n",
    "    # target variable\n",
    "    .with_column(Column(\"ged_sb\", from_table = \"ged2_pgm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"ged_ns\", from_table = \"ged2_pgm\", from_column = \"ged_ns_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ged_os\", from_table = \"ged2_pgm\", from_column = \"ged_os_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"sb_count\", from_table = \"ged2_pgm\", from_column = \"ged_sb_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ns_count\", from_table = \"ged2_pgm\", from_column = \"ged_ns_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"os_count\", from_table = \"ged2_pgm\", from_column = \"ged_os_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "    .with_column(Column(\"pop_gpw_sum\", from_table=\"priogrid_year\", from_column=\"pop_gpw_sum\")\n",
    "        \n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryset_base_CM = (Queryset(\"Benz_PG_CF\", \"country_month\")\n",
    "\n",
    "    .with_column(Column(\"country_name\", from_table = \"country\", from_column = \"name\")\n",
    "        .transform.missing.replace_na()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"year_id\", from_table = \"country_year\", from_column = \"year_id\")\n",
    "        )\n",
    "\n",
    "    # target variable\n",
    "    .with_column(Column(\"ged_sb\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "        \n",
    "    .with_column(Column(\"ged_ns\", from_table = \"ged2_cm\", from_column = \"ged_ns_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ged_os\", from_table = \"ged2_cm\", from_column = \"ged_os_best_sum_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "        #.transform.ops.ln()\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"sb_count\", from_table = \"ged2_cm\", from_column = \"ged_sb_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"ns_count\", from_table = \"ged2_cm\", from_column = \"ged_ns_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "\n",
    "    .with_column(Column(\"os_count\", from_table = \"ged2_cm\", from_column = \"ged_os_best_count_nokgi\")\n",
    "        .transform.missing.replace_na()\n",
    "\n",
    "        )\n",
    "    .with_column(Column(\"pop_gpw_sum\", from_table=\"wdi_cy\", from_column=\"wdi_sp_pop_totl\")\n",
    "        \n",
    "        )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directories to set:\n",
    "#This should be the only variable to change ---------------------------------------\n",
    "print(os.getcwd())\n",
    "#should point to ...VIEWS_FAO_index/notebooks/Benz_experiments/Benz_experiments:\n",
    "#----------------------------------------------------------------------------------\n",
    "aggregation_tables_dir = os.getcwd() + '/Aggregation_Key_Tables/'\n",
    "Timeline_tables_dir = os.getcwd() + '/Tables_For_Timeline_Maps/'\n",
    "report_inf = os.getcwd() + '/Report_Checks/Report_inf_values/'\n",
    "agg_completeness = os.getcwd() + '/Report_Checks/Aggregation_completeness/'\n",
    "compare_countries = os.getcwd() + '/Country_Comparisons/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This toolbox considers 3 primary paramters\n",
    "\n",
    "**Parameter 1:** Is this analysis employing PGM or CM data?<br><br>\n",
    "**Parameter 2:** What level of SPACE aggregation is the user interested in?<br>\n",
    "*Options include -- Original PrioGRid aggregation 1x1 or courser aggregations 2x2, 3x3, 4x4, 5x5, 6x6, 8x8, 9x9, and 10x10*<br><br>\n",
    "**Parameter 3:** What level of TIME aggregation is the user interested in?<br><br>\n",
    "*Options include -- Original PrioGRid monthly resolution and annual*<br>\n",
    "Note that within this time parameter, the range of available data is fixed between 1989-2022.<br><br>\n",
    "**Parameter 4:** Define the processing extent to apply space and time factors<br><br>\n",
    "**Parameter 5:** Establish what statistics to generate for the Unit of Analysis and designated Area of Responsibility'<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGM_preprocess(table):\n",
    "\n",
    "    #replace NA Population values with 0\n",
    "    table['pop_gpw_sum'] = table['pop_gpw_sum'].replace({np.nan:0})\n",
    "\n",
    "    table['Fatalities_Sum'] = table['ged_sb'] + table['ged_ns'] + table['ged_os']\n",
    "    table['PerCapitaFatalities'] = table['Fatalities_Sum'] / table['pop_gpw_sum']\n",
    "    table['PerCapitaFatalities'] = table['PerCapitaFatalities'].replace({np.nan:0})\n",
    "\n",
    "    table = table.drop(['ged_sb','ged_ns','ged_os','sb_count','ns_count','os_count'], axis = 1)\n",
    "\n",
    "    return(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_infinity_values(base_table,CM__or__PG, resolution=0):\n",
    "\n",
    "    if resolution == 0:\n",
    "        res = '_'\n",
    "    else:\n",
    "        res = resolution\n",
    "\n",
    "    CM__or__PGstr = CM__or__PG+'_'\n",
    "\n",
    "    base_table['PerCapitaFatalities'] = base_table['PerCapitaFatalities'].replace([np.inf, -np.inf], np.nan)\n",
    "    Anamoly = base_table[base_table['PerCapitaFatalities'].isna()]\n",
    "    #Anamoly.to_csv(f'/Users/gbenz/Documents/Food Security and Conflict/{CM__or__PGstr}{res}Fatality_NoPop.csv')\n",
    "    Anamoly.to_csv(f'{report_inf}{CM__or__PGstr}{res}Fatality_NoPop.csv')\n",
    "\n",
    "    base_table['PerCapitaFatalities'] = base_table['PerCapitaFatalities'].replace({np.nan:0})\n",
    "\n",
    "    return(base_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PRIO_Agg(table,time,CMorPG,scale=0,country=0):\n",
    "    \n",
    "#     import glob\n",
    "\n",
    "#     CM_or_PG = CMorPG\n",
    "#     c = np.isinf(table['PerCapitaFatalities']).values.sum() \n",
    "\n",
    "#     if c > 0:    \n",
    "#         table=report_infinity_values(table,CM_or_PG)\n",
    "\n",
    "#     if time == 'monthly':\n",
    "#         time_attribute = 'month_id'\n",
    "#     elif time == 'annual':\n",
    "#         time_attribute = 'year_id'\n",
    "\n",
    "#     if CM_or_PG == 'CM':\n",
    "#         if country == 0:\n",
    "#             table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             return(table)\n",
    "#         elif country !=0:\n",
    "#             table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             selected_country=table[table['Included_Countries'].isin([country])]\n",
    "#             return(selected_country, selected_country)\n",
    "\n",
    "#     elif CM_or_PG == 'PG': \n",
    "#         if scale == '1x1':\n",
    "#             table = table.rename(columns={'priogrid_gid':'Scale_ID'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             if country == 0:\n",
    "#                 return(table, table)\n",
    "#             else:\n",
    "# #FIX 02-18--------------------------------------------------------------------------------------------------------------------\n",
    "# #Need to reflect consistent changes to the aggregation functions applied below\n",
    "# #Must map to the Country ID \n",
    "#                 selected_country=table[table['Included_Countries'].isin([country])]\n",
    "#                 return(selected_country, selected_country)    \n",
    "#         #--------------------------------------------------\n",
    "#         else:\n",
    "#             #source_PG_aggregation_dir = '/Users/gbenz/Documents/Common Data/PG Aggregation/'\n",
    "#             aggregation_tables_dir = '/Aggregation_Key_Tables/'\n",
    "\n",
    "#             allFiles = glob.glob(os.getcwd() + aggregation_tables_dir + \"/*.csv\")\n",
    "\n",
    "#             for filename in allFiles:\n",
    "#                     if scale in filename:\n",
    "#                         #print(filename)\n",
    "#                         break\n",
    "#             Aggregation_file = filename\n",
    "\n",
    "#             single_res = int(scale.split('x')[0])\n",
    "\n",
    "#             Expected = single_res ** 2\n",
    "\n",
    "#             pg_AG = pd.read_csv(Aggregation_file)\n",
    "\n",
    "#             pg_AG['gid'] = pg_AG['gid'].astype(str)\n",
    "#             pg_AG['Id'] = pg_AG['Id'].astype(str)\n",
    "\n",
    "#             pg_AG['Scale_ID'] = pg_AG.groupby(['Id'])['gid'].transform(lambda x : '_'.join(x))\n",
    "\n",
    "#             pg_AG['gid'] = pg_AG['gid'].astype('int64')\n",
    "#             pg_AG['Id'] = pg_AG['Id'].astype('int64')\n",
    "\n",
    "#         #A method to get rows that communicate 1. Each indivdiual geospatial abstract id and corresponding PRIOgrid ID \n",
    "#             pg_AG__FOR_VALIDATE = pg_AG.groupby(['Id','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#             pg_AG__FOR_VALIDATE = pg_AG__FOR_VALIDATE.sort_values(by='Scale_ID')\n",
    "\n",
    "#             #pg_AG__FOR_VALIDATE['liststring'] = pg_AG__FOR_VALIDATE['lists'].apply(lambda x: ','.join(map(str, x)))\n",
    "#             GIS_dic = dict(zip(pg_AG__FOR_VALIDATE['Scale_ID'], pg_AG__FOR_VALIDATE['Id']))\n",
    "\n",
    "#             pg__AG = pg_AG.groupby('Scale_ID')['gid'].apply(list)\n",
    "#             pg__AG__dic = pg__AG.to_dict()\n",
    "\n",
    "#             table['Scale_ID'] = table.priogrid_gid.map({item: k for k, v in pg__AG__dic.items() for item in v})\n",
    "#             df_2022 = table.sort_values(by=['Scale_ID','priogrid_gid'], ascending=[False,True])\n",
    "# #----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#         #changes here --\n",
    "#             withcountry = df_2022.groupby(['Scale_ID','country_name']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#         #This is exactly the problem ------^\n",
    "#             withcountry['Country_present'] = withcountry.groupby(['Scale_ID'])['country_name'].transform(lambda x : '___'.join(x))\n",
    "#             withcountry = withcountry.drop(['country_name'], axis=1).drop_duplicates()\n",
    "#             withcountry__dic = dict(zip(withcountry.Scale_ID, withcountry.Country_present))\n",
    "#         #Needs to account for start and end dates-----^\n",
    "#         #---------\n",
    "#             check = df_2022.groupby(['priogrid_gid','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#             check = check.sort_values(by='Scale_ID')\n",
    "\n",
    "#             check_PGID = check.groupby(['Scale_ID']).size().to_frame().reset_index()\n",
    "#             check_PGID = check_PGID.rename(columns = {0:'Size'})\n",
    "#             check_PGID = check_PGID.sort_values(by='Size')\n",
    "#             less_than_expected = check_PGID[check_PGID['Size'] < Expected]\n",
    "#             #print(less_than_expected)\n",
    "#             less_than_expected.to_csv(f'{agg_completeness}{CMorPG}_{scale}_completeness.csv')\n",
    "\n",
    "#             df_2022_grouped = df_2022.groupby([time_attribute,'Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "\n",
    "#             if country == 0:\n",
    "#                 df_2022_grouped['GIS__Index'] = df_2022_grouped['Scale_ID'].map(GIS_dic)\n",
    "#                 for_GIS = df_2022_grouped.drop(['Scale_ID'], axis=1)\n",
    "#                 df_2022_grouped = df_2022_grouped.drop(['GIS__Index'], axis=1)\n",
    "\n",
    "#                 return(df_2022_grouped, for_GIS)\n",
    "#             else:\n",
    "#                 df_2022_grouped['Countries_In_AG_Unit']= df_2022_grouped['Scale_ID'].map(withcountry__dic)\n",
    "#                 df_2022_grouped['Included_Countries'] = df_2022_grouped['Countries_In_AG_Unit'].str.split('___')\n",
    "#                 selected_country = df_2022_grouped.loc[df_2022_grouped['Included_Countries'].explode().eq(country).loc[lambda x: x].index]\n",
    "#                 selected_country = selected_country.drop('Included_Countries', axis=1)\n",
    "                \n",
    "#                 selected_country['GIS__Index'] = selected_country['Scale_ID'].map(GIS_dic)\n",
    "#                 for_GIS = selected_country.drop(['Scale_ID'], axis=1)\n",
    "#                 selected_country = selected_country.drop(['GIS__Index'], axis=1)\n",
    "\n",
    "#                 return(selected_country, for_GIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRIO_Agg_serious(table,time,CMorPG,scale=0,country=0,recent_or_all='recent'):\n",
    "    \n",
    "    import glob\n",
    "\n",
    "    CM_or_PG = CMorPG\n",
    "    c = np.isinf(table['PerCapitaFatalities']).values.sum() \n",
    "\n",
    "    if c > 0:    \n",
    "        table=report_infinity_values(table,CM_or_PG)\n",
    "\n",
    "    if time == 'monthly':\n",
    "        time_attribute = 'month_id'\n",
    "    elif time == 'annual':\n",
    "        time_attribute = 'year_id'\n",
    "\n",
    "    if CM_or_PG == 'CM':\n",
    "        if country == 0:\n",
    "            table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "            table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "            table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "            return(table)\n",
    "        elif country !=0:\n",
    "            table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "            table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "            table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "            selected_country=table[table['Included_Countries'].isin([country])]\n",
    "            return(selected_country, selected_country)\n",
    "\n",
    "    elif CM_or_PG == 'PG': \n",
    "        if scale == '1x1':\n",
    "\n",
    "            if country == 0:\n",
    "                table = table.rename(columns={'priogrid_gid':'Scale_ID'})\n",
    "                table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "                #table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "                table = table.drop(['country_id','C_start_year','C_end_year'], axis = 1)\n",
    "                table.drop_duplicates()\n",
    "                return(table, table)\n",
    "            else:\n",
    "#FIX 02-18--------------------------------------------------------------------------------------------------------------------\n",
    "#Need to reflect consistent changes to the aggregation functions applied below\n",
    "#Must map to the Country ID \n",
    "\n",
    "#NEED TO ADD the function to map only recent boundaries--\n",
    "                #selected_country = table[table['Included_Countries'].isin([country])]\n",
    "#What fields does setupDOBY need:\n",
    "#just country_name\n",
    "                #table['Included_Countries'] = table['country_id']\n",
    "                table['Scale_ID'] = table['priogrid_gid']\n",
    "                table['country_id'] = table['country_id'].astype(str)\n",
    "\n",
    "#------^is a matter of formatted so field names match what the definition is looking for rather \n",
    "#   than add a series of if statements\n",
    "                year_dictionary = setup_DOBY(table, country, recent_or_all)\n",
    "                xx = scale_and_countryid(year_dictionary, table, scale)\n",
    "\n",
    "                #xx = xx.drop(['country_id','C_start_year','C_end_year'], axis = 1)\n",
    "                xx.drop_duplicates()\n",
    "                return(xx, xx)    \n",
    "        #--------------------------------------------------\n",
    "        else:\n",
    "            #source_PG_aggregation_dir = '/Users/gbenz/Documents/Common Data/PG Aggregation/'\n",
    "            allFiles = glob.glob(source_PG_aggregation_dir + \"/*.csv\")\n",
    "\n",
    "            for filename in allFiles:\n",
    "                    if scale in filename:\n",
    "                        #print(filename)\n",
    "                        break\n",
    "            Aggregation_file = filename\n",
    "\n",
    "            single_res = int(scale.split('x')[0])\n",
    "\n",
    "            Expected = single_res ** 2\n",
    "\n",
    "            pg_AG = pd.read_csv(Aggregation_file)\n",
    "\n",
    "            pg_AG['gid'] = pg_AG['gid'].astype(str)\n",
    "            pg_AG['Id'] = pg_AG['Id'].astype(str)\n",
    "\n",
    "            pg_AG['Scale_ID'] = pg_AG.groupby(['Id'])['gid'].transform(lambda x : '_'.join(x))\n",
    "\n",
    "            pg_AG['gid'] = pg_AG['gid'].astype('int64')\n",
    "            pg_AG['Id'] = pg_AG['Id'].astype('int64')\n",
    "\n",
    "        #A method to get rows that communicate 1. Each indivdiual geospatial abstract id and corresponding PRIOgrid ID \n",
    "            pg_AG__FOR_VALIDATE = pg_AG.groupby(['Id','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "            pg_AG__FOR_VALIDATE = pg_AG__FOR_VALIDATE.sort_values(by='Scale_ID')\n",
    "\n",
    "            #pg_AG__FOR_VALIDATE['liststring'] = pg_AG__FOR_VALIDATE['lists'].apply(lambda x: ','.join(map(str, x)))\n",
    "            GIS_dic = dict(zip(pg_AG__FOR_VALIDATE['Scale_ID'], pg_AG__FOR_VALIDATE['Id']))\n",
    "\n",
    "            pg__AG = pg_AG.groupby('Scale_ID')['gid'].apply(list)\n",
    "            pg__AG__dic = pg__AG.to_dict()\n",
    "\n",
    "            table['Scale_ID'] = table.priogrid_gid.map({item: k for k, v in pg__AG__dic.items() for item in v})\n",
    "            df_2022 = table.sort_values(by=['Scale_ID','priogrid_gid'], ascending=[False,True])\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        #changes here --\n",
    "        #This is exactly the problem ------^\n",
    "\n",
    "            if country == 0:\n",
    "                df_2022 = df_2022.drop(['country_id','C_start_year','C_end_year'], axis = 1)\n",
    "                df_2022.drop_duplicates()\n",
    "\n",
    "                print(df_2022.tail(5))\n",
    "\n",
    "                chckPG = len(unique(df_2022['priogrid_gid']))\n",
    "                print(chckPG)\n",
    "                chckmonth = len(unique(df_2022['month_id']))\n",
    "                print(chckmonth)\n",
    "                all =len(df_2022)\n",
    "                print(all)\n",
    "                #---\n",
    "                df_2022_grouped = df_2022.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                #append to empty dataframe\n",
    "                df_2022_grouped['Applied_cid'] = 'None'\n",
    "\n",
    "                print('dataframe for:', key)\n",
    "                df_2022_grouped['GIS__Index'] = df_2022_grouped['Scale_ID'].map(GIS_dic)\n",
    "                for_GIS = df_2022_grouped.drop(['Scale_ID'], axis=1)\n",
    "                df_2022_grouped = df_2022_grouped.drop(['GIS__Index'], axis=1)\n",
    "\n",
    "                return(df_2022_grouped, for_GIS)\n",
    "            else:\n",
    "\n",
    "                df_22 = map_c_id_to_aggregations(df_2022)\n",
    "                year_dictionary = setup_DOBY(table, country, recent_or_all)\n",
    "                xx = scale_and_countryid(year_dictionary, df_22, scale)\n",
    "\n",
    "                \n",
    "                xx['GIS__Index'] = xx['Scale_ID'].map(GIS_dic)\n",
    "                for_GIS = xx.drop(['Scale_ID'], axis=1)\n",
    "                xx = xx.drop(['GIS__Index'], axis=1)\n",
    "\n",
    "                return(xx, for_GIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PRIO_Agg_Silly(table,time,CMorPG,scale=0,country=0):\n",
    "    \n",
    "#     import glob\n",
    "\n",
    "#     CM_or_PG = CMorPG\n",
    "#     c = np.isinf(table['PerCapitaFatalities']).values.sum() \n",
    "\n",
    "#     if c > 0:    \n",
    "#         table=report_infinity_values(table,CM_or_PG)\n",
    "\n",
    "#     if time == 'monthly':\n",
    "#         time_attribute = 'month_id'\n",
    "#     elif time == 'annual':\n",
    "#         time_attribute = 'year_id'\n",
    "\n",
    "#     if CM_or_PG == 'CM':\n",
    "#         if country == 0:\n",
    "#             table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             return(table)\n",
    "#         elif country !=0:\n",
    "#             table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             selected_country=table[table['Included_Countries'].isin([country])]\n",
    "#             return(selected_country, selected_country)\n",
    "\n",
    "#     elif CM_or_PG == 'PG': \n",
    "#         if scale == '1x1':\n",
    "#             table = table.rename(columns={'priogrid_gid':'Scale_ID'})\n",
    "#             table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#             table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#             if country == 0:\n",
    "#                 return(table, table)\n",
    "#             else:\n",
    "#                 selected_country=table[table['Included_Countries'].isin([country])]\n",
    "#                 return(selected_country, selected_country)    \n",
    "#         #--------------------------------------------------\n",
    "#         else:\n",
    "#             #source_PG_aggregation_dir = '/Users/gbenz/Documents/Common Data/PG Aggregation/'\n",
    "#             allFiles = glob.glob(source_PG_aggregation_dir + \"/*.csv\")\n",
    "\n",
    "#             for filename in allFiles:\n",
    "#                     if scale in filename:\n",
    "#                         #print(filename)\n",
    "#                         break\n",
    "#             Aggregation_file = filename\n",
    "\n",
    "#             single_res = int(scale.split('x')[0])\n",
    "\n",
    "#             Expected = single_res ** 2\n",
    "\n",
    "#             pg_AG = pd.read_csv(Aggregation_file)\n",
    "\n",
    "#             pg_AG['gid'] = pg_AG['gid'].astype(str)\n",
    "#             pg_AG['Id'] = pg_AG['Id'].astype(str)\n",
    "\n",
    "#             pg_AG['Scale_ID'] = pg_AG.groupby(['Id'])['gid'].transform(lambda x : '_'.join(x))\n",
    "\n",
    "#             pg_AG['gid'] = pg_AG['gid'].astype('int64')\n",
    "#             pg_AG['Id'] = pg_AG['Id'].astype('int64')\n",
    "\n",
    "#         #A method to get rows that communicate 1. Each indivdiual geospatial abstract id and corresponding PRIOgrid ID \n",
    "#             pg_AG__FOR_VALIDATE = pg_AG.groupby(['Id','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#             pg_AG__FOR_VALIDATE = pg_AG__FOR_VALIDATE.sort_values(by='Scale_ID')\n",
    "\n",
    "#             #pg_AG__FOR_VALIDATE['liststring'] = pg_AG__FOR_VALIDATE['lists'].apply(lambda x: ','.join(map(str, x)))\n",
    "#             GIS_dic = dict(zip(pg_AG__FOR_VALIDATE['Scale_ID'], pg_AG__FOR_VALIDATE['Id']))\n",
    "\n",
    "#             pg__AG = pg_AG.groupby('Scale_ID')['gid'].apply(list)\n",
    "#             pg__AG__dic = pg__AG.to_dict()\n",
    "\n",
    "#             table['Scale_ID'] = table.priogrid_gid.map({item: k for k, v in pg__AG__dic.items() for item in v})\n",
    "#             df_2022 = table.sort_values(by=['Scale_ID','priogrid_gid'], ascending=[False,True])\n",
    "#             return(df_2022,df_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PRIO_Aggregation(table,time,CMorPG,scale=0,country=0):\n",
    "    \n",
    "#     import glob\n",
    "\n",
    "#     CM_or_PG = CMorPG\n",
    "#     c = np.isinf(table['PerCapitaFatalities']).values.sum() \n",
    "\n",
    "#     if c > 0:    \n",
    "#         table=report_infinity_values(table,CM_or_PG)\n",
    "\n",
    "#     if time == 'monthly':\n",
    "#         time_attribute = 'month_id'\n",
    "#     elif time == 'annual':\n",
    "#         time_attribute = 'year_id'\n",
    "\n",
    "#     if scale == '1x1':\n",
    "#         table = table.rename(columns={'priogrid_gid':'Scale_ID'})\n",
    "#         table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#         table = table.rename(columns={'country_name':'Included_Countries'})\n",
    "#         if country == 0:\n",
    "#             return(table)\n",
    "#         else:\n",
    "#             selected_country=table[table['Included_Countries'].isin([country])]\n",
    "#             return(selected_country)\n",
    "        \n",
    "#     elif scale == 0:\n",
    "#         table = table.rename(columns={'country_id':'Scale_ID'})\n",
    "#         table = table.drop(['year_id', 'pop_gpw_sum'], axis=1)\n",
    "#         return(table) \n",
    "#     #--------------------------------------------------\n",
    "#     else:\n",
    "#         source_PG_aggregation_dir = '/Users/gbenz/Documents/Common Data/PG Aggregation/'\n",
    "#         allFiles = glob.glob(source_PG_aggregation_dir + \"/*.csv\")\n",
    "\n",
    "#         for filename in allFiles:\n",
    "#                 if scale in filename:\n",
    "#                     #print(filename)\n",
    "#                     break\n",
    "#         Aggregation_file = filename\n",
    "\n",
    "#         single_res = int(scale.split('x')[0])\n",
    "\n",
    "#         Expected = single_res ** 2\n",
    "\n",
    "#         pg_AG = pd.read_csv(Aggregation_file)\n",
    "\n",
    "#         pg_AG['gid'] = pg_AG['gid'].astype(str)\n",
    "#         pg_AG['Id'] = pg_AG['Id'].astype(str)\n",
    "\n",
    "#         pg_AG['Scale_ID'] = pg_AG.groupby(['Id'])['gid'].transform(lambda x : '_'.join(x))\n",
    "\n",
    "#         pg_AG['gid'] = pg_AG['gid'].astype('int64')\n",
    "#         pg_AG['Id'] = pg_AG['Id'].astype('int64')\n",
    "#     #A method to get rows that communicate 1. Each indivdiual geospatial abstract id and corresponding PRIOgrid ID \n",
    "#         pg_AG__FOR_VALIDATE = pg_AG.groupby(['Id','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#         pg_AG__FOR_VALIDATE = pg_AG__FOR_VALIDATE.sort_values(by='Scale_ID')\n",
    "\n",
    "#         pg__AG = pg_AG.groupby('Scale_ID')['gid'].apply(list)\n",
    "#         pg__AG__dic = pg__AG.to_dict()\n",
    "\n",
    "#         table['Scale_ID'] = table.priogrid_gid.map({item: k for k, v in pg__AG__dic.items() for item in v})\n",
    "#         df_2022 = table.sort_values(by=['Scale_ID','priogrid_gid'], ascending=[False,True])\n",
    "\n",
    "#     #changes here --\n",
    "#         withcountry = df_2022.groupby(['Scale_ID','country_name']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#         withcountry['Country_present'] = withcountry.groupby(['Scale_ID'])['country_name'].transform(lambda x : '___'.join(x))\n",
    "#         withcountry = withcountry.drop(['country_name'], axis=1).drop_duplicates()\n",
    "#         withcountry__dic = dict(zip(withcountry.Scale_ID, withcountry.Country_present))\n",
    "#     #---------\n",
    "#         check = df_2022.groupby(['priogrid_gid','Scale_ID']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "#         check = check.sort_values(by='Scale_ID')\n",
    "\n",
    "#         check_PGID = check.groupby(['Scale_ID']).size().to_frame().reset_index()\n",
    "#         check_PGID = check_PGID.rename(columns = {0:'Size'})\n",
    "#         check_PGID = check_PGID.sort_values(by='Size')\n",
    "#         less_than_expected = check_PGID[check_PGID['Size'] < Expected]\n",
    "#         #print(less_than_expected)\n",
    "#         less_than_expected.to_csv('/Users/gbenz/Documents/Common Data/inf_FPC.csv')\n",
    "\n",
    "#         df_2022_grouped = df_2022.groupby([time_attribute,'Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "\n",
    "#         if country == 0:\n",
    "#             return(df_2022_grouped)\n",
    "#         else:\n",
    "#             df_2022_grouped['Countries_In_AG_Unit']= df_2022_grouped['Scale_ID'].map(withcountry__dic)\n",
    "#             df_2022_grouped['Included_Countries'] = df_2022_grouped['Countries_In_AG_Unit'].str.split('___')\n",
    "#             selected_country = df_2022_grouped.loc[df_2022_grouped['Included_Countries'].explode().eq(country).loc[lambda x: x].index]\n",
    "#             selected_country = selected_country.drop('Included_Countries', axis=1)\n",
    "#             return(selected_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Format_summary_stats(PG_or_CM, table_to_describe,field_to_describe,zero__or__non_zero):\n",
    "    \n",
    "    if PG_or_CM == 'PG':\n",
    "        lowpercentile = 40\n",
    "    else:\n",
    "        lowpercentile = 0\n",
    "\n",
    "    p = np.array(arange(lowpercentile, 100.1, 0.1))\n",
    "    divisor = 100\n",
    "    p_div = p/divisor\n",
    "    l = p_div.tolist()\n",
    "    l_3dec = [round(elem, 3) for elem in l ]\n",
    "\n",
    "    if field_to_describe == 'Fatalities_Sum':\n",
    "        SummaryField = 'Fatalities'\n",
    "\n",
    "    elif field_to_describe == 'PerCapitaFatalities':\n",
    "        SummaryField = 'Fatalities Per Capita'\n",
    "\n",
    "    if zero__or__non_zero == 'zero' and PG_or_CM == 'PG':\n",
    "        #percentile = [.5,.7,.8,.85,.9,.95,.98,.99,.991,.992,.993,.994,.995,.996,.997,.998,.999,1]\n",
    "        data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=l_3dec)})\n",
    "\n",
    "    elif zero__or__non_zero == 'zero' and PG_or_CM == 'CM':\n",
    "        #percentile = [.5,.7,.8,.81,.82,.83,.84,.85,.86,.87,.88,.89,.9,.95,.98,.99,.991,.992,.993,.994,.995,.996,.997,.998,.999,1]\n",
    "        data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=l_3dec)})\n",
    "\n",
    "    elif zero__or__non_zero == 'non-zero':\n",
    "        check_length_nonzero = len(table_to_describe[table_to_describe[field_to_describe]>0.0])\n",
    "        if check_length_nonzero == 0:\n",
    "            return(0, 0, 0)\n",
    "        attribute_nozero=table_to_describe[table_to_describe[field_to_describe]!= 0]\n",
    "        length_of_attribute_nozero = len(attribute_nozero)\n",
    "        percentile = [0,.25,.5,.75,.8,.85,.9,.95,.99,.995,1]\n",
    "        data = pd.DataFrame({SummaryField: attribute_nozero[field_to_describe].describe(percentiles=percentile)})\n",
    "\n",
    "    #data = pd.DataFrame({SummaryField: table_to_describe[field_to_describe].describe(percentiles=percentile)})\n",
    "    data = data.reset_index()\n",
    "    data = data.rename(columns={'index':'Percentile'})\n",
    "    data = data.iloc[4:][:-1]\n",
    "    data['Percentile'] = data['Percentile'].str[:-1]\n",
    "\n",
    "    if field_to_describe == 'Fatalities_Sum' and zero__or__non_zero == 'non-zero':\n",
    "        data['Fatalities'] = (data['Fatalities']).astype(int)\n",
    "        #attribute_nozero=table_to_describe[table_to_describe['Fatalities_Sum']!= 0]\n",
    "        return(attribute_nozero, data, length_of_attribute_nozero)\n",
    "\n",
    "    elif field_to_describe == 'Fatalities_Sum' and zero__or__non_zero == 'zero':\n",
    "        data['Fatalities'] = (data['Fatalities']).astype(int)\n",
    "        return(data)\n",
    "\n",
    "    elif field_to_describe == 'PerCapitaFatalities' and zero__or__non_zero == 'non-zero':\n",
    "        #attribute_nozero=table_to_describe[table_to_describe['PerCapitaFatalities']!= 0]\n",
    "        return(attribute_nozero, data, length_of_attribute_nozero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_zero_percentiles(insert_percentile):\n",
    "    float_percentile_at_1 = float(insert_percentile)\n",
    "    if float_percentile_at_1 >= 99.5:\n",
    "        sub_perc = [99.7, 99.8, 99.9, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 99.5 and float_percentile_at_1 >= 99:\n",
    "        sub_perc = [99.5, 99.7, 99.9, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 99 and float_percentile_at_1 >= 98:\n",
    "        sub_perc = [99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 98 and float_percentile_at_1 >= 95:\n",
    "        sub_perc = [99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 95 and float_percentile_at_1 >= 90:\n",
    "        sub_perc = [95, 99, 99.5, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 90 and float_percentile_at_1 >= 85:\n",
    "        sub_perc = [90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 85 and float_percentile_at_1 >= 80:\n",
    "        sub_perc = [85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "\n",
    "    elif float_percentile_at_1 < 80 and float_percentile_at_1 >= 70:\n",
    "        sub_perc = [80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "    \n",
    "    elif float_percentile_at_1 < 70 and float_percentile_at_1 >= 50:\n",
    "        sub_perc = [70, 80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)\n",
    "    \n",
    "    elif float_percentile_at_1 <50:\n",
    "        sub_perc = [50, 75, 80, 85, 90, 95, 99, 100]\n",
    "        sub_perc.insert(0, float_percentile_at_1)\n",
    "        return(sub_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_definition_df(definition_dataframe,original_dataframe,zero__or__nonzero,single_cell_analysis,PG__or__CM='PG',single_cell_analysis_percentiles=[99,95]):\n",
    "\n",
    "    check_list = list(definition_dataframe)\n",
    "\n",
    "    if 'Fatalities' in check_list:\n",
    "        #attribute_nozero=original_dataframe[original_dataframe['Fatalities_Sum']!= 0]\n",
    "        #return(Fatalities_nozero)\n",
    "\n",
    "        if zero__or__nonzero == 'zero':\n",
    "            definition_dataframe = definition_dataframe.reset_index()\n",
    "            if 1 not in definition_dataframe['Fatalities'].values:\n",
    "                  return(0)\n",
    "            percentile_at_1 = list(definition_dataframe.loc[definition_dataframe['Fatalities'] == 1, 'Percentile'])[0]\n",
    "            sub_perc=represent_zero_percentiles(percentile_at_1)\n",
    "\n",
    "            search_P = list(map(str, sub_perc))\n",
    "            #print(search_P)\n",
    "            definition_dataframe['Percentile'] = definition_dataframe['Percentile'].astype('string')\n",
    "            from_sub_perc = definition_dataframe[definition_dataframe['Percentile'].isin(search_P)]\n",
    "            #sub_perc = ['84','90','95','99','99.5','100']\n",
    "            #definition_dataframe['Percentile'] = definition_dataframe['Percentile'].astype('string')\n",
    "            #from_sub_perc = definition_dataframe[definition_dataframe['Percentile'].isin(sub_perc)]\n",
    "            #from_sub_perc = definition_dataframe[definition_dataframe['Percentile'] in sub_perc]\n",
    "            #match_p = definition_dataframe.loc[definition_dataframe['Percentile'] == i]\n",
    "            def_values = from_sub_perc['Fatalities'].unique()\n",
    "            #print(def_values)\n",
    "        else:\n",
    "            def_values = definition_dataframe['Fatalities'].unique()\n",
    "        id_fatality = []\n",
    "        id_triggers = []\n",
    "        id_p = []\n",
    "            \n",
    "    if 'Fatalities Per Capita' in check_list:\n",
    "        def_values = definition_dataframe['Fatalities Per Capita'].unique()\n",
    "        id_percapita = []\n",
    "        id_triggers = []\n",
    "        id_p = []\n",
    "\n",
    "    collected = pd.DataFrame()\n",
    "\n",
    "    if single_cell_analysis == 'Yes':\n",
    "        def_values = single_cell_analysis_percentiles\n",
    "\n",
    "    for i in def_values:\n",
    "                            if 'Fatalities' in check_list and i == 0.0:\n",
    "                                #if i == 0.0:\n",
    "                                continue\n",
    "                            elif 'Fatalities' in check_list and i != 0.0:\n",
    "                                match_p = definition_dataframe.loc[definition_dataframe['Fatalities'] == i]\n",
    "                                perc = match_p.at[match_p.index[0], 'Percentile']\n",
    "                                limit = original_dataframe.loc[original_dataframe['Fatalities_Sum'] >= i]\n",
    "                                triggers = len(limit.index)\n",
    "                                fatality = i\n",
    "\n",
    "                                id_p.append(perc)\n",
    "                                id_fatality.append(fatality)\n",
    "                                id_triggers.append(triggers)\n",
    "\n",
    "                                Out_Percentile = pd.DataFrame(list(zip(id_p, id_fatality, id_triggers)),\n",
    "                                    columns=['Percentile','Fatalities','Occurance'])\n",
    "                                \n",
    "                            if 'Fatalities Per Capita' in check_list:\n",
    "                                match_p = definition_dataframe.loc[definition_dataframe['Fatalities Per Capita'] == i]\n",
    "                                perc = match_p.at[match_p.index[0], 'Percentile']\n",
    "                                limit = original_dataframe.loc[original_dataframe['PerCapitaFatalities'] >= i]\n",
    "                                triggers = len(limit.index)\n",
    "                                capita = i                        \n",
    "\n",
    "                                id_p.append(perc)\n",
    "                                id_percapita.append(capita)\n",
    "                                id_triggers.append(triggers)\n",
    "\n",
    "                                Out_Percentile = pd.DataFrame(list(zip(id_p, id_percapita, id_triggers)),\n",
    "                                    columns=['Percentile','Fatalities Per Capita','Occurance'])\n",
    "                            \n",
    "    if zero__or__nonzero == 'zero' or single_cell_analysis == 'Yes':\n",
    "           \n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        return(collected)\n",
    "    \n",
    "    elif zero__or__nonzero == 'non-zero'and 'Fatalities Per Capita' in check_list:\n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        collected['Fatalities Per Capita'] = collected['Fatalities Per Capita']*10000\n",
    "        collected['Fatalities Per Capita'] = collected['Fatalities Per Capita'].round(1)\n",
    "        collected = collected.rename(columns={'Fatalities Per Capita':'Per Capita'})\n",
    "        Transpose_desc=collected.transpose()\n",
    "        new_header = Transpose_desc.iloc[0] #grab the first row for the header\n",
    "        Transpose_desc_less = Transpose_desc[1:] #take the data less the header row\n",
    "        Transpose_desc_less.columns = new_header\n",
    "        Transpose_desc_less = Transpose_desc_less.reset_index()\n",
    "        Transpose_desc_less = Transpose_desc_less.rename(columns={'index':'Percentile'})\n",
    "\n",
    "        return(Transpose_desc_less)\n",
    "\n",
    "    elif zero__or__nonzero == 'non-zero' and 'Fatalities' in check_list:\n",
    "        collected = pd.concat([collected, Out_Percentile], ignore_index=True) \n",
    "        Transpose_desc=collected.transpose()\n",
    "        new_header = Transpose_desc.iloc[0] #grab the first row for the header\n",
    "        Transpose_desc_less = Transpose_desc[1:] #take the data less the header row\n",
    "        Transpose_desc_less.columns = new_header\n",
    "        Transpose_desc_less = Transpose_desc_less.reset_index()\n",
    "        Transpose_desc_less = Transpose_desc_less.rename(columns={'index':'Percentile'})\n",
    "\n",
    "        return(Transpose_desc_less)\n",
    "\n",
    "    #elif zero__or__nonzero != 'zero' or zero__or__nonzero != 'non-zero':\n",
    "        #print('This parameter was incorrectly named. Select from zero or non-zero') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_for_graphs(description,original_df,a,b,c,):\n",
    "\n",
    "    a=str(a)\n",
    "    b=str(b)\n",
    "    c=str(c)\n",
    "\n",
    "    desc_attribute = description.at[0, 'Percentile']\n",
    "    if desc_attribute == 'Fatalities':\n",
    "        attribute = 'Fatalities_Sum'\n",
    "    elif desc_attribute == 'Fatalities Per Capita':\n",
    "        attribute = 'PerCapitaFatalities'\n",
    "\n",
    "    f_fpc=original_df[attribute]\n",
    "    #fpc=df_109_516___Fatalities['PerCapitaFatalities']\n",
    "\n",
    "    #print('trying to now select 85th percentile value')\n",
    "    Select_a_Percentile = description.at[0,a]\n",
    "    Select_b_Percentile = description.at[0,b]\n",
    "    Select_c_Percentile = description.at[0,c]\n",
    "\n",
    "#print(Select_95_Percentile)\n",
    "\n",
    "#print()\n",
    "    Fatalities_a = f_fpc[f_fpc <= Select_a_Percentile]\n",
    "    Fatalities_a_b = f_fpc[(f_fpc > Select_a_Percentile) & (f_fpc <= Select_b_Percentile)]\n",
    "    Fatalities_b_c = f_fpc[(f_fpc > Select_b_Percentile) & (f_fpc <= Select_c_Percentile)]\n",
    "    Fatalities_c = f_fpc[(f_fpc > Select_c_Percentile)]\n",
    "\n",
    "    Fatalities_a = np.sort(Fatalities_a)\n",
    "    cdf_a = 1.0 * np.arange(len(Fatalities_a)) / float(len(Fatalities_a) - 1)\n",
    "    Fatalities_a_b = np.sort(Fatalities_a_b)\n",
    "    cdf_a_b = 1.0 * np.arange(len(Fatalities_a_b)) / float(len(Fatalities_a_b) - 1)\n",
    "    Fatalities_b_c = np.sort(Fatalities_b_c)\n",
    "    cdf_b_c = 1.0 * np.arange(len(Fatalities_b_c)) / float(len(Fatalities_b_c) - 1)\n",
    "    Fatalities_c = np.sort(Fatalities_c)\n",
    "    cdf_c = 1.0 * np.arange(len(Fatalities_c)) / float(len(Fatalities_c) - 1)\n",
    "    return((Fatalities_a,cdf_a), (Fatalities_a_b,cdf_a_b), (Fatalities_b_c,cdf_b_c), (Fatalities_c,cdf_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def single_hist_params (hist):\n",
    "    xlim_max = max(hist)\n",
    "    xlim_min = min(hist-1) # for x limit min\n",
    "\n",
    "    x_ticks = linspace(xlim_min,xlim_max,5)\n",
    "    x_int_list = [int(item) for item in x_ticks]\n",
    "\n",
    "    x_tick_labels = [str(item) for item in x_int_list]\n",
    "    x_tick_labels[1] = ''\n",
    "    x_tick_labels[3] = ''\n",
    "\n",
    "    num_most_common = Counter(hist).most_common(1)[0][1]\n",
    "    ylim_max=num_most_common + 3 #for y limit max\n",
    "\n",
    "    ylim_min = 0\n",
    "\n",
    "    y_ticks = linspace(ylim_min,ylim_max,3)\n",
    "    y_int_list = [int(item) for item in y_ticks]\n",
    "\n",
    "    y_tick_labels = [str(item) for item in y_int_list]\n",
    "    return(xlim_max, xlim_min, x_int_list, x_tick_labels, ylim_max, ylim_min, y_int_list, y_tick_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarytextline (cm_or_pg, total_events, perc_nonzero, total_nonzero, fpc_99th_nz, fpc_99th_nz_occurance, month_or_annual='monthly', resolution=0, country=0):\n",
    "\n",
    "    if cm_or_pg == 'PG' and country != 0:\n",
    "        text = f'In {country}, employing a unit of analysis that considers a {resolution} priogrid at a {month_or_annual} temporal resolution, yields {total_events} total events.\\nFrom this value, just less than {perc_nonzero}% report zero fatalities. Among a subset data frame, consisting of {total_nonzero} non-zero events,\\nthe 99th percentile reports {fpc_99th_nz} fatalities per capita (per 10,000 individuals), a threshold experienced {fpc_99th_nz_occurance} times.'\n",
    "        return(text)\n",
    "    \n",
    "    if cm_or_pg == 'PG' and country == 0:\n",
    "        text = f'Across Africa and the Middle East, employing a unit of analysis that considers a {resolution} priogrid at a {month_or_annual} temporal resolution,\\nyields {total_events} total events. From this value, just less than {perc_nonzero}% report zero fatalities. Among a subset data frame,\\nconsisting of {total_nonzero} non-zero events, the 99th percentile reports {fpc_99th_nz} fatalities per capita (per 10,000 individuals), a threshold experienced {fpc_99th_nz_occurance} times.'\n",
    "        return(text)\n",
    "\n",
    "    if cm_or_pg == 'CM' and country == 0:\n",
    "        text = f'Globally, employing a unit of analysis that considers each county boundary at a {month_or_annual} temporal resolution,\\nyields {total_events} total events. From this value, just less than {perc_nonzero}% report zero fatalities. Among a subset data frame,\\nconsisting of {total_nonzero} non-zero events, the 99th percentile reports {fpc_99th_nz} fatalities per capita (per 10,000 individuals), a threshold experienced {fpc_99th_nz_occurance} times.'\n",
    "        return(text)\n",
    "\n",
    "    if cm_or_pg and country != 0:\n",
    "        text = f'In {country}, employing a unit of analysis that exclusively considers this county boundary at a {month_or_annual} temporal resolution,\\nyields {total_events} total events. From this value, just less than {perc_nonzero}% report zero fatalities. Among a subset data frame, consisting\\nof {total_nonzero} non-zero events, the 99th percentile reports {fpc_99th_nz} fatalities per capita (per 10,000 individuals),\\na threshold experienced {fpc_99th_nz_occurance} times.'\n",
    "        return(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_summarytextline(cm_or_pg,A,B,C,D,month_or_annual='monthly',resolution=0, country=0):\n",
    "\n",
    "    cm__or__pg = cm_or_pg\n",
    "    mora = month_or_annual\n",
    "    r = resolution\n",
    "    c = country\n",
    "\n",
    "    total_events = len(A)\n",
    "    Percentage_non_zero = B.loc[0, 'Percentile']\n",
    "    total_nonzero = C.loc[1, '0']\n",
    "    PCF_Occurance = D.loc[1, '99']\n",
    "    PCF_total = D.loc[0, '99']\n",
    "        \n",
    "    txt = summarytextline(cm__or__pg, total_events, Percentage_non_zero, total_nonzero, PCF_total, PCF_Occurance, mora, r, c)\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_axes(ax, text, fontsize=18):\n",
    "        ax.text(0.5, 0.5, text, transform=ax.transAxes,\n",
    "                ha=\"center\", va=\"center\", fontsize=fontsize, color=\"darkgrey\")\n",
    "\n",
    "    #def statsheet(zerotable, nonzerotable_Fatality, nonzerotable_fpc, hist1, cdf1, hist2, cdf2, hist3, cdf3, hist4, cdf4, timeseries):    \n",
    "def statsheet(zerotable, textsummary, nonzerotable_Fatality, nonzerotable_fpc, hist1, cdf1, hist2, cdf2, hist3, cdf3, hist4, cdf4, timeline, PG_or_CM, month_or_annual, country=0, resolution=0):    \n",
    "\n",
    "    #nonzerotable_fpc['Fatalities Per Capita'] = nonzerotable_fpc['Fatalities Per Capita']*10000\n",
    "    #nonzerotable_fpc['Fatalities Per Capita'] = nonzerotable_fpc['Fatalities Per Capita'].round(1)\n",
    "    Unit_of_analysis = PG_or_CM\n",
    "    mora = month_or_annual \n",
    "    r = resolution\n",
    "    c = country\n",
    "    if resolution != 0:\n",
    "        res = resolution\n",
    "    else:\n",
    "        res = ''\n",
    "\n",
    "    if country != 0:\n",
    "        cntry = country\n",
    "    else:\n",
    "         cntry = 'Global'\n",
    "    \n",
    "    Title = cntry +' ' + mora + ' ' + res + ' ' + Unit_of_analysis + ' ' + 'Stat Sheet'\n",
    "\n",
    "    #if resolution != 0:\n",
    "\n",
    "    #For timeline--------------------------v\n",
    "    timeline_month_fatalitytotal = timeline.groupby([\"month_id\"]).Fatalities_Sum.sum().reset_index().reset_index()\n",
    "\n",
    "    timeline_month_fatalities20000 = timeline_month_fatalitytotal.loc[timeline_month_fatalitytotal['Fatalities_Sum']>20000]\n",
    "\n",
    "    index_to_color = timeline_month_fatalities20000['index']\n",
    "    #--------------------------------------^\n",
    "\n",
    "    units_of_analysis = '13000'\n",
    "    percent_zero_fromtable = '99.3%'\n",
    "    percent_nonzero_fromtable ='.6%'\n",
    "    total_nonzero_fromtable = '1300'\n",
    "    inf_total = '7'\n",
    "    MissingData1 ='Y# occurances of 2 or less# fatalities and Y# occurances of 3-5 fatalities.'\n",
    "    MissingData2 = 'Y# counts of fatalities between n and n'\n",
    "    MissingData3 = 'XXXXXXX# fatalities were recorded between XX and XX of XXXX, XXXXXX in XX-XX, XXXXXXXX# in XX-XX, and XXXXX# in XX-XX'\n",
    "    #inputtext = 'In this text I want to summarize:\\nalso, the per capita row reflects 1/10,000 individuals 1. The definition of event in this iteration 2.The total number of Events.\\n Including how many months and the month ranges. Describe the graphs \\n why do the total fatalities not match the total PCF (becuse 7 events in area with no population\\n This is the last line that you have room for!'\n",
    "    #inputtext = f'Defining an event, summarizing fatalities, as a 1x1 standard PRIO Grid across a monthly temporal resolution produced {units_of_analysis} units of analysis. Summary tables\\n discriminate between events reflecting zero and non-zero fatality results. At the employed unit scale, zero fatalities account for {percent_zero_fromtable} of all events. The remaining\\n tables and graphics are constituent to that remaining {percent_nonzero_fromtable} ({total_nonzero_fromtable}) fatalities. Non-zero results from the Per Capita table reflect a unique total from the reported fatalities,\\n {inf_total} events contained fatalities in units with no expected population values. Several graphics host data that is not completely visualized with extreme values exceeding\\n the Y-axis; These locations are indicated by a prominent red bar. The following relationships uncover the obscured information. 1st-85th Percentile: There were\\n {MissingData1} ; 99.5-100th Percentile: {MissingData2}'\n",
    "    inputtext = 'This is incomplete for now but statistics are generated to insert in next push...'\n",
    "    fig = plt.figure(figsize=(11, 8.5), constrained_layout = True)\n",
    "    spec = fig.add_gridspec(7, 4)\n",
    "\n",
    "#Zero table\n",
    "    ax0 = fig.add_subplot(spec[0:3, :-3])\n",
    "    #annotate_axes(ax0, 'ax0')\n",
    "    table_ax0 = ax0.table(cellText=zerotable.values,\n",
    "                    colLabels=zerotable.columns,\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    \n",
    "    FirstFatality = table_ax0[1,0]\n",
    "    FirstFatality.set_edgecolor('#e34a33')\n",
    "    FirstFatality.set_linewidth(2)\n",
    "\n",
    "    ax0.add_patch(FirstFatality)\n",
    "    \n",
    "    table_ax0.set_fontsize(8)\n",
    "    ax0.axis('off')\n",
    "    table_ax0.scale(1, 1.65)\n",
    "    ax0.set_title('Distribution of Fatalities\\nAll zero and non-zero events', size=10)\n",
    "\n",
    "# Summary Text\n",
    "    \n",
    "    #summarytext = summarytextline (Unit_of_analysis, total_events, perc_nonzero, total_nonzero, fpc_99th_nz, fpc_99th_nz_occurance, mora, r, c)\n",
    "\n",
    "    ax1 = fig.add_subplot(spec[0, -3:])\n",
    "    #annotate_axes(ax1, 'ax1')\n",
    "    ax1.text(0, 0.5,textsummary, fontsize=8, va='top',wrap='True',\n",
    "                      bbox=dict(facecolor='none', edgecolor='black', boxstyle='round,pad=1'))\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(Title, size=14, fontweight=\"bold\")\n",
    "\n",
    "    #ax1.margins(x=-.25)\n",
    "    #text_ax1.scale(-.25, 1)\n",
    "\n",
    "#plt.text(5, 5, input_text, fontsize=10, style='oblique', ha='center', va='top', wrap=True, rotation=-30)\n",
    "\n",
    "#Non-Zero Fatalities\n",
    "    ax2 = fig.add_subplot(spec[1, -3:])\n",
    "    #annotate_axes(ax1, 'ax1')\n",
    "    table_ax2 = ax2.table(cellText=nonzerotable_fpc.values,\n",
    "                    colLabels=nonzerotable_fpc.columns,\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    \n",
    "    FPC_99_val = table_ax2[1,9]\n",
    "    FPC_99_val.set_edgecolor('#e34a33')\n",
    "    FPC_99_val.set_linewidth(2.5)\n",
    "\n",
    "    FPC_99_occ = table_ax2[2,9]\n",
    "    FPC_99_occ.set_edgecolor('#e34a33')\n",
    "    FPC_99_occ.set_linewidth(2.5)\n",
    "\n",
    "    ax2.add_patch(FPC_99_val)\n",
    "    ax2.add_patch(FPC_99_occ)\n",
    "\n",
    "    table_ax2.auto_set_font_size(False)\n",
    "    table_ax2.set_fontsize(6)\n",
    "    ax2.axis('off')\n",
    "    table_ax2.scale(1.0, 1.45)\n",
    "\n",
    "#Non-Zero Fatalities\n",
    "    ax3 = fig.add_subplot(spec[2, -3:])\n",
    "\n",
    "    cellcolours_array = [[ '#ffffff', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9','#fef0d9', '#fdcc8a', '#fdcc8a', '#fc8d59', '#fc8d59', '#e34a33'],\n",
    "                        ['#ffffff', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fef0d9', '#fdcc8a', '#fdcc8a', '#fc8d59', '#fc8d59', '#e34a33']]\n",
    "\n",
    "    table_ax3 = ax3.table(cellText=nonzerotable_Fatality.values,\n",
    "                    colLabels=nonzerotable_Fatality.columns,\n",
    "                    cellColours=cellcolours_array,\n",
    "                    loc='center',\n",
    "                    cellLoc='center',\n",
    "                    rowLoc='center')\n",
    "    table_ax3.auto_set_font_size(False)\n",
    "    table_ax3.set_fontsize(6)\n",
    "    ax3.axis('off')\n",
    "    table_ax3.scale(1, 1.45)\n",
    "\n",
    "    #ax4_set_ylim_max,ax4_set_xlim_max,ax4_set_xticks = ax4_params(res)\n",
    "    ax4xlim_max, ax4xlim_min, ax4x_int_list, ax4x_tick_labels, ax4ylim_max, ax4ylim_min, ax4y_int_list, ax4y_tick_labels = single_hist_params (hist1)\n",
    "    #Histogram 1-85\n",
    "    ax4 = fig.add_subplot(spec[3, 0])\n",
    "    #annotate_axes(ax4, 'ax4')\n",
    "    ax4.hist(hist1, bins=100, color='black')\n",
    "    ax4.set_title(\"1-85th Percentile\")\n",
    "    #for i in range(0,10):\n",
    "    #    patches_ax4[i].set_facecolor('red')\n",
    "    #ax4.set_xlabel(\"Fatalities\")\n",
    "    ax4.set_ylabel(\"Fatalities\")\n",
    "\n",
    "    ax4.set_ylim(ax4ylim_min, ax4ylim_max)\n",
    "    ax4.set_yticks(ticks=ax4y_int_list, labels=ax4y_tick_labels)\n",
    "\n",
    "    ax4.set_xlim(ax4xlim_min, ax4xlim_max)\n",
    "    ax4.set_xticks(ticks=ax4x_int_list, labels=ax4x_tick_labels)\n",
    "\n",
    "    #ax4.set_yticks((0,500,1000,1500,2000))\n",
    "    #ax4.set_yticks(ticks=[0,500,1000,1500,2000],labels=['0',' ','1000','','2000'])\n",
    "\n",
    "    #for label in ax4.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax4.tick_params(axis='x', labelcolor='white', labelsize=.1)\n",
    "    ax4.set_facecolor('#fef0d9')\n",
    "\n",
    "    #CDF 1-85\n",
    "    ax5 = fig.add_subplot(spec[4, 0])\n",
    "    #annotate_axes(ax5, 'ax5')\n",
    "    ax5.plot(hist1, cdf1, color='black')\n",
    "    ax5.set_xlabel(\"Fatalities\")\n",
    "    ax5.set_ylabel(\"Probability\")\n",
    "    ax5.set_title(\"CDF (1-85)\")\n",
    "    #ax5.sharex(ax4)\n",
    "    ax5.set_xticks(ticks=ax4x_int_list, labels=ax4x_tick_labels)\n",
    "    #ax5.set_yticks((0,50,100,200,225))\n",
    "\n",
    "    #for label in ax5.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax5.xaxis.label.set_color('black')\n",
    "    ax5.set_facecolor('#fef0d9')\n",
    "    \n",
    "    #ax6_set_xticks, ax6_set_xticks_labels, ax6_set_yticks, ax6_set_yticks_labels = ax6_params(res)\n",
    "    ax6xlim_max, ax6xlim_min, ax6x_int_list, ax6x_tick_labels, ax6ylim_max, ax6ylim_min, ax6y_int_list, ax6y_tick_labels = single_hist_params(hist2)\n",
    "\n",
    "    #Histogram 85-95\n",
    "    ax6 = fig.add_subplot(spec[3, 1])\n",
    "    #annotate_axes(ax6, 'ax6')\n",
    "    ax6.hist(hist2, bins=100, color='black')\n",
    "    ax6.set_title(\"85-95th Percentile\")\n",
    "    ax6.tick_params(axis='x', labelcolor='white')\n",
    "\n",
    "    ax6.set_xlim(ax6xlim_min, ax6xlim_max)\n",
    "    ax6.set_xticks(ticks=ax6x_int_list, labels=ax6x_tick_labels)\n",
    "    #for label in ax6.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax6.set_ylim(ax6ylim_min, ax6ylim_max)\n",
    "    ax6.set_yticks(ticks=ax6y_int_list,labels=ax6y_tick_labels)\n",
    "    ax6.set_facecolor('#fdcc8a')\n",
    "\n",
    "    #CDF 85-95\n",
    "    ax7 = fig.add_subplot(spec[4, 1])\n",
    "    #annotate_axes(ax7, 'ax7')\n",
    "    ax7.plot(hist2, cdf2, color='black')\n",
    "    ax7.set_title(\"CDF (85-95)\")\n",
    "    #ax7.sharex(ax6)\n",
    "    ax7.set_xticks(ticks=ax6x_int_list, labels=ax6x_tick_labels)\n",
    "    #for label in ax7.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax7.set_facecolor('#fdcc8a')\n",
    "\n",
    "    #ax8_set_xticks, ax8_set_xticks_labels, ax8_set_yticks, ax8_set_yticks_labels = ax8_params(res)\n",
    "    ax8xlim_max, ax8xlim_min, ax8x_int_list, ax8x_tick_labels, ax8ylim_max, ax8ylim_min, ax8y_int_list, ax8y_tick_labels = single_hist_params(hist3)\n",
    "\n",
    "    #Histogram 95-99.5\n",
    "    ax8 = fig.add_subplot(spec[3, 2])\n",
    "    #annotate_axes(ax8, 'ax8')\n",
    "    ax8.hist(hist3, bins=100, color='black')\n",
    "    ax8.set_title(\"95-99.5 Percentile\")\n",
    "    ax8.tick_params(axis='x', labelcolor='white')\n",
    "    \n",
    "    ax8.set_xlim(ax8xlim_min, ax8xlim_max)\n",
    "    ax8.set_xticks(ticks=ax8x_int_list, labels=ax8x_tick_labels)\n",
    "\n",
    "    ax8.set_ylim(ax8ylim_min, ax8ylim_max)\n",
    "    ax8.set_yticks(ticks=ax8y_int_list,labels=ax8y_tick_labels)\n",
    "    ax8.set_facecolor('#fc8d59')\n",
    "\n",
    "    #CDF 95-99.5\n",
    "    ax9 = fig.add_subplot(spec[4, 2])\n",
    "    #annotate_axes(ax9, 'ax9')\n",
    "    ax9.plot(hist3, cdf3, color = 'black')\n",
    "    ax9.set_title(\"CDF (95-99.5)\")\n",
    "    #ax9.sharex(ax8)\n",
    "    ax9.set_xticks(ticks=ax8x_int_list, labels=ax8x_tick_labels)\n",
    "\n",
    "    #ax9.set_xticks((125,200,300,400,500,600,700,800),)\n",
    "    #for label in ax9.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax9.set_facecolor('#fc8d59')\n",
    "\n",
    "    #ax10_set_xticks, ax10_set_xticks_labels, ax10_set_yticks, ax10_set_yticks_labels, ylim = ax10_params(res)\n",
    "    ax10xlim_max, ax10xlim_min, ax10x_int_list, ax10x_tick_labels, ax10ylim_max, ax10ylim_min, ax10y_int_list, ax10y_tick_labels = single_hist_params(hist4)\n",
    "\n",
    "    #Histogram 99.5-100\n",
    "    ax10 = fig.add_subplot(spec[3, 3])\n",
    "    #annotate_axes(ax10, 'ax10')\n",
    "    N, bins, patches_ax10=ax10.hist(hist4, bins=100, color='black')\n",
    "    ax10.set_title(\"99.5-100th Percentile\")\n",
    "    ax10.tick_params(axis='x', labelcolor='white')\n",
    "    \n",
    "    ax10.set_ylim(ax10ylim_min, ax10ylim_max)\n",
    "    ax10.set_yticks(ticks=ax10y_int_list,labels=ax10y_tick_labels)\n",
    "\n",
    "    ax10.set_xticks(ticks=ax10x_int_list, labels=ax10x_tick_labels)\n",
    "    #for i in range(0,2):\n",
    "    #    patches_ax10[i].set_edgecolor('white')\n",
    "    #    patches_ax10[i].set_facecolor('red')\n",
    "\n",
    "    #for label in ax10.xaxis.get_ticklabels()[::1]:\n",
    "    #    label.set_visible(False)\n",
    "    ax10.set_facecolor('#e34a33')\n",
    "\n",
    "    #CDF 99.5-100\n",
    "    ax11 = fig.add_subplot(spec[4, 3])\n",
    "    #annotate_axes(ax11, 'ax11')\n",
    "    ax11.plot(hist4, cdf4, color = 'black')\n",
    "    ax11.set_title(\"CDF (99.5-100)\")\n",
    "    #ax11.sharex(ax10)\n",
    "    ax11.set_xticks(ticks=ax10x_int_list, labels=ax10x_tick_labels)\n",
    "\n",
    "    #ax11.set_xticks((10000,50000,100000,150000))\n",
    "    #for label in ax11.xaxis.get_ticklabels()[::2]:\n",
    "    #    label.set_visible(False)\n",
    "    ax11.tick_params(axis='x', labelsize=7)\n",
    "\n",
    "    ax11.set_facecolor('#e34a33')\n",
    "\n",
    "    if country == 0:\n",
    "        ax12lim_max = 17500\n",
    "        ax12y_int_list = [0,1000,5000, 7500, 10000, 1250, 15000, 17500]\n",
    "        ax12y_tick_labels = ['0','1000','5000', '', '10000','', '15000', '17500']\n",
    "    \n",
    "    else:\n",
    "        ax12lim_max = 5000\n",
    "        ax12y_int_list = [0, 500, 750, 1250, 2000, 2750, 3500, 5000]\n",
    "        ax12y_tick_labels = ['0','500', '', '1250', '2000', '2750', '3500', '5000']\n",
    "\n",
    "    ax12 = fig.add_subplot(spec[5:, :])\n",
    "    #annotate_axes(ax12, 'ax12')\n",
    "    bars=ax12.bar(timeline_month_fatalitytotal['month_id'],timeline_month_fatalitytotal['Fatalities_Sum'],align='center', color = 'darkgrey') # A bar chart\n",
    "    ax12.set_xlabel('Month')\n",
    "    ax12.set_ylabel('Total Fatalities')\n",
    "    ax12.set_ylim(0, ax12lim_max)\n",
    "    ax12.set_yticks(ticks=ax12y_int_list,labels=ax12y_tick_labels)\n",
    "    for col in index_to_color:\n",
    "        # That's it!\n",
    "        bars[col].set_color('white')\n",
    "    \n",
    "    #ax7 = fig.add_subplot(spec[4, 1])\n",
    "    #ax.get_yaxis().set_label_coords(-0.1,0.5)\n",
    "\n",
    "    fig.align_ylabels()\n",
    "\n",
    "    #fig.tight_layout()\n",
    "    return(plt.show())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pg = queryset_base_PG.publish().fetch()\n",
    "df_pg = df_pg.reset_index()\n",
    "\n",
    "df_cm = queryset_base_CM.publish().fetch()\n",
    "df_cm = df_cm.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pg = df_pg.reset_index()\n",
    "# df_109_516 = df_pg.loc[(df_pg['month_id']>=109) & (df_pg['month_id']<= 516)]\n",
    "\n",
    "# df_109_516__country = df_109_516[(df_109_516['country_name'] == 'Ethiopia')]\n",
    "\n",
    "\n",
    "# print(df_109_516__country.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Pantaleon(PG_or_CM, d_pg, d_cm, monthly_or_annual, resolution=0, country=0, recent_or_all=0):\n",
    "\n",
    "    pg__or__cm = PG_or_CM\n",
    "    res = resolution\n",
    "    cntry = country\n",
    "    m_or_a = monthly_or_annual\n",
    "    \n",
    "    if PG_or_CM == 'PG':\n",
    "        #df_pg = queryset_base_PG.publish().fetch()\n",
    "    #Reset index in order to access 'month_id' and 'priogrid_gid' columns\n",
    "        #d_pg = d_pg.reset_index()\n",
    "        df_109_516 = d_pg.loc[(d_pg['month_id']>=109) & (d_pg['month_id']<= 516)]\n",
    "\n",
    "    else:\n",
    "        #df_cm = queryset_base_CM.publish().fetch()\n",
    "        #d_cm = d_cm.reset_index()\n",
    "        df_109_516 = d_cm.loc[(d_cm['month_id']>=109) & (d_cm['month_id']<= 516)]\n",
    "\n",
    "    df__PP=PGM_preprocess(df_109_516)\n",
    "    df_ag, GIS=PRIO_Agg_serious(df__PP, monthly_or_annual,pg__or__cm, res, cntry, recent_or_all)\n",
    "\n",
    "    #total_events = report_length(df_ag, PG_or_CM,'Global', monthly_or_annual,res)\n",
    "    #print(total_events)\n",
    "\n",
    "    format_fatalities_zero=Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','zero')\n",
    "    #print(format_fatalities_zero.dtypes)\n",
    "    \n",
    "    described_fatalities_zero = correct_definition_df(format_fatalities_zero,df_ag,'zero','No',pg__or__cm)\n",
    "\n",
    "    fatalities_nonzero, described_fatalities_nonzero,len_fat = Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','non-zero')\n",
    "    Fatalities_nonzero_cordef = correct_definition_df(described_fatalities_nonzero, fatalities_nonzero,'non-zero','No')\n",
    "    #print(len_fat)\n",
    "    \n",
    "    pcf_nonzero, described_pcf_nonzero, len_fpc = Format_summary_stats(PG_or_CM,df_ag,'PerCapitaFatalities','non-zero')\n",
    "    pcf_nonzero_cordef = correct_definition_df(described_pcf_nonzero, pcf_nonzero,'non-zero','No')\n",
    "    #print(len_fpc)\n",
    "    a, b, c, d=params_for_graphs(Fatalities_nonzero_cordef,fatalities_nonzero,85,95,99.5)\n",
    "\n",
    "    #print('type of A:')\n",
    "    a_dic = a[0]\n",
    "    a_cdf = a[1]\n",
    "    b_dic = b[0]\n",
    "    b_cdf = b[1]\n",
    "    c_dic = c[0]\n",
    "    c_cdf = c[1]\n",
    "    d_dic = d[0]\n",
    "    d_cdf = d[1]\n",
    "    #def statsheet(zerotable, nonzerotable_Fatality, nonzerotable_fpc, hist1, cdf1, hist2, cdf2, hist3, cdf3, hist4, cdf4, timeline, PG_or_CM, month_or_annual, country=0, resolution=0):    \n",
    "    \n",
    "    txt = format_for_summarytextline(pg__or__cm,df_ag,described_fatalities_zero,Fatalities_nonzero_cordef,pcf_nonzero_cordef,m_or_a,res, cntry)\n",
    "    x = statsheet(described_fatalities_zero, txt, Fatalities_nonzero_cordef, pcf_nonzero_cordef, a_dic, a_cdf, b_dic, b_cdf, c_dic, c_cdf, d_dic, d_cdf, fatalities_nonzero, pg__or__cm, m_or_a, cntry, res)    \n",
    "    return(x,GIS)\n",
    "    #return(described_fatalities_zero, Fatalities_nonzero_cordef, pcf_nonzero_cordef, a_dic, a_cdf, b_dic, b_cdf, c_dic, c_cdf, d_dic, d_cdf, fatalities_nonzero,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onlyAggfile(PG_or_CM, qs, monthly_or_annual, resolution=0, country=0):\n",
    "\n",
    "#     df = qs\n",
    "\n",
    "#     pg__or__cm = PG_or_CM\n",
    "#     res = resolution\n",
    "#     cntry = country\n",
    "#     m_or_a = monthly_or_annual\n",
    "    \n",
    "\n",
    "#     #Reset index in order to access 'month_id' and 'priogrid_gid' columns\n",
    "#     df = df.reset_index()\n",
    "#     df_109_516 = df.loc[(df['month_id']>=109) & (df['month_id']<= 516)]\n",
    "\n",
    "#     df__PP=PGM_preprocess(df_109_516)\n",
    "#     #df_2022=PRIO_Agg(df__PP, monthly_or_annual,pg__or__cm, res, cntry)\n",
    "#     return(df__PP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM_orPG ='PG'\n",
    "# temporal_resolution = 'monthly'\n",
    "# Scale = '1x1'\n",
    "# Country = 'Ethiopia'\n",
    "# rec_or_all = 'all'\n",
    "\n",
    "# #df_pg = df_pg.reset_index()\n",
    "# df_109_516 = df_pg.loc[(df_pg['month_id']>=109) & (df_pg['month_id']<= 516)]\n",
    "\n",
    "# df__PP=PGM_preprocess(df_109_516)\n",
    "\n",
    "# #year_dictionary = setup_DOBY(df__PP, country, recent_or_all)\n",
    "# #print(year_dictionary)\n",
    "# df_2022, x= PRIO_Agg_serious(df__PP, temporal_resolution,CM_orPG, Scale, Country, rec_or_all)\n",
    "\n",
    "# #hmm = df_109_516.loc[(df_109_516['country_name']=='Ethiopia')]\n",
    "# print(df_2022.head(10))\n",
    "# print(list(df__PP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Determine if there are multiple country ids for a country name:\n",
    "def DOBY(n):\n",
    "    n['Year_range'] = list(zip(n[\"C_start_year\"], n[\"C_end_year\"]))\n",
    "    d = dict(zip(n['C_id'], n['Year_range']))\n",
    "    return(d)\n",
    "\n",
    "#boundaries = 'first'\n",
    "\n",
    "def setup_DOBY(df, country, boundary_requirement):\n",
    "\n",
    "    filtered__country = df.loc[(df['country_name']==country)]\n",
    "    filtered__country = filtered__country.rename(columns={'country_id':'C_id'})\n",
    "    country_and_year = filtered__country.groupby(['C_id', 'country_name', 'C_start_year', 'C_end_year']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "    cids = list(unique(country_and_year['C_id']))\n",
    "\n",
    "    length_of_cids = len(cids)\n",
    "    country_and_year_sorted=country_and_year.sort_values(by=['C_start_year'],ascending=False)\n",
    "    if length_of_cids > 1 and boundary_requirement == 'recent':\n",
    "        country_head=country_and_year_sorted.head(1)\n",
    "        year_dictionary = DOBY(country_head)\n",
    "        return(year_dictionary)\n",
    "\n",
    "    else:\n",
    "        year_dictionary = DOBY(country_and_year_sorted)\n",
    "        return(year_dictionary)\n",
    "\n",
    "#year_dictionary = setup_DOBY(df__PP, 'Ethiopia', 'all')\n",
    "\n",
    "for index, (key, value) in enumerate(year_dictionary.items()):\n",
    "    print(index, key, value)\n",
    "    start = value[0]\n",
    "    end = value[1]\n",
    "    print(start, end)\n",
    "\n",
    "    if index == 0:\n",
    "        print('going to treat the firstborn differently...')\n",
    "    else:\n",
    "        print('different rules apply to the next children')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Determine if there are multiple country ids for a country name:\n",
    "\n",
    "#2 Establish the years corresponding to each country id\n",
    "\n",
    "#3 if/when county ids are contiguous -- establish a statement that avoids redundat data\n",
    "        #if year is shared turn <= to < \n",
    "        \n",
    "#4 pose questions as field: Do you want data retreived from the most recent country boundary\n",
    "#       or aggregated summary of all historic boundaries with the same name?\n",
    "        #IF yes -- create for loop and combine dataframes\n",
    "def map_c_id_to_aggregations(x):       \n",
    "        withcountry = x.groupby(['Scale_ID','country_id']).size().to_frame().iloc[:, :-1].reset_index()\n",
    "                #This is exactly the problem ------^\n",
    "        withcountry['country_id'] = withcountry['country_id'].astype(str)\n",
    "\n",
    "        withcountry['Country_id_present'] = withcountry.groupby(['Scale_ID'])['country_id'].transform(lambda x : '___'.join(x))\n",
    "        withcountry = withcountry.drop(['country_id'], axis=1).drop_duplicates()\n",
    "\n",
    "        withcountry__dic = dict(zip(withcountry.Scale_ID, withcountry.Country_id_present))\n",
    "        #print(withcountry)\n",
    "\n",
    "        x['Countries_In_AG_Unit']= x['Scale_ID'].map(withcountry__dic)\n",
    "        x['Included_Countries'] = x['Countries_In_AG_Unit'].str.split('___')\n",
    "        return(x)\n",
    "\n",
    "df_22 = map_c_id_to_aggregations(df_2022)\n",
    "#print(df_22.tail(3))\n",
    "#This is where we need a function:\n",
    "#year_dictionary = setup_DOBY(df__PP, 'Ethiopia', 'recent')\n",
    "\n",
    "#selected_country = df_22.loc[df_22['Included_Countries'].explode().eq('192').loc[lambda x: x].index]\n",
    "#print(year_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where we need a function:\n",
    "#year_dictionary = setup_DOBY(df__PP, 'Ethiopia', 'recent')\n",
    "#if multiple keys in dictionary: create loop\n",
    "\n",
    "def scale_and_countryid(dictionary_input, table_input, scale):\n",
    "        \n",
    "        year_len_dictionary=len(dictionary_input)\n",
    "\n",
    "        if year_len_dictionary > 1:\n",
    "                #if running for 'all'\n",
    "                print('multiple dictionary keys')\n",
    "                join_multi_country_ID = pd.DataFrame()\n",
    "\n",
    "                for index, (key, value) in enumerate(dictionary_input.items()):\n",
    "                        print(index)\n",
    "                        key = str(key)\n",
    "                        print(key)\n",
    "                        start = value[0]\n",
    "                        print(start)\n",
    "                        end = value[1]\n",
    "                        print(end)\n",
    "                        if index == 0:\n",
    "                                print('index 0:', index, ' includes start value: ', start, 'and end value: ',end)\n",
    "                                #--\n",
    "                                if scale != '1x1': #because this field is a list\n",
    "                                        selected_country = table_input.loc[table_input['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                                else: #because this field is just a value\n",
    "                                        #going to have to convert this field to a string type\n",
    "                                        selected_country = table_input.loc[table_input['country_id']==key]\n",
    "                                #---\n",
    "                                selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id']<= end)]\n",
    "                                \n",
    "                                if scale != '1x1':\n",
    "                                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                                else:\n",
    "                                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'C_start_year','C_end_year'], axis = 1)\n",
    "\n",
    "                                selected_filtered_country.drop_duplicates()\n",
    "                                print(selected_filtered_country.tail(5))\n",
    "\n",
    "                                chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                                print(chckPG)\n",
    "                                chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                                print(chckmonth)\n",
    "                                all =len(selected_filtered_country)\n",
    "                                print(all)\n",
    "                                #---\n",
    "                                df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                                #append to empty dataframe\n",
    "                                df_2022_grouped['Applied_cid'] = key\n",
    "                                print('dataframe for:', key)\n",
    "                                print(df_2022_grouped.tail(3))\n",
    "                                join_multi_country_ID = join_multi_country_ID.append(df_2022_grouped)\n",
    "                        else:\n",
    "                                print('index should be other than 0:', index, ' includes start value: ', start, 'and end value: ',end)\n",
    "                                if scale != '1x1': #because this field is a list\n",
    "                                        selected_country = table_input.loc[table_input['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                                else: #because this field is just a value\n",
    "                                        #going to have to convert this field to a string type\n",
    "                                        selected_country = table_input.loc[table_input['country_id']==key]\n",
    "\n",
    "                                selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id'] < end)]\n",
    "                                #---\n",
    "                                if scale != '1x1':\n",
    "                                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                                else:\n",
    "                                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'C_start_year','C_end_year'], axis = 1)                                \n",
    "                                \n",
    "                                selected_filtered_country.drop_duplicates()\n",
    "                                print(selected_filtered_country.tail(5))\n",
    "\n",
    "                                chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                                print('length of PG: ',chckPG)\n",
    "                                chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                                print('length of monthid: ',chckmonth)\n",
    "                                all =len(selected_filtered_country)\n",
    "                                print('total; ',all)\n",
    "                            #---\n",
    "                                df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                                df_2022_grouped['Applied_cid'] = key\n",
    "                                print('dataframe for:', key)\n",
    "                                print(df_2022_grouped.tail(3))\n",
    "                                join_multi_country_ID = join_multi_country_ID.append(df_2022_grouped)\n",
    "\n",
    "                return(join_multi_country_ID)\n",
    "\n",
    "        else:\n",
    "                for key, value in dictionary_input.items():\n",
    "                        key = str(key)\n",
    "                        print(key)\n",
    "                        start = value[0]\n",
    "                        print(start)\n",
    "                        end = value[1]\n",
    "                        print(end)\n",
    "                        if scale != '1x1': #because this field is a list\n",
    "                                selected_country = table_input.loc[table_input['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                        else: #because this field is just a value\n",
    "                                        #going to have to convert this field to a string type\n",
    "                                selected_country = table_input.loc[table_input['country_id']==key]\n",
    "\n",
    "                        selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id']<= end)]\n",
    "                        if scale != '1x1':\n",
    "                                selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                        else:\n",
    "                                selected_filtered_country = selected_filtered_country.drop(['country_id', 'C_start_year','C_end_year'], axis = 1)                          \n",
    "                        \n",
    "                        selected_filtered_country.drop_duplicates()\n",
    "                        #print(selected_filtered_country.tail(5))\n",
    "\n",
    "                        chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                        print(chckPG)\n",
    "                        chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                        print(chckmonth)\n",
    "                        all =len(selected_filtered_country)\n",
    "                        print(all)\n",
    "\n",
    "                        df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                        df_2022_grouped['Applied_cid'] = key\n",
    "                        return(df_2022_grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the scale/country ID all together:\n",
    "#This will need to be applied within the PRIO_Agg function which \n",
    "#   for this purpose is broken apart into PRIO_Agg_silly\n",
    "# CM_orPG ='PG'\n",
    "# temporal_resolution = 'monthly'\n",
    "# Scale = '2x2'\n",
    "# Country = 'Ethiopia'\n",
    "# recent_or_all = 'all'\n",
    "\n",
    "# #df_pg = df_pg.reset_index()\n",
    "# df_109_516 = df_pg.loc[(df_pg['month_id']>=109) & (df_pg['month_id']<= 516)]\n",
    "\n",
    "# df__PP=PGM_preprocess(df_109_516)\n",
    "\n",
    "# df_2022, x=PRIO_Agg_Silly(df__PP, temporal_resolution,CM_orPG, Scale, Country)\n",
    "\n",
    "# df_22 = map_c_id_to_aggregations(df_2022)\n",
    "\n",
    "# year_dictionary = setup_DOBY(df__PP, Country, recent_or_all)\n",
    "\n",
    "# #last\n",
    "# xx = scale_and_countryid(year_dictionary, df_22)\n",
    "# #print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is where we need a function:\n",
    "year_dictionary = setup_DOBY(df__PP, 'Ethiopia', 'all')\n",
    "#if multiple keys in dictionary: create loop\n",
    "dicyear_length=len(year_dictionary.keys())\n",
    "print(dicyear_length)\n",
    "\n",
    "if dicyear_length > 1:\n",
    "        print('multiple dictionary keys')\n",
    "        join_multi_country_ID = pd.DataFrame()\n",
    "\n",
    "        for index, (key, value) in enumerate(year_dictionary.items()):\n",
    "                print(index)\n",
    "                key = str(key)\n",
    "                print(key)\n",
    "                start = value[0]\n",
    "                print(start)\n",
    "                end = value[1]\n",
    "                print(end)\n",
    "                if index == 0:\n",
    "                        print('index 0:', index, ' includes start value: ', start, 'and end value: ',end)\n",
    "                        selected_country = df_22.loc[df_22['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                        selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id']<= end)]\n",
    "                        #---\n",
    "                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                        selected_filtered_country.drop_duplicates()\n",
    "                        print(selected_filtered_country.tail(2))\n",
    "                        print(selected_filtered_country.head(2))\n",
    "\n",
    "                        chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                        print('length of PG:',chckPG)\n",
    "                        chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                        print('length of monthid: ',chckmonth)\n",
    "                        all =len(selected_filtered_country)\n",
    "                        print('Total: ',all)\n",
    "                        #---\n",
    "                        df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                        #append to empty dataframe\n",
    "                        df_2022_grouped['Applied_cid'] = key\n",
    "                        #print('dataframe for:', key)\n",
    "                        #print(df_2022_grouped.tail(3))\n",
    "                        join_multi_country_ID = join_multi_country_ID.append(df_2022_grouped)\n",
    "                else:\n",
    "                        print('index should be other than 0:', index, ' includes start value: ', start, 'and end value: ',end)\n",
    "                        selected_country = df_22.loc[df_22['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                        selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id'] < end)]\n",
    "                        #---\n",
    "                        selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                        selected_filtered_country.drop_duplicates()\n",
    "                        #print(selected_filtered_country.tail(5))\n",
    "\n",
    "                        chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                        print('length of PG: ',chckPG)\n",
    "                        chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                        print('length of monthid: ',chckmonth)\n",
    "                        all =len(selected_filtered_country)\n",
    "                        print('total; ',all)\n",
    "                        #---\n",
    "                        df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "                        df_2022_grouped['Applied_cid'] = key\n",
    "                        #print('dataframe for:', key)\n",
    "                        #print(df_2022_grouped.tail(3))\n",
    "                        join_multi_country_ID = join_multi_country_ID.append(df_2022_grouped)\n",
    "        print(join_multi_country_ID.tail(2))\n",
    "        print(join_multi_country_ID.head(2))\n",
    "else:\n",
    "        for key, value in year_dictionary.items():\n",
    "                key = str(key)\n",
    "                print(key)\n",
    "                start = value[0]\n",
    "                print(start)\n",
    "                end = value[1]\n",
    "                print(end)\n",
    "                selected_country = df_22.loc[df_22['Included_Countries'].explode().eq(key).loc[lambda x: x].index]\n",
    "                selected_filtered_country = selected_country.loc[(selected_country['year_id']>=start) & (selected_country['year_id']<= end)]\n",
    "                selected_filtered_country = selected_filtered_country.drop(['country_id', 'Included_Countries','C_start_year','C_end_year'], axis = 1)\n",
    "                selected_filtered_country.drop_duplicates()\n",
    "                print(selected_filtered_country.tail(5))\n",
    "\n",
    "                chckPG = len(unique(selected_filtered_country['priogrid_gid']))\n",
    "                print(chckPG)\n",
    "                chckmonth = len(unique(selected_filtered_country['month_id']))\n",
    "                print(chckmonth)\n",
    "                all =len(selected_filtered_country)\n",
    "                print(all)\n",
    "#selected_country = df_2022.loc[df_2022['Included_Countries'].explode().eq('57').loc[lambda x: x].index]\n",
    "#selected_country = selected_country.drop('Included_Countries', axis=1)\n",
    "#return(selected_country)\n",
    "\n",
    "#selected_filtered_country = selected_country.loc[(selected_country['year_id']>=1993) & (selected_country['year_id']<= 2050)]\n",
    "#df_2022_grouped = selected_filtered_country.groupby(['month_id','year_id','Scale_ID']).agg({'PerCapitaFatalities':'sum','Fatalities_Sum':'sum'}).reset_index()\n",
    "\n",
    "#hmm = df_2022.loc[(df_2022['country_id']==57)]\n",
    "\n",
    "#display(df_2022_grouped)\n",
    "#proof = join_multi_country_ID.loc[(join_multi_country_ID['year_id']==1993) & (join_multi_country_ID['Applied_cid']== 191)]\n",
    "#checkagain = join_multi_country_ID.loc[(join_multi_country_ID['month_id']==156)]\n",
    "#print(checkagain)\n",
    "#-----THIS RIGHT HERE----#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imjustken(PG_or_CM, d_pg, d_cm,  monthly_or_annual, resolution=0, country=0, rec_or_all=0):\n",
    "\n",
    "    pg__or__cm = PG_or_CM\n",
    "    res = resolution\n",
    "    cntry = country\n",
    "    m_or_a = monthly_or_annual\n",
    "    re__or__all = rec_or_all\n",
    "    \n",
    "    if PG_or_CM == 'PG':\n",
    "        #df_pg = queryset_base_PG.publish().fetch()\n",
    "    #Reset index in order to access 'month_id' and 'priogrid_gid' columns\n",
    "        d_pg = d_pg.reset_index()\n",
    "        df_109_516 = d_pg.loc[(d_pg['month_id']>=109) & (d_pg['month_id']<= 516)]\n",
    "\n",
    "    else:\n",
    "        #df_cm = queryset_base_CM.publish().fetch()\n",
    "        d_cm = d_cm.reset_index()\n",
    "        df_109_516 = d_cm.loc[(d_cm['month_id']>=109) & (d_cm['month_id']<= 516)]\n",
    "\n",
    "    df__PP=PGM_preprocess(df_109_516)\n",
    "    df_ag, GIS=PRIO_Agg_serious(df__PP, monthly_or_annual,pg__or__cm, res, cntry, re__or__all)\n",
    "\n",
    "    format_fatalities_zero=Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','zero')\n",
    "    #print(format_fatalities_zero.dtypes)\n",
    "    \n",
    "    described_fatalities_zero = correct_definition_df(format_fatalities_zero,df_ag,'zero','No',pg__or__cm)\n",
    "\n",
    "    fatalities_nonzero, described_fatalities_nonzero,len_fat = Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','non-zero')\n",
    "    \n",
    "    return(described_fatalities_nonzero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_or_CM = 'PG'\n",
    "\n",
    "monthly_or_annual = 'monthly'\n",
    "resolution = '5x5'\n",
    "country = 'Ethiopia'\n",
    "rec_or_all = 'all'\n",
    "abc = imjustken(PG_or_CM, df_pg, df_cm,  monthly_or_annual, resolution, country, rec_or_all)\n",
    "\n",
    "print(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Repeat_for_zero_fatalities(PG_or_CM, queryset, monthly_or_annual, resolution=0, country=0):\n",
    "\n",
    "    pg__or__cm = PG_or_CM\n",
    "    res = resolution\n",
    "    cntry = country\n",
    "    m_or_a = monthly_or_annual\n",
    "    \n",
    "    #if PG_or_CM == 'PG':\n",
    "        #df_pg = queryset_base_PG.publish().fetch()\n",
    "    #Reset index in order to access 'month_id' and 'priogrid_gid' columns\n",
    "    df_pg = queryset.reset_index()\n",
    "    df_109_516 = df_pg.loc[(df_pg['month_id']>=109) & (df_pg['month_id']<= 516)]\n",
    "\n",
    "    #else:\n",
    "        #df_cm = queryset_base_CM.publish().fetch()\n",
    "\n",
    "    df__PP=PGM_preprocess(df_109_516)\n",
    "    df_ag=PRIO_Agg(df__PP, monthly_or_annual,pg__or__cm, res, cntry)\n",
    "\n",
    "    #total_events = report_length(df_ag, PG_or_CM,'Global', monthly_or_annual,res)\n",
    "    #print(total_events)\n",
    "\n",
    "    format_fatalities_zero=Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','zero')\n",
    "    #print(format_fatalities_zero.dtypes)\n",
    "    \n",
    "    described_fatalities_zero = correct_definition_df(format_fatalities_zero,df_ag,'zero','No',pg__or__cm)\n",
    "    \n",
    "    fatalities_nonzero, described_fatalities_nonzero,len_fat = Format_summary_stats(PG_or_CM,df_ag,'Fatalities_Sum','non-zero')\n",
    "    #Fatalities_nonzero_cordef = correct_definition_df(described_fatalities_nonzero, fatalities_nonzero,'non-zero','No')\n",
    "    #print(len_fat)\n",
    "    \n",
    "    return(described_fatalities_zero, fatalities_nonzero, described_fatalities_nonzero, len_fat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingester3.extensions import *\n",
    "import os\n",
    "\n",
    "\n",
    "def Save_for_timeline_generation(yes_or_no, gisfile, pg_or_cm, temporal, resolution, country):\n",
    "    \n",
    "    if yes_or_no == 'yes':\n",
    "\n",
    "#1. create month field --\n",
    "#2. convert to string\n",
    "        m_list = ['1','2','3','4','5','6','7','8','9']\n",
    "    #subset all that fit the prior def\n",
    "    #mask = df['Subscription'].isin(active_statuses)\n",
    "\n",
    "        gisfile['month'] = gisfile.m.month.astype(str)\n",
    "        #gisfile['month'] = np.where(gisfile['month'].isin(m_list),gisfile['month'].str.zfill(1),gisfile['month'].str.zfill(0))\n",
    "        gisfile['month'] = gisfile['month'].astype(str).str.zfill(2)\n",
    "        gisfile['year'] = gisfile.m.year.astype(str)\n",
    "        gisfile['date'] = gisfile['year'] + '-' + gisfile['month']\n",
    "\n",
    "        gisfile = gisfile.drop(['month','year'], axis=1)\n",
    "\n",
    "        print(gisfile.head(3))\n",
    "    #All_country_zero.loc[mask, 'Percentile_of_1'] = 100\n",
    "\n",
    "        gisfile.to_csv(f'{Tables_For_Timeline_Maps}{pg_or_cm}_{temporal}_{resolution}_{country}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countrylist = ['Syria', 'South Sudan', 'Yemen', 'Ethiopia']\n",
    "#countrylist = ['Syria', 'South Sudan', 'Yemen', 'Ethiopia', 'Nigeria', 'Rwanda', 'Senegal']\n",
    "\n",
    "CM_orPG ='CM'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = [0]\n",
    "Country = ['Syria', 'South Sudan', 'Yemen', 'Ethiopia', 'Nigeria', 'Rwanda', 'Senegal']\n",
    "\n",
    "#df_cm | df_pg\n",
    "\n",
    "#co = df_cm['country_name'].unique()\n",
    "#co = sort(co)\n",
    "\n",
    "per = []\n",
    "c = []\n",
    "fat95 = []\n",
    "growdata = pd.DataFrame()\n",
    "\n",
    "for i in Country:\n",
    "    print( 'working on '+ i)\n",
    "\n",
    "    s = []\n",
    "    c = []\n",
    "    fat95 = []\n",
    "\n",
    "    for a in Scale:\n",
    "        print('...at ' + str(a) + ' resolution:')\n",
    "\n",
    "        z = imjustken(CM_orPG, temporal_resolution, a, i)\n",
    "        \n",
    "        val_95= z['Fatalities'][7]\n",
    "\n",
    "        s.append(a)\n",
    "        c.append(i)\n",
    "        fat95.append(val_95)\n",
    "\n",
    "    All_country_zero = pd.DataFrame(\n",
    "        {'Country': c,\n",
    "        'Aggregation': s,\n",
    "        'Percentile_95': fat95,\n",
    "        })\n",
    "    growdata = growdata.append(All_country_zero)\n",
    "\n",
    "print(growdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "reporttime = datetime.now().strftime(\"%Y_%m_%d__%I_%p\")\n",
    "print(reporttime)\n",
    "\n",
    "growdata.to_csv(f'{compare_countries}scale_and_country_{reporttime}.csv') \n",
    "#/Users/gbenz/Documents/Food Security and Conflict/FAO_Preprocessing/scale_and_country_CM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pg = queryset_base_PG.publish().fetch()\n",
    "df_pg = df_pg.reset_index()\n",
    "\n",
    "df_cm = queryset_base_CM.publish().fetch()\n",
    "df_cm = df_cm.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to manipulate in Graph_it_all():\n",
    "\n",
    "1. CM_or_pg: select from either 'PG' or 'CM' \n",
    "\n",
    "2. temporal_resolution: select from 'monthly' or 'annual' -- The accuracy of 'annual' has not been accepted\n",
    "\n",
    "3. Scale: declare any resolution '1x1' to '10x10' (note: '7x7' not available yet)\n",
    "ex. ('1x1', '2x2', '3x3') these must be strings\n",
    "NOTE: this parameter assumes a value of 0 which applies only to CM inputs\n",
    "\n",
    "4. Select any country name \n",
    "4a. This parameter assumes a value of 0, implying it will run 'globally'.\n",
    "\n",
    "Save_timeline = This applies mostly for Garrett's use to later generate impressive time-enabled maps. For the purpose of reviewing the statsheet this parameter can be set to 'no'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countrylist = ['Syria', 'South Sudan', 'Yemen', 'Ethiopia', 'Nigeria', 'Rwanda', 'Senegal']\n",
    "#df_cm | df_pg\n",
    "\n",
    "CM_orPG ='PG'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = '2x2'\n",
    "Country = 'Egypt'\n",
    "rec_or_all = 'recent'\n",
    "\n",
    "Save_timeline='yes'\n",
    "#for i in countrylist:\n",
    "x, gis = Pantaleon(CM_orPG, df_pg, df_cm, temporal_resolution, Scale, Country, rec_or_all)\n",
    "\n",
    "Save_for_timeline_generation(Save_timeline, gis, CM_orPG, temporal_resolution, Scale, Country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_orPG ='CM'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = 0\n",
    "#Country = 'Afghanistan'\n",
    "\n",
    "#df_cm | df_pg\n",
    "\n",
    "countries = df_cm['country_name'].unique()\n",
    "countries = sort(countries)\n",
    "\n",
    "per = []\n",
    "fat95 = []\n",
    "c = []\n",
    "\n",
    "for i in countries:\n",
    "    xx, yy = Repeat_for_zero_fatalities(CM_orPG, df_cm, temporal_resolution, Scale, i)\n",
    "\n",
    "    print(i)\n",
    "    print(type(xx))\n",
    "    if type(xx) is int:\n",
    "        per.append(xx)\n",
    "        fat95.append(xx)\n",
    "        c.append(i)\n",
    "\n",
    "    else:\n",
    "        p = xx['Percentile'][0]\n",
    "        per.append(p)\n",
    "        c.append(i)\n",
    "\n",
    "All_country_zero = pd.DataFrame(\n",
    "    {'Percentile_of_1': per,\n",
    "     'Country': c,\n",
    "    })\n",
    "\n",
    "\n",
    "#print(All_country_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_orPG ='PG'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = 0\n",
    "Country = ['Afghanistan','Antigua and Barbuda']\n",
    "\n",
    "#df_cm | df_pg\n",
    "\n",
    "co = df_cm['country_name'].unique()\n",
    "co = sort(co)\n",
    "\n",
    "per = []\n",
    "c = []\n",
    "fat95 = []\n",
    "\n",
    "for i in co:\n",
    "    xx, yy, aa, bb = Repeat_for_zero_fatalities(CM_orPG, df_cm, temporal_resolution, Scale, i)\n",
    "    if isinstance(aa, pd.DataFrame):\n",
    "        aa=aa.reset_index()\n",
    "        val_95= aa['Fatalities'][7]\n",
    "\n",
    "    if type(xx) is int:\n",
    "        per.append(xx)\n",
    "        fat95.append(xx)\n",
    "        c.append(i)\n",
    "\n",
    "    else:\n",
    "        p = xx['Percentile'][0]\n",
    "        per.append(p)\n",
    "        c.append(i)\n",
    "        fat95.append(val_95)\n",
    "\n",
    "All_country_zero = pd.DataFrame(\n",
    "    {'Country': c,\n",
    "    'Percentile_of_1': per,\n",
    "    'Percentile_95': fat95,\n",
    "    })\n",
    "\n",
    "#greater_than0len = len(yy[yy['Fatalities_Sum']>0.0])\n",
    "\n",
    "print(All_country_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_orPG ='PG'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = ['1x1','2x2','5x5','8x8']\n",
    "Country = ['Syria','South Sudan']\n",
    "\n",
    "#df_cm | df_pg\n",
    "\n",
    "co = df_cm['country_name'].unique()\n",
    "co = sort(co)\n",
    "\n",
    "per = []\n",
    "c = []\n",
    "fat95 = []\n",
    "\n",
    "for i in co:\n",
    "    print('working on ' + i)\n",
    "    for a in Scale:\n",
    "        print('... at ' + a + ' resolution')\n",
    "        xx, yy, aa, bb = Repeat_for_zero_fatalities(CM_orPG, df_pg, temporal_resolution, a, i)\n",
    "\n",
    "        print(aa)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#greater_than0len = len(yy[yy['Fatalities_Sum']>0.0])\n",
    "\n",
    "#print(All_country_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_country_zero['Percentile_of_1'] = All_country_zero['Percentile_of_1'].astype(float)\n",
    "All_country_zero = All_country_zero.sort_values('Percentile_of_1', ascending=False)\n",
    "\n",
    "print(All_country_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_orPG ='CM'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = 0\n",
    "Country = ['Afghanistan','Antigua and Barbuda']\n",
    "\n",
    "#df_cm | df_pg\n",
    "\n",
    "co = df_cm['country_name'].unique()\n",
    "co = sort(co)\n",
    "\n",
    "per = []\n",
    "c = []\n",
    "at95 = []\n",
    "\n",
    "for i in Country:\n",
    "    xx, yy, aa, bb = Repeat_for_zero_fatalities(CM_orPG, df_cm, temporal_resolution, Scale, i)\n",
    "    print(aa)\n",
    "    val_95= xx['Percentile'][7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if type(aa) == pd.DataFrame():\n",
    "        aa=aa.reset_index()\n",
    "        val_95= xx['Percentile'][7]    \n",
    "\n",
    "if type(aa) == pd.DataFrame():\n",
    "        aa=aa.reset_index()\n",
    "        val_95= xx['Percentile'][7]\n",
    "\n",
    "\n",
    "    if xx == 0:\n",
    "        per.append(xx)\n",
    "        c.append(i)\n",
    "\n",
    "    else:  \n",
    "        p = xx['Percentile'][0]\n",
    "        per.append(p)\n",
    "        c.append(i)\n",
    "        at95.append(val_95)\n",
    "\n",
    "    All_country_zero = pd.DataFrame(\n",
    "    {'Country': c,\n",
    "    'Percentile_of_1': per,\n",
    "    'Perc_95': at95,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_cm['country_name'].unique()\n",
    "countries = sort(countries)\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_cm['country_name'].unique()\n",
    "countries = sort(countries)\n",
    "\n",
    "countrylist = ['Afghanistan']\n",
    "CM_orPG = 'CM'\n",
    "temporal_resolution = 'monthly'\n",
    "Scale = 0\n",
    "\n",
    "#Country = 'Afghanistan'\n",
    "\n",
    "per = []\n",
    "c = []\n",
    "\n",
    "for i in countrylist:\n",
    "    xx = Repeat_for_zero_fatalities(CM_orPG, df_cm, temporal_resolution, Scale, i)\n",
    "    print(i)\n",
    "\n",
    "    if xx == 0:\n",
    "        per.append(xx)\n",
    "        c.append(i)\n",
    "\n",
    "    else:  \n",
    "        p = xx['Percentile'][0]\n",
    "        per.append(p)\n",
    "        c.append(i)\n",
    "\n",
    "All_country_zero = pd.DataFrame(\n",
    "    {'Percentile_of_1': per,\n",
    "     'Country': c,\n",
    "    })\n",
    "\n",
    "print(All_country_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_cm['country_name'].unique()\n",
    "countries = sort(countries)\n",
    "\n",
    "print(countries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
